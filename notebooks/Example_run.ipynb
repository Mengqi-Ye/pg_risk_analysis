{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5263e9-087d-4863-a4e5-839dc33017bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osgeo import ogr,gdal\n",
    "import os\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pyproj\n",
    "from pygeos import from_wkb,from_wkt\n",
    "import pygeos\n",
    "from tqdm import tqdm\n",
    "from shapely.wkb import loads\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from shapely.geometry import mapping\n",
    "pd.options.mode.chained_assignment = None\n",
    "from rasterio.mask import mask\n",
    "import rioxarray\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f11a902-f512-4fd3-b035-af38041ee083",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal.SetConfigOption(\"OSM_CONFIG_FILE\", os.path.join('..',\"osmconf.ini\"))\n",
    "\n",
    "# change paths to make it work on your own machine\n",
    "data_path = os.path.join('C:\\\\','data','pg_risk_analysis')\n",
    "tc_path = os.path.join(data_path,'tc_netcdf')\n",
    "fl_path = os.path.join(data_path,'GLOFRIS')\n",
    "osm_data_path = os.path.join('C:\\\\','data','country_osm')\n",
    "pg_data_path = os.path.join(data_path,'pg_data')\n",
    "vul_curve_path = os.path.join(data_path,'vulnerability_curves','input_vulnerability_data.xlsx')\n",
    "output_path = os.path.join('C:\\\\','projects','pg_risk_analysis','output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc83d355-8c98-4ae6-97b1-3203a29a4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_b(geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    This function builds an SQL query from the values passed to the retrieve() function.\n",
    "    Arguments:\n",
    "         *geoType* : Type of geometry (osm layer) to search for.\n",
    "         *keyCol* : A list of keys/columns that should be selected from the layer.\n",
    "         ***valConstraint* : A dictionary of constraints for the values. e.g. WHERE 'value'>20 or 'value'='constraint'\n",
    "    Returns:\n",
    "        *string: : a SQL query string.\n",
    "    \"\"\"\n",
    "    query = \"SELECT \" + \"osm_id\"\n",
    "    for a in keyCol: query+= \",\"+ a  \n",
    "    query += \" FROM \" + geoType + \" WHERE \"\n",
    "    # If there are values in the dictionary, add constraint clauses\n",
    "    if valConstraint: \n",
    "        for a in [*valConstraint]:\n",
    "            # For each value of the key, add the constraint\n",
    "            for b in valConstraint[a]: query += a + b\n",
    "        query+= \" AND \"\n",
    "    # Always ensures the first key/col provided is not Null.\n",
    "    query+= \"\"+str(keyCol[0]) +\" IS NOT NULL\" \n",
    "    return query \n",
    "\n",
    "\n",
    "def retrieve(osm_path,geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    Function to extract specified geometry and keys/values from OpenStreetMap\n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.     \n",
    "        *geoType* : Type of Geometry to retrieve. e.g. lines, multipolygons, etc.\n",
    "        *keyCol* : These keys will be returned as columns in the dataframe.\n",
    "        ***valConstraint: A dictionary specifiying the value constraints.  \n",
    "        A key can have multiple values (as a list) for more than one constraint for key/value.  \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all columns, geometries, and constraints specified.    \n",
    "    \"\"\"\n",
    "    driver=ogr.GetDriverByName('OSM')\n",
    "    data = driver.Open(osm_path)\n",
    "    query = query_b(geoType,keyCol,**valConstraint)\n",
    "    sql_lyr = data.ExecuteSQL(query)\n",
    "    features =[]\n",
    "    # cl = columns \n",
    "    cl = ['osm_id'] \n",
    "    for a in keyCol: cl.append(a)\n",
    "    if data is not None:\n",
    "        print('query is finished, lets start the loop')\n",
    "        for feature in tqdm(sql_lyr,desc='extract'):\n",
    "            #try:\n",
    "            if feature.GetField(keyCol[0]) is not None:\n",
    "                geom1 = (feature.geometry().ExportToWkt())\n",
    "                #print(geom1)\n",
    "                geom = from_wkt(feature.geometry().ExportToWkt()) \n",
    "                if geom is None:\n",
    "                    continue\n",
    "                # field will become a row in the dataframe.\n",
    "                field = []\n",
    "                for i in cl: field.append(feature.GetField(i))\n",
    "                field.append(geom)   \n",
    "                features.append(field)\n",
    "            #except:\n",
    "            #    print(\"WARNING: skipped OSM feature\")   \n",
    "    else:\n",
    "        print(\"ERROR: Nonetype error when requesting SQL. Check required.\")    \n",
    "    cl.append('geometry')                   \n",
    "    if len(features) > 0:\n",
    "        return pd.DataFrame(features,columns=cl)\n",
    "    else:\n",
    "        print(\"WARNING: No features or No Memory. returning empty GeoDataFrame\") \n",
    "        return pd.DataFrame(columns=['osm_id','geometry'])\n",
    "\n",
    "def power_polyline(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract all energy linestrings from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'lines',['power','voltage'])\n",
    "    \n",
    "    df = df.reset_index(drop=True).rename(columns={'power': 'asset'})\n",
    "    \n",
    "    #print(df) #check infra keys\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def power_polygon(osm_path): # check with joel, something was wrong here with extracting substations\n",
    "    \"\"\"\n",
    "    Function to extract energy polygons from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['other_tags']) \n",
    "    \n",
    "    df = df.loc[(df.other_tags.str.contains('power'))]   #keep rows containing power data         \n",
    "    df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})     \n",
    "    \n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"substation\"', case=False)]  = 'substation' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"plant\"', case=False)] = 'plant' #specify row\n",
    "    \n",
    "    df = df.loc[(df.asset == 'substation') | (df.asset == 'plant')]\n",
    "            \n",
    "    return df.reset_index(drop=True) \n",
    "\n",
    "def electricity(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract building polygons from OpenStreetMap    \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all unique building polygons.    \n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['power'])\n",
    "    \n",
    "    df = df.reset_index(drop=True).rename(columns={'power': 'asset'})\n",
    "    \n",
    "    #df = df[df.asset!='generator']\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"substation\"', case=False)]  = 'substation' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"plant\"', case=False)] = 'plant' #specify row\n",
    "    \n",
    "    #print(df)  #check infra keys\n",
    "    \n",
    "    df = df.loc[(df.asset == 'substation') | (df.asset == 'plant')]\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def retrieve_poly_subs(osm_path, w_list, b_list):\n",
    "    \"\"\"\n",
    "    Function to extract electricity substation polygons from OpenStreetMap\n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region\n",
    "        for which we want to do the analysis.\n",
    "        *w_list* :  white list of keywords to search in the other_tags columns\n",
    "        *b_list* :  black list of keywords of rows that should not be selected\n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique substation.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['other_tags'])\n",
    "    df = df[df.other_tags.str.contains('substation', case=False, na=False)]\n",
    "    #df = df.loc[(df.other_tags.str.contains('substation'))]\n",
    "    df = df[~df.other_tags.str.contains('|'.join(b_list))]\n",
    "    #df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})\n",
    "    df['asset']  = 'substation' #specify row\n",
    "    #df = df.loc[(df.asset == 'substation')] #specify row\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def power_point(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract energy points from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"   \n",
    "    df = retrieve(osm_path,'points',['other_tags']) \n",
    "    df = df.loc[(df.other_tags.str.contains('power'))]  #keep rows containing power data       \n",
    "    df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})     \n",
    "    \n",
    "    #print(df)\n",
    "    \n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"tower\"', case=False)]  = 'power_tower' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"pole\"', case=False)] = 'power_pole' #specify row\n",
    "    #df['asset'].loc[df['asset'].str.contains('\"utility\"=>\"power\"', case=False)] = 'power_tower' #specify row\n",
    "    \n",
    "    df = df.loc[(df.asset == 'power_tower') | (df.asset == 'power_pole')]\n",
    "            \n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36fe9f2e-0be0-47fd-83ca-67f3a272279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject(df_ds,current_crs=\"epsg:4326\",approximate_crs = \"epsg:3857\"):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        df_ds ([type]): [description]\n",
    "        current_crs (str, optional): [description]. Defaults to \"epsg:3857\".\n",
    "        approximate_crs (str, optional): [description]. Defaults to \"epsg:4326\".\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"    \n",
    "\n",
    "    geometries = df_ds['geometry']\n",
    "    coords = pygeos.get_coordinates(geometries)\n",
    "    transformer=pyproj.Transformer.from_crs(current_crs, approximate_crs,always_xy=True)\n",
    "    new_coords = transformer.transform(coords[:, 0], coords[:, 1])\n",
    "    \n",
    "    return pygeos.set_coordinates(geometries.copy(), np.array(new_coords).T) \n",
    "\n",
    "def load_curves_maxdam(vul_curve_path,hazard_type):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        data_path ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "\n",
    "    if hazard_type == 'tc':\n",
    "        sheet_name = 'wind_curves'\n",
    "    \n",
    "    elif hazard_type == 'fl':\n",
    "        sheet_name = 'flooding_curves'\n",
    "    \n",
    "    # load curves and maximum damages as separate inputs\n",
    "    curves = pd.read_excel(vul_curve_path,sheet_name=sheet_name,skiprows=11,index_col=[0])\n",
    "    maxdam = pd.read_excel(vul_curve_path,sheet_name=sheet_name,index_col=[0]).iloc[:8]\n",
    "    #print(curves)\n",
    "    \n",
    "    curves.columns = maxdam.columns\n",
    "\n",
    "    #transpose maxdam so its easier work with the dataframe\n",
    "    maxdam = maxdam.T\n",
    "\n",
    "    #interpolate the curves to fill missing values\n",
    "    curves = curves.interpolate()\n",
    "    \n",
    "    #print(curves)\n",
    "   \n",
    "    return curves,maxdam\n",
    "\n",
    "def buffer_assets(assets,buffer_size=100):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        assets ([type]): [description]\n",
    "        buffer_size (int, optional): [description]. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"    \n",
    "    assets['buffered'] = pygeos.buffer(assets.geometry.values,buffer_size)\n",
    "    return assets\n",
    "\n",
    "def overlay_hazard_assets(df_ds,assets):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        df_ds ([type]): [description]\n",
    "        assets ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    #overlay \n",
    "    hazard_tree = pygeos.STRtree(df_ds.geometry.values)\n",
    "    if (pygeos.get_type_id(assets.iloc[0].geometry) == 3) | (pygeos.get_type_id(assets.iloc[0].geometry) == 6):\n",
    "        return  hazard_tree.query_bulk(assets.geometry,predicate='intersects')    \n",
    "    else:\n",
    "        return  hazard_tree.query_bulk(assets.buffered,predicate='intersects')\n",
    "    \n",
    "def get_damage_per_asset_per_rp(asset,df_ds,assets,curves,maxdam,return_period,country):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        asset ([type]): [description]\n",
    "        df_ds ([type]): [description]\n",
    "        assets ([type]): [description]\n",
    "        grid_size (int, optional): [description]. Defaults to 90.\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"    \n",
    "\n",
    "    # find the exact hazard overlays:\n",
    "    get_hazard_points = df_ds.iloc[asset[1]['hazard_point'].values].reset_index()\n",
    "    get_hazard_points = get_hazard_points.loc[pygeos.intersects(get_hazard_points.geometry.values,assets.iloc[asset[0]].geometry)]\n",
    "\n",
    "    asset_type = assets.iloc[asset[0]].asset\n",
    "    asset_geom = assets.iloc[asset[0]].geometry\n",
    "\n",
    "    if asset_type in ['plant','substation','generator']:\n",
    "        maxdam_asset = maxdam.loc[asset_type].MaxDam/pygeos.area(asset_geom)\n",
    "    else:\n",
    "        maxdam_asset = maxdam.loc[asset_type].MaxDam\n",
    "\n",
    "\n",
    "    hazard_intensity = curves[asset_type].index.values\n",
    "    fragility_values = curves[asset_type].values\n",
    "    \n",
    "    if len(get_hazard_points) == 0:\n",
    "        return asset[0],0\n",
    "    else:\n",
    "        \n",
    "        if pygeos.get_type_id(asset_geom) == 1:\n",
    "            get_hazard_points['overlay_meters'] = pygeos.length(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            return asset[0],np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,fragility_values))*get_hazard_points.overlay_meters*maxdam_asset)\n",
    "        \n",
    "        elif  pygeos.get_type_id(asset_geom) == 3:\n",
    "            get_hazard_points['overlay_m2'] = pygeos.area(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            return asset[0],get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity, fragility_values)*maxdam_asset*x.overlay_m2,axis=1).sum()     \n",
    "        \n",
    "        else:\n",
    "            return asset[0],np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,fragility_values))*maxdam_asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df720cc-65d2-44b0-89e1-418f26a0804a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                  power_tower  power_tower.1  power_tower.2  power_tower.3  \\\n",
       " Wind speed (m/s)                                                             \n",
       " 0.000000                  0.0            0.0            0.0            0.0   \n",
       " 1.000000                  0.0            0.0            0.0            0.0   \n",
       " 1.388889                  0.0            0.0            0.0            0.0   \n",
       " 2.000000                  0.0            0.0            0.0            0.0   \n",
       " 2.235200                  0.0            0.0            0.0            0.0   \n",
       " ...                       ...            ...            ...            ...   \n",
       " 380.000000                1.0            1.0            1.0            1.0   \n",
       " 385.000000                1.0            1.0            1.0            1.0   \n",
       " 390.000000                1.0            1.0            1.0            1.0   \n",
       " 395.000000                1.0            1.0            1.0            1.0   \n",
       " 400.000000                1.0            1.0            1.0            1.0   \n",
       " \n",
       "                   power_tower.4  power_tower.5  power_tower.6  power_tower.7  \\\n",
       " Wind speed (m/s)                                                               \n",
       " 0.000000                    0.0            0.0            0.0            0.0   \n",
       " 1.000000                    0.0            0.0            0.0            0.0   \n",
       " 1.388889                    0.0            0.0            0.0            0.0   \n",
       " 2.000000                    0.0            0.0            0.0            0.0   \n",
       " 2.235200                    0.0            0.0            0.0            0.0   \n",
       " ...                         ...            ...            ...            ...   \n",
       " 380.000000                  1.0            1.0            1.0            1.0   \n",
       " 385.000000                  1.0            1.0            1.0            1.0   \n",
       " 390.000000                  1.0            1.0            1.0            1.0   \n",
       " 395.000000                  1.0            1.0            1.0            1.0   \n",
       " 400.000000                  1.0            1.0            1.0            1.0   \n",
       " \n",
       "                   power_tower.8  power_tower.9  ...  power_pole.36  \\\n",
       " Wind speed (m/s)                                ...                  \n",
       " 0.000000                    0.0            0.0  ...            NaN   \n",
       " 1.000000                    0.0            0.0  ...            NaN   \n",
       " 1.388889                    0.0            0.0  ...            NaN   \n",
       " 2.000000                    0.0            0.0  ...            NaN   \n",
       " 2.235200                    0.0            0.0  ...         0.0000   \n",
       " ...                         ...            ...  ...            ...   \n",
       " 380.000000                  1.0            1.0  ...         0.9276   \n",
       " 385.000000                  1.0            1.0  ...         0.9276   \n",
       " 390.000000                  1.0            1.0  ...         0.9276   \n",
       " 395.000000                  1.0            1.0  ...         0.9276   \n",
       " 400.000000                  1.0            1.0  ...         0.9276   \n",
       " \n",
       "                   power_pole.37  power_pole.38  power_pole.39  power_pole.40  \\\n",
       " Wind speed (m/s)                                                               \n",
       " 0.000000                    NaN            NaN            NaN            NaN   \n",
       " 1.000000                    NaN            NaN            NaN            NaN   \n",
       " 1.388889                    NaN            NaN            NaN            NaN   \n",
       " 2.000000                    NaN            NaN            NaN            NaN   \n",
       " 2.235200                 0.0000         0.0000         0.0000         0.0000   \n",
       " ...                         ...            ...            ...            ...   \n",
       " 380.000000               0.9437         0.9738         0.9928         0.9928   \n",
       " 385.000000               0.9437         0.9738         0.9928         0.9928   \n",
       " 390.000000               0.9437         0.9738         0.9928         0.9928   \n",
       " 395.000000               0.9437         0.9738         0.9928         0.9928   \n",
       " 400.000000               0.9437         0.9738         0.9928         0.9928   \n",
       " \n",
       "                   power_pole.41  power_pole.42  power_pole.43  power_pole.44  \\\n",
       " Wind speed (m/s)                                                               \n",
       " 0.000000                    NaN            NaN            NaN            NaN   \n",
       " 1.000000                    NaN            NaN            NaN            NaN   \n",
       " 1.388889                    NaN            NaN            NaN            NaN   \n",
       " 2.000000                    NaN            NaN            NaN            NaN   \n",
       " 2.235200                    0.0         0.0000         0.0000            0.0   \n",
       " ...                         ...            ...            ...            ...   \n",
       " 380.000000                  1.0         0.9866         0.9897            1.0   \n",
       " 385.000000                  1.0         0.9866         0.9897            1.0   \n",
       " 390.000000                  1.0         0.9866         0.9897            1.0   \n",
       " 395.000000                  1.0         0.9866         0.9897            1.0   \n",
       " 400.000000                  1.0         0.9866         0.9897            1.0   \n",
       " \n",
       "                   power_pole.45  \n",
       " Wind speed (m/s)                 \n",
       " 0.000000                    NaN  \n",
       " 1.000000                    NaN  \n",
       " 1.388889                    NaN  \n",
       " 2.000000                    NaN  \n",
       " 2.235200                    0.0  \n",
       " ...                         ...  \n",
       " 380.000000                  1.0  \n",
       " 385.000000                  1.0  \n",
       " 390.000000                  1.0  \n",
       " 395.000000                  1.0  \n",
       " 400.000000                  1.0  \n",
       " \n",
       " [268 rows x 91 columns],\n",
       " Infrastructure type   Code                        Specific occupancy  \\\n",
       " power_tower           W3_1                      Wind attack angle: 0   \n",
       " power_tower.1         W3_2                   Wind attack angle: 22.5   \n",
       " power_tower.2         W3_3                     Wind attack angle: 45   \n",
       " power_tower.3         W3_4                   Wind attack angle: 67.5   \n",
       " power_tower.4         W3_5                     Wind attack angle: 90   \n",
       " ...                    ...                                       ...   \n",
       " power_pole.41        W4_39               Class 5, power model, 50 yr   \n",
       " power_pole.42        W4_40               Class 5, power model, 75 yr   \n",
       " power_pole.43        W4_41              Class 5, power model, 100 yr   \n",
       " power_pole.44        W4_42   Class 5, 13.7m tall, 12.47kV, span 44 m   \n",
       " power_pole.45        W4_43  Class 5,  13.7m tall, 34.5kV, span 104 m   \n",
       " \n",
       " Infrastructure type                  Reference Type vulnerability data  \\\n",
       " power_tower                    Fu et al., 2019                   curve   \n",
       " power_tower.1                  Fu et al., 2019                   curve   \n",
       " power_tower.2                  Fu et al., 2019                   curve   \n",
       " power_tower.3                  Fu et al., 2019                   curve   \n",
       " power_tower.4                  Fu et al., 2019                   curve   \n",
       " ...                                        ...                     ...   \n",
       " power_pole.41        Shafieezadeh et al., 2014                   curve   \n",
       " power_pole.42        Shafieezadeh et al., 2014                   curve   \n",
       " power_pole.43        Shafieezadeh et al., 2014                   curve   \n",
       " power_pole.44                 Han et al., 2014                   curve   \n",
       " power_pole.45                 Han et al., 2014                   curve   \n",
       " \n",
       " Infrastructure type           Unit         MaxDam      LowerDam       UpperDam  \n",
       " power_tower          euro/facility  117360.574259  88020.430694  146700.717823  \n",
       " power_tower.1        euro/facility  117360.574259  88020.430694  146700.717823  \n",
       " power_tower.2        euro/facility  117360.574259  88020.430694  146700.717823  \n",
       " power_tower.3        euro/facility  117360.574259  88020.430694  146700.717823  \n",
       " power_tower.4        euro/facility  117360.574259  88020.430694  146700.717823  \n",
       " ...                            ...            ...           ...            ...  \n",
       " power_pole.41        euro/facility    2778.847368   2084.135526     3473.55921  \n",
       " power_pole.42        euro/facility    2778.847368   2084.135526     3473.55921  \n",
       " power_pole.43        euro/facility    2778.847368   2084.135526     3473.55921  \n",
       " power_pole.44        euro/facility    2778.847368   2084.135526     3473.55921  \n",
       " power_pole.45        euro/facility    2778.847368   2084.135526     3473.55921  \n",
       " \n",
       " [91 rows x 8 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_curves_maxdam(vul_curve_path,hazard_type='tc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9896d9f-4592-4552-8876-c1340f3e09f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_storm_data(climate_model,basin):\n",
    "    \n",
    "    with xr.open_dataset(os.path.join(tc_path,'STORM_FIXED_RETURN_PERIODS{}_{}.nc'.format(climate_model,basin))) as ds:\n",
    "        \n",
    "        # get the mean values\n",
    "        df_ds = ds['mean'].to_dataframe().unstack(level=2).reset_index()\n",
    "\n",
    "        # create geometry values and drop lat lon columns\n",
    "        df_ds['geometry'] = [pygeos.points(x) for x in list(zip(df_ds['lon'],df_ds['lat']))]\n",
    "        df_ds = df_ds.drop(['lat','lon'],axis=1,level=0)\n",
    "        \n",
    "        # interpolate wind speeds of 1, 2, and 5-yr return period\n",
    "        ## rename columns to return periods (must be integer for interpolating)\n",
    "        df_ds_geometry = pd.DataFrame()\n",
    "        df_ds_geometry['geometry'] = df_ds['geometry']\n",
    "        df_ds = df_ds.drop(['geometry'],axis=1,level=0)\n",
    "        df_ds.columns = [int(x) for x in ds['rp']]\n",
    "        df_ds[1] = np.nan\n",
    "        df_ds[2] = np.nan\n",
    "        df_ds[5] = np.nan\n",
    "        df_ds[25] = np.nan\n",
    "        df_ds[250] = np.nan\n",
    "        df_ds = df_ds.reindex(sorted(df_ds.columns), axis=1)\n",
    "        df_ds = df_ds.interpolate(method='pchip',axis=1,limit_direction='both')\n",
    "        df_ds['geometry'] = df_ds_geometry['geometry']\n",
    "        #df_ds = df_ds[['1','2','5','10','25','50','100','250','500','1000','geometry']]\n",
    "        df_ds = df_ds[[1,2,5,10,25,50,100,250,500,1000,'geometry']]\n",
    "        \n",
    "        #rename columns to return periods\n",
    "        #return_periods = ['1_{}{}'.format(int(x),climate_model) for x in ds['rp']]\n",
    "        #df_ds.columns = ['1_{}{}'.format(int(x),climate_model) for x in [1,2,5,10,25,50,100,250,500,1000]] +['geometry']     \n",
    "        df_ds['geometry'] = pygeos.buffer(df_ds.geometry,radius=0.1/2,cap_style='square').values\n",
    "        df_ds['geometry'] = reproject(df_ds)\n",
    "            \n",
    "        # drop all non values to reduce size\n",
    "        #df_ds = df_ds.loc[~df_ds['1_10000{}'.format(climate_model)].isna()].reset_index(drop=True)\n",
    "        df_ds = df_ds.fillna(0)\n",
    "        #df_ds = df_ds[['1','2','5','10','25','50','100','250','500','1000']]\n",
    "        #df_ds = df_ds[['1_{}{}'.format(int(x),climate_model) for x in list(df_ds.columns.get_level_values(0))[:-1]]+['geometry']]\n",
    "\n",
    "    return df_ds\n",
    "\n",
    "def open_storm_data():\n",
    "    climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "    df_ds = {}\n",
    "    for climate_model in climate_models:\n",
    "        #combine STORM data from different basins\n",
    "        wp = load_storm_data(climate_model,'WP')\n",
    "        sp = load_storm_data(climate_model,'SP')\n",
    "        ni = load_storm_data(climate_model,'NI')\n",
    "        si = load_storm_data(climate_model,'SI')\n",
    "        df_ds_cl = pd.concat([wp,sp,ni,si],keys=['wp','sp','ni','si'])\n",
    "\n",
    "        df_ds_cl = df_ds_cl.reset_index(drop=True)\n",
    "        df_ds[climate_model] = df_ds_cl\n",
    "    \n",
    "    return df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5630c0-488d-403e-9289-09ab777387b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_storm_data('_CMCC-CM2-VHR4','WP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cd1788c-cc9f-467f-849f-3ec9a7f82a8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed eval>:1\u001b[0m\n",
      "Cell \u001b[1;32mIn [37], line 50\u001b[0m, in \u001b[0;36mopen_storm_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m wp \u001b[38;5;241m=\u001b[39m load_storm_data(climate_model,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWP\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     49\u001b[0m sp \u001b[38;5;241m=\u001b[39m load_storm_data(climate_model,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSP\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m ni \u001b[38;5;241m=\u001b[39m \u001b[43mload_storm_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclimate_model\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m si \u001b[38;5;241m=\u001b[39m load_storm_data(climate_model,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSI\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     52\u001b[0m df_ds_cl \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([wp,sp,ni,si],keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwp\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msp\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mni\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msi\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn [37], line 9\u001b[0m, in \u001b[0;36mload_storm_data\u001b[1;34m(climate_model, basin)\u001b[0m\n\u001b[0;32m      6\u001b[0m df_ds \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dataframe()\u001b[38;5;241m.\u001b[39munstack(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# create geometry values and drop lat lon columns\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m df_ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [pygeos\u001b[38;5;241m.\u001b[39mpoints(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(df_ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m],df_ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m]))]\n\u001b[0;32m     10\u001b[0m df_ds \u001b[38;5;241m=\u001b[39m df_ds\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# interpolate wind speeds of 1, 2, and 5-yr return period\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m## rename columns to return periods (must be integer for interpolating)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [37], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m df_ds \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dataframe()\u001b[38;5;241m.\u001b[39munstack(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# create geometry values and drop lat lon columns\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m df_ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[43mpygeos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(df_ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m],df_ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m]))]\n\u001b[0;32m     10\u001b[0m df_ds \u001b[38;5;241m=\u001b[39m df_ds\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# interpolate wind speeds of 1, 2, and 5-yr return period\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m## rename columns to return periods (must be integer for interpolating)\u001b[39;00m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pgrisk\\lib\\site-packages\\pygeos\\decorators.py:80\u001b[0m, in \u001b[0;36mmultithreading_enabled.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_args:\n\u001b[0;32m     79\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr, old_flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array_args, old_flags):\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pgrisk\\lib\\site-packages\\pygeos\\creation.py:73\u001b[0m, in \u001b[0;36mpoints\u001b[1;34m(coords, y, z, indices, out, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m coords \u001b[38;5;241m=\u001b[39m _xyz_to_coords(coords, y, z)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mpoints(coords, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m simple_geometries_1d(coords, indices, GeometryType\u001b[38;5;241m.\u001b[39mPOINT, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "open_storm_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c7ff6dd-a3f2-4e2a-becd-e5cffa38edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_flood_data(country_code):\n",
    "\n",
    "    # load country geometry file and create geometry to clip\n",
    "    ne_countries = gpd.read_file('C:\\\\Data\\\\natural_earth\\\\ne_10m_admin_0_countries.shp') \n",
    "    geometry = ne_countries.loc[ne_countries['ISO_A3']==country_code].geometry.values[0]\n",
    "    geoms = [mapping(geometry)]\n",
    "    \n",
    "    #climate_model: historical, rcp4p5, rcp8p5; time_period: hist, 2030, 2050, 2080\n",
    "    rps = ['0001','0002','0005','0010','0025','0050','0100','0250','0500','1000']\n",
    "    climate_models = ['historical','rcp8p5']\n",
    "    \n",
    "    \n",
    "    for rp in rps:\n",
    "        #global input_file\n",
    "        for climate_model in climate_models:\n",
    "            if climate_model=='historical':\n",
    "                #f rps=='0001':\n",
    "                    input_file = os.path.join(fl_path,'global',\n",
    "                                              'inuncoast_{}_nosub_hist_rp{}_0.tif'.format(climate_model,rp)) \n",
    "                #elif rps==['0002','0005','0010','0025','0050','0100','0250','0500','1000']:\n",
    "                #    input_file = os.path.join(fl_path,'global',\n",
    "                #                              'inuncoast_{}_nosub_hist_rp{}_0.tif'.format(climate_model,rp)) \n",
    "            elif climate_model=='rcp8p5':\n",
    "                #f rps=='0001':\n",
    "                    input_file = os.path.join(fl_path,'global',\n",
    "                                              'inuncoast_{}_nosub_2030_rp{}_0.tif'.format(climate_model,rp))\n",
    "                #elif rps==['0002','0005','0010','0025','0050','0100','0250','0500','1000']:\n",
    "                #    input_file = os.path.join(fl_path,'global',\n",
    "                #                              'inuncoast_{}_nosub_2030_rp{}_0.tif'.format(climate_model,rp))\n",
    "            \n",
    "            # load raster file and save clipped version\n",
    "            with rasterio.open(input_file) as src:\n",
    "                out_image, out_transform = mask(src, geoms, crop=True)\n",
    "                out_meta = src.meta\n",
    "\n",
    "                out_meta.update({\"driver\": \"GTiff\",\n",
    "                         \"height\": out_image.shape[1],\n",
    "                         \"width\": out_image.shape[2],\n",
    "                         \"transform\": out_transform})\n",
    "\n",
    "                file_path = os.path.join(fl_path,'country','_'.join([country_code]+input_file.split('_')[3:]))\n",
    "\n",
    "                with rasterio.open(file_path, \"w\", **out_meta) as dest:\n",
    "                    dest.write(out_image)\n",
    "\n",
    "def load_flood_data(country_code,scenario_type):\n",
    "    files = [x for x in os.listdir(os.path.join(fl_path,'country'))  if country_code in x ]\n",
    "    \n",
    "    rps = ['0001','0002','0005','0010','0025','0050','0100','0250','0500','1000']\n",
    "    collect_df_ds = []\n",
    "    \n",
    "    if scenario_type=='historical':\n",
    "        print('Loading historical coastal flood data ...')\n",
    "        for rp in rps:\n",
    "            #for file in files:\n",
    "            file_path = os.path.join(fl_path,'country','{}_{}_nosub_hist_rp{}_0.tif'.format(country_code,scenario_type,rp))\n",
    "            with xr.open_dataset(file_path) as ds: #, engine=\"rasterio\"\n",
    "                df_ds = ds.to_dataframe().reset_index()\n",
    "                df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "                df_ds = df_ds.rename(columns={'band_data': 'rp'+rp}) #rename to return period\n",
    "                df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "                df_ds = df_ds.dropna()\n",
    "                df_ds = df_ds.reset_index(drop=True)\n",
    "                df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=20/2,cap_style='square').values  #?????????????????????????\n",
    "                df_ds['geometry'] = reproject(df_ds)\n",
    "                collect_df_ds.append(df_ds)\n",
    "\n",
    "        df_all = collect_df_ds[0].merge(collect_df_ds[1]).merge(collect_df_ds[2]).merge(collect_df_ds[3]).merge(collect_df_ds[4])\\\n",
    "                 .merge(collect_df_ds[5]).merge(collect_df_ds[6]).merge(collect_df_ds[7]).merge(collect_df_ds[8]).merge(collect_df_ds[9])\n",
    "\n",
    "    elif scenario_type=='rcp8p5':\n",
    "        print('Loading future coastal flood data ...')\n",
    "        for rp in rps:\n",
    "            #for file in files:\n",
    "            file_path = os.path.join(fl_path,'country','{}_{}_nosub_2030_rp{}_0.tif'.format(country_code,scenario_type,rp))\n",
    "            with xr.open_dataset(file_path) as ds: #, engine=\"rasterio\"\n",
    "                df_ds = ds.to_dataframe().reset_index()\n",
    "                df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "                df_ds = df_ds.rename(columns={'band_data': 'rp'+rp}) #rename to return period\n",
    "                df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "                df_ds = df_ds.dropna()\n",
    "                df_ds = df_ds.reset_index(drop=True)\n",
    "                df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=20/2,cap_style='square').values\n",
    "                df_ds['geometry'] = reproject(df_ds)\n",
    "                collect_df_ds.append(df_ds)\n",
    "\n",
    "        df_all = collect_df_ds[0].merge(collect_df_ds[1]).merge(collect_df_ds[2]).merge(collect_df_ds[3]).merge(collect_df_ds[4])\\\n",
    "                 .merge(collect_df_ds[5]).merge(collect_df_ds[6]).merge(collect_df_ds[7]).merge(collect_df_ds[8]).merge(collect_df_ds[9])\n",
    "\n",
    "    return df_all\n",
    "\n",
    "def open_flood_data(country_code):\n",
    "    scenario_types = ['historical','rcp8p5']\n",
    "    df_ds = {}\n",
    "    for scenario_type in scenario_types:\n",
    "        #hist = load_flood_data(country_code,'historical')\n",
    "        #rcp8p5 = load_flood_data(country_code,'rcp8p5')\n",
    "        #df_ds_sc = pd.concat([hist,rcp8p5],keys=['historical','rcp8p5'])\n",
    "        df_ds_sc = load_flood_data(country_code,scenario_type)\n",
    "\n",
    "        df_ds[scenario_type] = df_ds_sc\n",
    "    \n",
    "    return df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a9173bf-9b7b-46d4-b1d3-291e68b2588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_flood_data('TWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5ac9f48-e434-4893-8c04-07e663921d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n",
      "CPU times: total: 30.2 s\n",
      "Wall time: 30.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'historical':          rp0001                                           geometry    rp0002  \\\n",
       " 0      1.764207  POLYGON ((14280899.175 4092200.019, 14280899.1...  1.908693   \n",
       " 1      0.000000  POLYGON ((14280899.175 4084326.103, 14280899.1...  0.000000   \n",
       " 2      0.000000  POLYGON ((14280899.175 4083201.706, 14280899.1...  0.000000   \n",
       " 3      0.000000  POLYGON ((14281826.838 4093325.313, 14281826.8...  0.000000   \n",
       " 4      0.000000  POLYGON ((14281826.838 4092200.019, 14281826.8...  0.000000   \n",
       " ...         ...                                                ...       ...   \n",
       " 45721  0.000000  POLYGON ((14691853.629 4163314.925, 14691853.6...  0.000000   \n",
       " 45722  0.000000  POLYGON ((14692781.291 4165579.974, 14692781.2...  0.000000   \n",
       " 45723  0.000000  POLYGON ((14692781.291 4164447.392, 14692781.2...  0.000000   \n",
       " 45724  0.000000  POLYGON ((14692781.291 4163314.925, 14692781.2...  0.000000   \n",
       " 45725  0.000000  POLYGON ((14693708.954 4164447.392, 14693708.9...  0.000000   \n",
       " \n",
       "          rp0005    rp0010    rp0025    rp0050    rp0100    rp0250    rp0500  \\\n",
       " 0      2.264267  2.499688  2.797143  3.017812  3.236852  3.525253  3.743019   \n",
       " 1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " 2      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " 3      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " 4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " ...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 45721  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " 45722  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " 45723  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " 45724  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " 45725  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " \n",
       "          rp1000  \n",
       " 0      3.960628  \n",
       " 1      0.000000  \n",
       " 2      0.000000  \n",
       " 3      0.000000  \n",
       " 4      0.000000  \n",
       " ...         ...  \n",
       " 45721  0.000000  \n",
       " 45722  0.000000  \n",
       " 45723  0.000000  \n",
       " 45724  0.000000  \n",
       " 45725  0.000000  \n",
       " \n",
       " [45726 rows x 11 columns],\n",
       " 'rcp8p5':          rp0001                                           geometry    rp0002  \\\n",
       " 0      1.963807  POLYGON ((14280899.175 4092200.019, 14280899.1...  2.108293   \n",
       " 1      0.000000  POLYGON ((14280899.175 4084326.103, 14280899.1...  0.000000   \n",
       " 2      0.000000  POLYGON ((14280899.175 4083201.706, 14280899.1...  0.000000   \n",
       " 3      0.000000  POLYGON ((14281826.838 4093325.313, 14281826.8...  0.000000   \n",
       " 4      0.000000  POLYGON ((14281826.838 4092200.019, 14281826.8...  0.000000   \n",
       " ...         ...                                                ...       ...   \n",
       " 45721  0.000000  POLYGON ((14691853.629 4163314.925, 14691853.6...  0.000000   \n",
       " 45722  0.000000  POLYGON ((14692781.291 4165579.974, 14692781.2...  0.000000   \n",
       " 45723  0.000000  POLYGON ((14692781.291 4164447.392, 14692781.2...  0.000000   \n",
       " 45724  0.000000  POLYGON ((14692781.291 4163314.925, 14692781.2...  0.000000   \n",
       " 45725  0.000000  POLYGON ((14693708.954 4164447.392, 14693708.9...  0.000000   \n",
       " \n",
       "          rp0005    rp0010    rp0025    rp0050    rp0100    rp0250    rp0500  \\\n",
       " 0      2.463867  2.699287  2.996743  3.217412  3.436452  3.724854  3.942619   \n",
       " 1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " 2      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " 3      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " 4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " ...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 45721  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " 45722  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " 45723  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " 45724  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " 45725  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       " \n",
       "          rp1000  \n",
       " 0      4.160228  \n",
       " 1      0.000000  \n",
       " 2      0.000000  \n",
       " 3      0.000000  \n",
       " 4      0.082438  \n",
       " ...         ...  \n",
       " 45721  0.000000  \n",
       " 45722  0.000000  \n",
       " 45723  0.000000  \n",
       " 45724  0.000000  \n",
       " 45725  0.000000  \n",
       " \n",
       " [45726 rows x 11 columns]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "twn_flood = open_flood_data('TWN')\n",
    "#print(type(lao_flood))\n",
    "twn_flood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3de688-606c-4dd2-abe3-f37015c7442e",
   "metadata": {},
   "source": [
    "# OSM data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "934161b6-5f01-4315-87b3-9e4a7bd70876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|████████████████████████████████████████████████████████████████████| 2594/2594 [00:08<00:00, 323.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|███████████████████████████████████████████████████████████████████████| 244/244 [00:18<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|█████████████████████████████████████████████████████████████| 1608621/1608621 [02:55<00:00, 9159.37it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_osm_infrastructure(country_code,osm_data_path):\n",
    "\n",
    "    # lines\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    power_lines_country = power_polyline(osm_path)\n",
    "    power_lines_country['geometry'] = reproject(power_lines_country)\n",
    "    power_lines_country = buffer_assets(power_lines_country.loc[power_lines_country.asset.isin(\n",
    "        ['cable','minor_cable','line','minor_line'])],buffer_size=100).reset_index(drop=True)\n",
    "    \n",
    "    # polygons\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    power_poly_country = electricity(osm_path)\n",
    "    power_poly_country['geometry'] = reproject(power_poly_country)\n",
    "    \n",
    "    # points\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    power_points_country = power_point(osm_path)\n",
    "    power_points_country['geometry'] = reproject(power_points_country)\n",
    "    power_points_country = buffer_assets(power_points_country.loc[power_points_country.asset.isin(\n",
    "        ['power_tower','power_pole'])],buffer_size=100).reset_index(drop=True)\n",
    "    #print(power_points_country)\n",
    "    #print(type(power_points_country))\n",
    "\n",
    "    return power_lines_country,power_poly_country,power_points_country\n",
    "\n",
    "\n",
    "osm_power_infra = extract_osm_infrastructure('TWN',osm_data_path)\n",
    "#print(type(osm_power_infra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c18d432c-e93d-4a40-b495-14be74207610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          osm_id asset voltage  \\\n",
       " 0       52174646  line  161000   \n",
       " 1       52174647  line    None   \n",
       " 2       52174648  line  161000   \n",
       " 3       52176335  line    None   \n",
       " 4       52176336  line    None   \n",
       " ...          ...   ...     ...   \n",
       " 1746  1098796452  line  161000   \n",
       " 1747  1098796453  line  161000   \n",
       " 1748  1098796454  line   69000   \n",
       " 1749  1098796455  line   69000   \n",
       " 1750  1100557068  line    None   \n",
       " \n",
       "                                                geometry  \\\n",
       " 0     LINESTRING (13524085.736 2879026.882, 13523921...   \n",
       " 1     LINESTRING (13523921.651 2879313.221, 13524074...   \n",
       " 2     LINESTRING (13522366.484 2874157.801, 13522432...   \n",
       " 3     LINESTRING (13525160.859 2876713.703, 13525168...   \n",
       " 4     LINESTRING (13528063.994 2877032.402, 13528287...   \n",
       " ...                                                 ...   \n",
       " 1746  LINESTRING (13481629.539 2880939.954, 13481633...   \n",
       " 1747  LINESTRING (13481629.539 2880939.954, 13481624...   \n",
       " 1748  LINESTRING (13484630.78 2882484.715, 13484554....   \n",
       " 1749  LINESTRING (13484554.437 2882521.015, 13484633...   \n",
       " 1750  LINESTRING (13517148.461 2886006.543, 13517182...   \n",
       " \n",
       "                                                buffered  \n",
       " 0     POLYGON ((13523834.887 2879263.502, 13523824.7...  \n",
       " 1     POLYGON ((13524055.351 2879440.892, 13524074.8...  \n",
       " 2     POLYGON ((13522403.249 2874254.634, 13522658.4...  \n",
       " 3     POLYGON ((13525068.44 2876869.436, 13525071.26...  \n",
       " 4     POLYGON ((13528346.027 2876951.973, 13528347.2...  \n",
       " ...                                                 ...  \n",
       " 1746  POLYGON ((13481708.927 2881001.119, 13481720.3...  \n",
       " 1747  POLYGON ((13481543.368 2880888.366, 13481533.3...  \n",
       " 1748  POLYGON ((13484511.496 2882430.704, 13484494.7...  \n",
       " 1749  POLYGON ((13484561.795 2882412.981, 13484522.4...  \n",
       " 1750  POLYGON ((13517084.513 2886193.691, 13517090.1...  \n",
       " \n",
       " [1751 rows x 5 columns],\n",
       "       osm_id       asset                                           geometry\n",
       " 0    2898719  substation  MULTIPOLYGON (((13406596.997 2769537.942, 1340...\n",
       " 1    3442741  substation  MULTIPOLYGON (((13416708.079 2596786.727, 1341...\n",
       " 2    4601461  substation  MULTIPOLYGON (((13530208.441 2880664.9, 135302...\n",
       " 3    5506835  substation  MULTIPOLYGON (((13529270.508 2882306.942, 1352...\n",
       " 4    5750909  substation  MULTIPOLYGON (((13504843.727 2673366.88, 13504...\n",
       " ..       ...         ...                                                ...\n",
       " 184     None       plant  MULTIPOLYGON (((13406014.284 2769056.421, 1340...\n",
       " 185     None       plant  MULTIPOLYGON (((13395161.924 2581390.613, 1339...\n",
       " 186     None  substation  MULTIPOLYGON (((13379742.995 2719300.176, 1337...\n",
       " 187     None       plant  MULTIPOLYGON (((13415810.978 2562831.441, 1341...\n",
       " 188     None       plant  MULTIPOLYGON (((13432465.821 2797251.302, 1343...\n",
       " \n",
       " [189 rows x 3 columns],\n",
       "             osm_id        asset                          geometry  \\\n",
       " 0        478669744   power_pole  POINT (13353739.241 3019225.354)   \n",
       " 1        478669768   power_pole  POINT (13353708.004 3019165.065)   \n",
       " 2        478670901   power_pole  POINT (13353777.579 3019282.543)   \n",
       " 3        664646850  power_tower  POINT (13524085.736 2879026.882)   \n",
       " 4        664646856  power_tower  POINT (13523921.651 2879313.221)   \n",
       " ...            ...          ...                               ...   \n",
       " 27180  10060734766  power_tower  POINT (13482276.628 2881681.909)   \n",
       " 27181  10060734767  power_tower  POINT (13482360.018 2881748.361)   \n",
       " 27182  10060734768  power_tower  POINT (13482443.708 2881815.058)   \n",
       " 27183  10060734769  power_tower   POINT (13482526.129 2881880.22)   \n",
       " 27184  10060734770  power_tower  POINT (13482608.527 2881946.697)   \n",
       " \n",
       "                                                 buffered  \n",
       " 0      POLYGON ((13353839.241 3019225.354, 13353837.3...  \n",
       " 1      POLYGON ((13353808.004 3019165.065, 13353806.0...  \n",
       " 2      POLYGON ((13353877.579 3019282.543, 13353875.6...  \n",
       " 3      POLYGON ((13524185.736 2879026.882, 13524183.8...  \n",
       " 4      POLYGON ((13524021.651 2879313.221, 13524019.7...  \n",
       " ...                                                  ...  \n",
       " 27180  POLYGON ((13482376.628 2881681.909, 13482374.7...  \n",
       " 27181  POLYGON ((13482460.018 2881748.361, 13482458.0...  \n",
       " 27182  POLYGON ((13482543.708 2881815.058, 13482541.7...  \n",
       " 27183  POLYGON ((13482626.129 2881880.22, 13482624.20...  \n",
       " 27184  POLYGON ((13482708.527 2881946.697, 13482706.6...  \n",
       " \n",
       " [27185 rows x 4 columns])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_power_infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abb7a943-1950-445c-8328-f6db95b7f163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for TWN fl (historical):  18%|████                  | 319/1751 [1:18:47<5:53:41, 14.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 177\u001b[0m\n\u001b[0;32m    173\u001b[0m         damaged_points \u001b[38;5;241m=\u001b[39m damaged_points_country\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffered\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m damaged_lines,damaged_poly,damaged_points\n\u001b[1;32m--> 177\u001b[0m osm_damage_infra \u001b[38;5;241m=\u001b[39m \u001b[43massess_damage_osm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTWN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mosm_power_infra\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [19], line 115\u001b[0m, in \u001b[0;36massess_damage_osm\u001b[1;34m(country_code, osm_power_infra, hazard_type)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m asset \u001b[38;5;129;01min\u001b[39;00m tqdm(overlay_lines\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masset\u001b[39m\u001b[38;5;124m'\u001b[39m),total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(overlay_lines\u001b[38;5;241m.\u001b[39masset\u001b[38;5;241m.\u001b[39munique()),\n\u001b[0;32m    113\u001b[0m                       desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolyline damage calculation for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(country_code,hazard_type,scenario_type)):\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m return_period \u001b[38;5;129;01min\u001b[39;00m return_periods:\n\u001b[1;32m--> 115\u001b[0m             collect_line_damages\u001b[38;5;241m.\u001b[39mappend([return_period,\u001b[43mget_damage_per_asset_per_rp\u001b[49m\u001b[43m(\u001b[49m\u001b[43masset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mdf_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mscenario_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mpower_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mcurves\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mmaxdam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mreturn_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m                                                                                   \u001b[49m\u001b[43mcountry_code\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m#print(collect_line_damages[0])\u001b[39;00m\n\u001b[0;32m    124\u001b[0m collect_line_damages \u001b[38;5;241m=\u001b[39m [(line[\u001b[38;5;241m0\u001b[39m],line[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m],line[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m collect_line_damages]\n",
      "Cell \u001b[1;32mIn [18], line 117\u001b[0m, in \u001b[0;36mget_damage_per_asset_per_rp\u001b[1;34m(asset, df_ds, assets, curves, maxdam, return_period, country)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pygeos\u001b[38;5;241m.\u001b[39mget_type_id(asset_geom) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 117\u001b[0m         get_hazard_points[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverlay_meters\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pygeos\u001b[38;5;241m.\u001b[39mlength(\u001b[43mpygeos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintersection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_hazard_points\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43masset_geom\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m asset[\u001b[38;5;241m0\u001b[39m],np\u001b[38;5;241m.\u001b[39msum((np\u001b[38;5;241m.\u001b[39minterp(get_hazard_points[return_period]\u001b[38;5;241m.\u001b[39mvalues,hazard_intensity,fragility_values))\u001b[38;5;241m*\u001b[39mget_hazard_points\u001b[38;5;241m.\u001b[39moverlay_meters\u001b[38;5;241m*\u001b[39mmaxdam_asset)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m  pygeos\u001b[38;5;241m.\u001b[39mget_type_id(asset_geom) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pgrisk\\lib\\site-packages\\pygeos\\decorators.py:80\u001b[0m, in \u001b[0;36mmultithreading_enabled.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_args:\n\u001b[0;32m     79\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr, old_flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array_args, old_flags):\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pgrisk\\lib\\site-packages\\pygeos\\set_operations.py:129\u001b[0m, in \u001b[0;36mintersection\u001b[1;34m(a, b, grid_size, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrid_size parameter only accepts scalar values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mintersection_prec(a, b, grid_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mintersection(a, b, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def assess_damage_osm(country_code,osm_power_infra,hazard_type):\n",
    "    \n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(vul_curve_path,hazard_type)\n",
    "    curves['line'] = 1 # remove this when things work!\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    power_lines,power_poly,power_points = osm_power_infra\n",
    "    #print(type(power_lines))\n",
    "    #print(type(osm_power_infra))\n",
    "    \n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "        df_ds = open_storm_data()\n",
    "        \n",
    "        # calculate damaged lines in loop by climate_model\n",
    "        damaged_lines = {}\n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),'1_10{}'.format(climate_model),\n",
    "                              '1_25{}'.format(climate_model),'1_50{}'.format(climate_model),'1_100{}'.format(climate_model),\n",
    "                              '1_250{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "\n",
    "            overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],power_lines).T,\n",
    "                                         columns=['asset','hazard_point'])\n",
    "            collect_line_damages = []\n",
    "            for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                              desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_line_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                           df_ds[climate_model],\n",
    "                                                                                           power_lines,\n",
    "                                                                                           curves,\n",
    "                                                                                           maxdam,\n",
    "                                                                                           return_period,\n",
    "                                                                                           country_code)])\n",
    "\n",
    "        collect_line_damages = [(line[0],line[1][0],line[1][1]) for line in collect_line_damages]\n",
    "        damaged_lines_country = power_lines.merge(pd.DataFrame(collect_line_damages,columns=['return_period','index','damage']),\n",
    "                                                  left_index=True,right_on='index')\n",
    "        damaged_lines_country = damaged_lines_country.drop(['buffered'],axis=1)\n",
    "        damaged_lines[climate_model] = damaged_lines_country\n",
    "        \n",
    "        # calculate damaged polygons in loop by country_code and climate_model\n",
    "        damaged_poly = {}\n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),'1_10{}'.format(climate_model),\n",
    "                              '1_25{}'.format(climate_model),'1_50{}'.format(climate_model),'1_100{}'.format(climate_model),\n",
    "                              '1_250{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "\n",
    "            overlay_poly = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],power_poly).T,\n",
    "                                        columns=['asset','hazard_point'])\n",
    "            collect_poly_damages = []\n",
    "            for asset in tqdm(overlay_poly.groupby('asset'),total=len(overlay_poly.asset.unique()),\n",
    "                              desc='polygon damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_poly_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                           df_ds[climate_model],\n",
    "                                                                                           power_poly,\n",
    "                                                                                           curves,\n",
    "                                                                                           maxdam,\n",
    "                                                                                           return_period,\n",
    "                                                                                           country_code)])\n",
    "\n",
    "        collect_poly_damages = [(line[0],line[1][0],line[1][1]) for line in collect_poly_damages]\n",
    "        #print(collect_poly_damages[0])\n",
    "        damaged_poly_country = power_poly.merge(pd.DataFrame(collect_poly_damages,columns=['return_period','index','damage']),\n",
    "                                                left_index=True,right_on='index')\n",
    "        damaged_poly[climate_model] = damaged_poly_country\n",
    "        \n",
    "        # calculate damaged points in loop by country_code and climate_model\n",
    "        damaged_points = {}\n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),'1_10{}'.format(climate_model),\n",
    "                              '1_25{}'.format(climate_model),'1_50{}'.format(climate_model),'1_100{}'.format(climate_model),\n",
    "                              '1_250{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "            \n",
    "            overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],power_points).T,\n",
    "                                          columns=['asset','hazard_point'])\n",
    "            collect_point_damages = []\n",
    "            for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                              desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_point_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                            df_ds[climate_model],\n",
    "                                                                                            power_points,\n",
    "                                                                                            curves,\n",
    "                                                                                            maxdam,\n",
    "                                                                                            return_period,\n",
    "                                                                                            country_code)])\n",
    "\n",
    "        collect_point_damages = [(line[0],line[1][0],line[1][1]) for line in collect_point_damages]\n",
    "        damaged_points_country = power_points.merge(pd.DataFrame(collect_point_damages,columns=['return_period','index','damage']),\n",
    "                                                    left_index=True,right_on='index')\n",
    "        damaged_points_country = damaged_points_country.drop(['buffered'],axis=1)\n",
    "        damaged_points[climate_model] = damaged_points_country\n",
    "        \n",
    "    elif hazard_type=='fl':\n",
    "        # read flood data\n",
    "        scenario_types = ('historical','rcp8p5')\n",
    "        df_ds = open_flood_data(country_code) #['historical'].head(30) # REMOVE .HEAD(30)\n",
    "        #time_periods = []\n",
    "        \n",
    "        #for time_period in time_periods:\n",
    "        return_periods = ['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000']\n",
    "        \n",
    "        # calculate damaged lines in loop by country_code and climate_model\n",
    "        damaged_lines = {}\n",
    "        for scenario_type in scenario_types:\n",
    "            overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[scenario_type],power_lines).T,columns=['asset','hazard_point'])\n",
    "            collect_line_damages = []\n",
    "            for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                              desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,scenario_type)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_line_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                           df_ds[scenario_type],\n",
    "                                                                                           power_lines,\n",
    "                                                                                           curves,\n",
    "                                                                                           maxdam,\n",
    "                                                                                           return_period,\n",
    "                                                                                           country_code)])\n",
    "\n",
    "            #print(collect_line_damages[0])\n",
    "        collect_line_damages = [(line[0],line[1][0],line[1][1]) for line in collect_line_damages]\n",
    "        damaged_lines_country = power_lines.merge(pd.DataFrame(collect_line_damages,columns=['return_period','index','damage']),\n",
    "                                                  left_index=True,right_on='index')\n",
    "        damaged_lines = damaged_lines_country.drop(['buffered'],axis=1)\n",
    "        \n",
    "        # calculate damaged polygons in loop by country_code and climate_model\n",
    "        damaged_poly = {}\n",
    "        for scenario_type in scenario_types:\n",
    "            overlay_poly = pd.DataFrame(overlay_hazard_assets(df_ds[scenario_type],power_poly).T,\n",
    "                                                              columns=['asset','hazard_point'])\n",
    "            collect_poly_damages = []\n",
    "            for asset in tqdm(overlay_poly.groupby('asset'),total=len(overlay_poly.asset.unique()),\n",
    "                              desc='polygon damage calculation for {} {} ({})'.format(country_code,hazard_type,scenario_type)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_poly_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                           df_ds[scenario_type],\n",
    "                                                                                           power_poly,\n",
    "                                                                                           curves,\n",
    "                                                                                           maxdam,\n",
    "                                                                                           return_period,\n",
    "                                                                                           country_code)])\n",
    "\n",
    "        collect_poly_damages = [(line[0],line[1][0],line[1][1]) for line in collect_poly_damages]\n",
    "        #print(collect_poly_damages[0])\n",
    "        damaged_poly_country = power_poly.merge(pd.DataFrame(collect_poly_damages,columns=['return_period','index','damage']),\n",
    "                                                left_index=True,right_on='index')\n",
    "        damaged_poly = damaged_poly_country\n",
    "        \n",
    "        # calculate damaged points in loop by country_code and climate_model\n",
    "        damaged_points = {}\n",
    "        for scenario_type in scenario_types:\n",
    "            overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[scenario_type],power_points).T,\n",
    "                                          columns=['asset','hazard_point'])\n",
    "            collect_point_damages = []\n",
    "            for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                              desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,scenario_type)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_point_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                            df_ds[scenario_type],\n",
    "                                                                                            power_points,\n",
    "                                                                                            curves,\n",
    "                                                                                            maxdam,\n",
    "                                                                                            return_period,\n",
    "                                                                                            country_code)])\n",
    "\n",
    "                #print(collect_point_damages[1][1])\n",
    "        collect_point_damages = [(line[0],line[1][0],line[1][1]) for line in collect_point_damages]\n",
    "        damaged_points_country = power_points.merge(pd.DataFrame(collect_point_damages,columns=['return_period','index','damage']),\n",
    "                                                    left_index=True,right_on='index')\n",
    "        damaged_points = damaged_points_country.drop(['buffered'],axis=1)\n",
    "\n",
    "    return damaged_lines,damaged_poly,damaged_points\n",
    "\n",
    "osm_damage_infra = assess_damage_osm('TWN',osm_power_infra,'fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac71f06a-d796-456c-a7b5-4564ba01f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_damage_infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c5f06-2b02-486a-afe9-9cb9807d5819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_analysis_osm(country_code,hazard_type): #\n",
    "    \n",
    "    # extract infrastructure data from OSM\n",
    "    osm_power_infra = extract_osm_infrastructure(country_code,osm_data_path)\n",
    "    \n",
    "    # assess damage to hazard_type\n",
    "    osm_damage_infra = assess_damage_osm(country_code,osm_power_infra,hazard_type)\n",
    "\n",
    "    return osm_damage_infra\n",
    "    \n",
    "    \n",
    "osm_damage_infra = country_analysis_osm('TWN','tc') #,'line','PG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b093416a-4b36-4f15-affe-2b78c4942c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#osm_damage_infra[1]['_CNRM-CM6-1-HR']\n",
    "osm_damage_infra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ba717-0015-4527-bf1a-a9556f87a541",
   "metadata": {},
   "source": [
    "# Government data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef53a27c-f539-43db-9870-1ee933ddf7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load collected power grid data\n",
    "def extract_pg_data(country_code,pg_type):\n",
    "    files = [x for x in os.listdir(pg_data_path)  if country_code in x ]\n",
    "    \n",
    "    if pg_type=='line':\n",
    "        for file in files: \n",
    "            file_path = os.path.join(pg_data_path,'{}_{}.gpkg'.format(country_code,pg_type))\n",
    "\n",
    "            pg_data_country = gpd.read_file(file_path)\n",
    "            pg_data_country = pd.DataFrame(pg_data_country.copy())\n",
    "            #print(pg_data_country.head())\n",
    "            pg_data_country.geometry = pygeos.from_shapely(pg_data_country.geometry)\n",
    "            pg_data_country['geometry'] = reproject(pg_data_country)\n",
    "\n",
    "        pg_data_country = buffer_assets(pg_data_country.loc[pg_data_country.asset.isin(['line'])],buffer_size=100).reset_index(drop=True)\n",
    "\n",
    "    elif pg_type=='point':\n",
    "        for file in files:\n",
    "            file_path = os.path.join(pg_data_path,'{}_{}.gpkg'.format(country_code,pg_type))\n",
    "                \n",
    "            pg_data_country = gpd.read_file(file_path)\n",
    "            pg_data_country = pd.DataFrame(pg_data_country.copy())\n",
    "            #print(pg_data_country.head())\n",
    "            pg_data_country.geometry = pygeos.from_shapely(pg_data_country.geometry)\n",
    "            pg_data_country['geometry'] = reproject(pg_data_country)\n",
    "            #print(pg_data_country)\n",
    "\n",
    "        pg_data_country = buffer_assets(pg_data_country.loc[pg_data_country.asset.isin(['plant_point','substation_point','power_tower','power_pole'])],buffer_size=100).reset_index(drop=True)\n",
    "\n",
    "    return pg_data_country\n",
    "\n",
    "def open_pg_data(country_code):\n",
    "    pg_lines = extract_pg_data(country_code,'line')\n",
    "    pg_points = extract_pg_data(country_code,'point')\n",
    "    #print(pg_points)\n",
    "    return pg_lines,pg_points\n",
    "\n",
    "pg_infra = open_pg_data('LAO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24824f71-092f-4509-97cf-4e292da71126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_damage_pg(country_code,pg_infra,hazard_type):\n",
    "    \n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(os.path.join(vul_curve_path,'infra_vulnerability_data.xlsx'))\n",
    "    #curves['line'] = 1 # remove this when things work!\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    pg_lines,pg_points = pg_infra\n",
    "    #print(type(pg_points))\n",
    "    #print(type(pg_infra))\n",
    "    \n",
    "    pg_lines.head(5)\n",
    "    pg_points.head(5)\n",
    "    \n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM'] # !!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        df_ds = open_storm_data()\n",
    "        \n",
    "        # calculate damaged lines in loop by country_code and climate_model\n",
    "        damaged_lines = {}\n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['1_10{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                              '1_100{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "\n",
    "            overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],\n",
    "                                                               pg_lines).T,columns=['asset','hazard_point'])\n",
    "            collect_line_damages = []\n",
    "            for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                              desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_line_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                           df_ds[climate_model],\n",
    "                                                                                           pg_lines,\n",
    "                                                                                           curves,\n",
    "                                                                                           maxdam,\n",
    "                                                                                           return_period,\n",
    "                                                                                           country_code)])\n",
    "\n",
    "        collect_line_damages = [(line[0],line[1][0],line[1][1]) for line in collect_line_damages]\n",
    "        damaged_lines_country = pg_lines.merge(pd.DataFrame(collect_line_damages,columns=['return_period','index','damage']),\n",
    "                                                  left_index=True,right_on='index')\n",
    "        damaged_lines_country = damaged_lines_country.drop(['buffered'],axis=1)\n",
    "        damaged_lines[climate_model] = damaged_lines_country\n",
    "        \n",
    "        # calculate damaged points in loop by country_code and climate_model\n",
    "        damaged_points = {}\n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['1_10{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                              '1_100{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "\n",
    "            overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],pg_points).T,\n",
    "                                          columns=['asset','hazard_point'])\n",
    "            collect_point_damages = []\n",
    "            for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                              desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_point_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                            df_ds[climate_model],\n",
    "                                                                                            pg_points,\n",
    "                                                                                            curves,\n",
    "                                                                                            maxdam,\n",
    "                                                                                            return_period,\n",
    "                                                                                            country_code)])\n",
    "\n",
    "        collect_point_damages = [(line[0],line[1][0],line[1][1]) for line in collect_point_damages]\n",
    "        damaged_points_country = pg_points.merge(pd.DataFrame(collect_point_damages,columns=['return_period','index','damage']),\n",
    "                                                    left_index=True,right_on='index')\n",
    "        damaged_points_country = damaged_points_country.drop(['buffered'],axis=1)\n",
    "        damaged_points[climate_model] = damaged_points_country\n",
    " \n",
    "    elif hazard_type=='fl':\n",
    "        # read flood data\n",
    "        scenario_types = ('historical','rcp8p5')\n",
    "        df_ds = open_flood_data(country_code) #['historical'].head(30) # REMOVE .HEAD(30)\n",
    "        #time_periods = []\n",
    "        \n",
    "        #for time_period in time_periods:\n",
    "        return_periods = ['rp0010','rp0050','rp0100','rp0500','rp1000']\n",
    "        \n",
    "        # calculate damaged lines in loop by country_code and climate_model\n",
    "        damaged_lines = {}\n",
    "        for scenario_type in scenario_types:\n",
    "            overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[scenario_type],pg_lines).T,columns=['asset','hazard_point'])\n",
    "            collect_line_damages = []\n",
    "            for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                              desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,scenario_type)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_line_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                           df_ds[scenario_type],\n",
    "                                                                                           pg_lines,\n",
    "                                                                                           curves,\n",
    "                                                                                           maxdam,\n",
    "                                                                                           return_period,\n",
    "                                                                                           country_code)])\n",
    "                    \n",
    "        collect_line_damages = [(line[0],line[1][0],line[1][1]) for line in collect_line_damages]\n",
    "        damaged_lines_country = pg_lines.merge(pd.DataFrame(collect_line_damages,columns=['return_period','index','damage']),\n",
    "                                                  left_index=True,right_on='index')\n",
    "        damaged_lines = damaged_lines_country.drop(['buffered'],axis=1)\n",
    "        \n",
    "        # calculate damaged points in loop by country_code and climate_model\n",
    "        damaged_points = {}\n",
    "        for scenario_type in scenario_types:\n",
    "            overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[scenario_type],pg_points).T,\n",
    "                                          columns=['asset','hazard_point'])\n",
    "            collect_point_damages = []\n",
    "            for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                              desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,scenario_type)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_point_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                            df_ds[scenario_type],\n",
    "                                                                                            pg_points,\n",
    "                                                                                            curves,\n",
    "                                                                                            maxdam,\n",
    "                                                                                            return_period,\n",
    "                                                                                            country_code)])\n",
    "\n",
    "        collect_point_damages = [(line[0],line[1][0],line[1][1]) for line in collect_point_damages]\n",
    "        damaged_points_country = pg_points.merge(pd.DataFrame(collect_point_damages,columns=['return_period','index','damage']),\n",
    "                                                    left_index=True,right_on='index')\n",
    "        damaged_points = damaged_points_country.drop(['buffered'],axis=1)\n",
    "        \n",
    "    return damaged_lines,damaged_points\n",
    "\n",
    "pg_damage_infra = assess_damage_pg('LAO',pg_infra,'tc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24da424b-cbc9-4359-a557-7900720bbef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'_CMCC-CM2-VHR4':         status  capacity_kV              value   id      source country  \\\n",
       "  0     Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "  1     Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "  2     Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "  3     Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "  4     Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "  ...        ...          ...                ...  ...         ...     ...   \n",
       "  2130  Existing           22               None  NaN  World Bank    None   \n",
       "  2131  Existing           22               None  NaN  World Bank    None   \n",
       "  2132  Existing           22               None  NaN  World Bank    None   \n",
       "  2133  Existing           22               None  NaN  World Bank    None   \n",
       "  2134  Existing           22               None  NaN  World Bank    None   \n",
       "  \n",
       "       operator undergrnd phases cables  year asset  \\\n",
       "  0        None      None   None   None  None  line   \n",
       "  1        None      None   None   None  None  line   \n",
       "  2        None      None   None   None  None  line   \n",
       "  3        None      None   None   None  None  line   \n",
       "  4        None      None   None   None  None  line   \n",
       "  ...       ...       ...    ...    ...   ...   ...   \n",
       "  2130     None      None   None   None  None  line   \n",
       "  2131     None      None   None   None  None  line   \n",
       "  2132     None      None   None   None  None  line   \n",
       "  2133     None      None   None   None  None  line   \n",
       "  2134     None      None   None   None  None  line   \n",
       "  \n",
       "                                                 geometry         return_period  \\\n",
       "  0     LINESTRING (11642041.532 2064458.971, 11641491...    1_10_CMCC-CM2-VHR4   \n",
       "  1     LINESTRING (11642041.532 2064458.971, 11641491...    1_50_CMCC-CM2-VHR4   \n",
       "  2     LINESTRING (11642041.532 2064458.971, 11641491...   1_100_CMCC-CM2-VHR4   \n",
       "  3     LINESTRING (11642041.532 2064458.971, 11641491...   1_500_CMCC-CM2-VHR4   \n",
       "  4     LINESTRING (11642041.532 2064458.971, 11641491...  1_1000_CMCC-CM2-VHR4   \n",
       "  ...                                                 ...                   ...   \n",
       "  2130  LINESTRING (11369167.465 2255664.932, 11361366...    1_10_CMCC-CM2-VHR4   \n",
       "  2131  LINESTRING (11369167.465 2255664.932, 11361366...    1_50_CMCC-CM2-VHR4   \n",
       "  2132  LINESTRING (11369167.465 2255664.932, 11361366...   1_100_CMCC-CM2-VHR4   \n",
       "  2133  LINESTRING (11369167.465 2255664.932, 11361366...   1_500_CMCC-CM2-VHR4   \n",
       "  2134  LINESTRING (11369167.465 2255664.932, 11361366...  1_1000_CMCC-CM2-VHR4   \n",
       "  \n",
       "        index        damage  \n",
       "  0         0  2.790178e+08  \n",
       "  1         0  2.790178e+08  \n",
       "  2         0  2.790178e+08  \n",
       "  3         0  2.790178e+08  \n",
       "  4         0  2.790178e+08  \n",
       "  ...     ...           ...  \n",
       "  2130    426  2.658654e+07  \n",
       "  2131    426  2.658654e+07  \n",
       "  2132    426  2.658654e+07  \n",
       "  2133    426  2.658654e+07  \n",
       "  2134    426  2.658654e+07  \n",
       "  \n",
       "  [2135 rows x 16 columns]},\n",
       " {'_CMCC-CM2-VHR4':        status      source country   type capacit_MW  involt_kV outvolt_kV  \\\n",
       "  0    Existing  World Bank    Laos  Hydro       None        NaN       None   \n",
       "  1    Existing  World Bank    Laos  Hydro       None        NaN       None   \n",
       "  2    Existing  World Bank    Laos  Hydro       None        NaN       None   \n",
       "  3    Existing  World Bank    Laos  Hydro       None        NaN       None   \n",
       "  4    Existing  World Bank    Laos  Hydro       None        NaN       None   \n",
       "  ..        ...         ...     ...    ...        ...        ...        ...   \n",
       "  180   Planned  World Bank    Laos   None       None       22.0       None   \n",
       "  181   Planned  World Bank    Laos   None       None       22.0       None   \n",
       "  182   Planned  World Bank    Laos   None       None       22.0       None   \n",
       "  183   Planned  World Bank    Laos   None       None       22.0       None   \n",
       "  184   Planned  World Bank    Laos   None       None       22.0       None   \n",
       "  \n",
       "      capaci_kVA units                  layer  \\\n",
       "  0         None  None  lao33762powerstations   \n",
       "  1         None  None  lao33762powerstations   \n",
       "  2         None  None  lao33762powerstations   \n",
       "  3         None  None  lao33762powerstations   \n",
       "  4         None  None  lao33762powerstations   \n",
       "  ..         ...   ...                    ...   \n",
       "  180       None  None    lao33762substations   \n",
       "  181       None  None    lao33762substations   \n",
       "  182       None  None    lao33762substations   \n",
       "  183       None  None    lao33762substations   \n",
       "  184       None  None    lao33762substations   \n",
       "  \n",
       "                                                    path             asset  \\\n",
       "  0    C:/Users/mye500/OneDrive - Vrije Universiteit ...       plant_point   \n",
       "  1    C:/Users/mye500/OneDrive - Vrije Universiteit ...       plant_point   \n",
       "  2    C:/Users/mye500/OneDrive - Vrije Universiteit ...       plant_point   \n",
       "  3    C:/Users/mye500/OneDrive - Vrije Universiteit ...       plant_point   \n",
       "  4    C:/Users/mye500/OneDrive - Vrije Universiteit ...       plant_point   \n",
       "  ..                                                 ...               ...   \n",
       "  180  C:/Users/mye500/OneDrive - Vrije Universiteit ...  substation_point   \n",
       "  181  C:/Users/mye500/OneDrive - Vrije Universiteit ...  substation_point   \n",
       "  182  C:/Users/mye500/OneDrive - Vrije Universiteit ...  substation_point   \n",
       "  183  C:/Users/mye500/OneDrive - Vrije Universiteit ...  substation_point   \n",
       "  184  C:/Users/mye500/OneDrive - Vrije Universiteit ...  substation_point   \n",
       "  \n",
       "                               geometry         return_period  index  \\\n",
       "  0    POINT (11361572.355 2244469.157)    1_10_CMCC-CM2-VHR4      0   \n",
       "  1    POINT (11361572.355 2244469.157)    1_50_CMCC-CM2-VHR4      0   \n",
       "  2    POINT (11361572.355 2244469.157)   1_100_CMCC-CM2-VHR4      0   \n",
       "  3    POINT (11361572.355 2244469.157)   1_500_CMCC-CM2-VHR4      0   \n",
       "  4    POINT (11361572.355 2244469.157)  1_1000_CMCC-CM2-VHR4      0   \n",
       "  ..                                ...                   ...    ...   \n",
       "  180  POINT (11668538.497 1965410.054)    1_10_CMCC-CM2-VHR4     36   \n",
       "  181  POINT (11668538.497 1965410.054)    1_50_CMCC-CM2-VHR4     36   \n",
       "  182  POINT (11668538.497 1965410.054)   1_100_CMCC-CM2-VHR4     36   \n",
       "  183  POINT (11668538.497 1965410.054)   1_500_CMCC-CM2-VHR4     36   \n",
       "  184  POINT (11668538.497 1965410.054)  1_1000_CMCC-CM2-VHR4     36   \n",
       "  \n",
       "             damage  \n",
       "  0    1.723896e+07  \n",
       "  1    1.965907e+07  \n",
       "  2    2.060631e+07  \n",
       "  3    2.362159e+07  \n",
       "  4    2.478939e+07  \n",
       "  ..            ...  \n",
       "  180  9.672118e+05  \n",
       "  181  1.260258e+06  \n",
       "  182  1.351720e+06  \n",
       "  183  1.495723e+06  \n",
       "  184  1.539769e+06  \n",
       "  \n",
       "  [185 rows x 16 columns]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_damage_infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fac49c0-8408-4d6a-b063-ef6180b6c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'tuple'>\n",
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for LAO fl (historical):  74%|█████████████████      | 317/427 [3:20:12<1:09:28, 37.89s/it]\n",
      "Exception ignored in: <function ZipFile.__del__ at 0x0000012B1188B040>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mye500\\Miniconda3\\envs\\pgrisk\\lib\\zipfile.py\", line 1816, in __del__\n",
      "    self.close()\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def country_analysis_pg(country_code,hazard_type): #\n",
    "    \n",
    "    # extract infrastructure data from OSM\n",
    "    pg_infra = open_pg_data(country_code)\n",
    "\n",
    "    # assess damage to wind storms\n",
    "    pg_damage_infra = assess_damage_pg(country_code,pg_infra,hazard_type)\n",
    "\n",
    "    return pg_damage_infra\n",
    "    \n",
    "    \n",
    "pg_damage_infra = country_analysis_pg('LAO','fl') #,'line','PG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2db9c5e8-9e66-40ed-9f76-3049cfa21b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'_CMCC-CM2-VHR4':         status  capacity_kV              value   id      source country  \\\n",
       "  0     Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "  1     Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "  2     Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "  3     Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "  4     Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "  ...        ...          ...                ...  ...         ...     ...   \n",
       "  2130  Existing           22               None  NaN  World Bank    None   \n",
       "  2131  Existing           22               None  NaN  World Bank    None   \n",
       "  2132  Existing           22               None  NaN  World Bank    None   \n",
       "  2133  Existing           22               None  NaN  World Bank    None   \n",
       "  2134  Existing           22               None  NaN  World Bank    None   \n",
       "  \n",
       "       operator undergrnd phases cables  year asset  \\\n",
       "  0        None      None   None   None  None  line   \n",
       "  1        None      None   None   None  None  line   \n",
       "  2        None      None   None   None  None  line   \n",
       "  3        None      None   None   None  None  line   \n",
       "  4        None      None   None   None  None  line   \n",
       "  ...       ...       ...    ...    ...   ...   ...   \n",
       "  2130     None      None   None   None  None  line   \n",
       "  2131     None      None   None   None  None  line   \n",
       "  2132     None      None   None   None  None  line   \n",
       "  2133     None      None   None   None  None  line   \n",
       "  2134     None      None   None   None  None  line   \n",
       "  \n",
       "                                                 geometry         return_period  \\\n",
       "  0     LINESTRING (11642041.532 2064458.971, 11641491...    1_10_CMCC-CM2-VHR4   \n",
       "  1     LINESTRING (11642041.532 2064458.971, 11641491...    1_50_CMCC-CM2-VHR4   \n",
       "  2     LINESTRING (11642041.532 2064458.971, 11641491...   1_100_CMCC-CM2-VHR4   \n",
       "  3     LINESTRING (11642041.532 2064458.971, 11641491...   1_500_CMCC-CM2-VHR4   \n",
       "  4     LINESTRING (11642041.532 2064458.971, 11641491...  1_1000_CMCC-CM2-VHR4   \n",
       "  ...                                                 ...                   ...   \n",
       "  2130  LINESTRING (11369167.465 2255664.932, 11361366...    1_10_CMCC-CM2-VHR4   \n",
       "  2131  LINESTRING (11369167.465 2255664.932, 11361366...    1_50_CMCC-CM2-VHR4   \n",
       "  2132  LINESTRING (11369167.465 2255664.932, 11361366...   1_100_CMCC-CM2-VHR4   \n",
       "  2133  LINESTRING (11369167.465 2255664.932, 11361366...   1_500_CMCC-CM2-VHR4   \n",
       "  2134  LINESTRING (11369167.465 2255664.932, 11361366...  1_1000_CMCC-CM2-VHR4   \n",
       "  \n",
       "        index        damage  \n",
       "  0         0  2.790178e+08  \n",
       "  1         0  2.790178e+08  \n",
       "  2         0  2.790178e+08  \n",
       "  3         0  2.790178e+08  \n",
       "  4         0  2.790178e+08  \n",
       "  ...     ...           ...  \n",
       "  2130    426  2.658654e+07  \n",
       "  2131    426  2.658654e+07  \n",
       "  2132    426  2.658654e+07  \n",
       "  2133    426  2.658654e+07  \n",
       "  2134    426  2.658654e+07  \n",
       "  \n",
       "  [2135 rows x 16 columns]},\n",
       " {'_CMCC-CM2-VHR4':        status      source country   type capacit_MW  involt_kV outvolt_kV  \\\n",
       "  0    Existing  World Bank    Laos  Hydro       None        NaN       None   \n",
       "  1    Existing  World Bank    Laos  Hydro       None        NaN       None   \n",
       "  2    Existing  World Bank    Laos  Hydro       None        NaN       None   \n",
       "  3    Existing  World Bank    Laos  Hydro       None        NaN       None   \n",
       "  4    Existing  World Bank    Laos  Hydro       None        NaN       None   \n",
       "  ..        ...         ...     ...    ...        ...        ...        ...   \n",
       "  180   Planned  World Bank    Laos   None       None       22.0       None   \n",
       "  181   Planned  World Bank    Laos   None       None       22.0       None   \n",
       "  182   Planned  World Bank    Laos   None       None       22.0       None   \n",
       "  183   Planned  World Bank    Laos   None       None       22.0       None   \n",
       "  184   Planned  World Bank    Laos   None       None       22.0       None   \n",
       "  \n",
       "      capaci_kVA units                  layer  \\\n",
       "  0         None  None  lao33762powerstations   \n",
       "  1         None  None  lao33762powerstations   \n",
       "  2         None  None  lao33762powerstations   \n",
       "  3         None  None  lao33762powerstations   \n",
       "  4         None  None  lao33762powerstations   \n",
       "  ..         ...   ...                    ...   \n",
       "  180       None  None    lao33762substations   \n",
       "  181       None  None    lao33762substations   \n",
       "  182       None  None    lao33762substations   \n",
       "  183       None  None    lao33762substations   \n",
       "  184       None  None    lao33762substations   \n",
       "  \n",
       "                                                    path             asset  \\\n",
       "  0    C:/Users/mye500/OneDrive - Vrije Universiteit ...       plant_point   \n",
       "  1    C:/Users/mye500/OneDrive - Vrije Universiteit ...       plant_point   \n",
       "  2    C:/Users/mye500/OneDrive - Vrije Universiteit ...       plant_point   \n",
       "  3    C:/Users/mye500/OneDrive - Vrije Universiteit ...       plant_point   \n",
       "  4    C:/Users/mye500/OneDrive - Vrije Universiteit ...       plant_point   \n",
       "  ..                                                 ...               ...   \n",
       "  180  C:/Users/mye500/OneDrive - Vrije Universiteit ...  substation_point   \n",
       "  181  C:/Users/mye500/OneDrive - Vrije Universiteit ...  substation_point   \n",
       "  182  C:/Users/mye500/OneDrive - Vrije Universiteit ...  substation_point   \n",
       "  183  C:/Users/mye500/OneDrive - Vrije Universiteit ...  substation_point   \n",
       "  184  C:/Users/mye500/OneDrive - Vrije Universiteit ...  substation_point   \n",
       "  \n",
       "                               geometry         return_period  index  \\\n",
       "  0    POINT (11361572.355 2244469.157)    1_10_CMCC-CM2-VHR4      0   \n",
       "  1    POINT (11361572.355 2244469.157)    1_50_CMCC-CM2-VHR4      0   \n",
       "  2    POINT (11361572.355 2244469.157)   1_100_CMCC-CM2-VHR4      0   \n",
       "  3    POINT (11361572.355 2244469.157)   1_500_CMCC-CM2-VHR4      0   \n",
       "  4    POINT (11361572.355 2244469.157)  1_1000_CMCC-CM2-VHR4      0   \n",
       "  ..                                ...                   ...    ...   \n",
       "  180  POINT (11668538.497 1965410.054)    1_10_CMCC-CM2-VHR4     36   \n",
       "  181  POINT (11668538.497 1965410.054)    1_50_CMCC-CM2-VHR4     36   \n",
       "  182  POINT (11668538.497 1965410.054)   1_100_CMCC-CM2-VHR4     36   \n",
       "  183  POINT (11668538.497 1965410.054)   1_500_CMCC-CM2-VHR4     36   \n",
       "  184  POINT (11668538.497 1965410.054)  1_1000_CMCC-CM2-VHR4     36   \n",
       "  \n",
       "             damage  \n",
       "  0    1.723896e+07  \n",
       "  1    1.965907e+07  \n",
       "  2    2.060631e+07  \n",
       "  3    2.362159e+07  \n",
       "  4    2.478939e+07  \n",
       "  ..            ...  \n",
       "  180  9.672118e+05  \n",
       "  181  1.260258e+06  \n",
       "  182  1.351720e+06  \n",
       "  183  1.495723e+06  \n",
       "  184  1.539769e+06  \n",
       "  \n",
       "  [185 rows x 16 columns]})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_damage_infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188bac94-5a72-447a-ae22-42da57a6b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def country_analysis_pg(country_code,hazard_type): #\n",
    "    \n",
    "    # extract infrastructure data from gov data\n",
    "    osm_power_infra = extract_pg_infra(country_code,pg_data_path)\n",
    "    osm_damage_infra = assess_damage_pg(country_code,pg_data_country,hazard_type)\n",
    "    \n",
    "    return osm_damage_infra\n",
    "    \n",
    "    \n",
    "osm_damage_infra = country_analysis_pg('LAO','fl') #,'line','PG'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769479e-4a85-4931-af47-fb1ff09b73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gridfinder(country_code):\n",
    "    base_map_path = os.path.join(data_path,'base_map')\n",
    "\n",
    "    cty_boundary_path = os.path.join(base_map_path,'gadm41_{}.gpkg'.format(country_code))\n",
    "    cty_boundary = gpd.read_file(cty_boundary_path)\n",
    "    #mask = pd.DataFrame(mask.copy())\n",
    "    #mask.geometry = pygeos.from_shapely(mask.geometry)\n",
    "    #mask['geometry'] = reproject(mask)\n",
    "\n",
    "    gridfinder_path = r'C:\\Users\\mye500\\OneDrive - Vrije Universiteit Amsterdam\\01_Research-Projects\\01_risk_assessment\\PG_data\\gridfinder\\grid.gpkg'\n",
    "    gridfinder = gpd.read_file(gridfinder_path)\n",
    "    #gridfinder = pd.DataFrame(gridfinder.copy())\n",
    "    #gridfinder.geometry = pygeos.from_shapely(gridfinder.geometry)\n",
    "    #gridfinder['geometry'] = reproject(gridfinder)\n",
    "\n",
    "    clipped = gpd.clip(gridfinder,cty_boundary)\n",
    "\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fde70-513a-4898-bbc2-ac8fa3912bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_gridfinder('TWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d93b7-74b5-4ff6-b812-ee1f3bc78aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
