{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5263e9-087d-4863-a4e5-839dc33017bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osgeo import ogr,gdal\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pyproj\n",
    "from pygeos import from_wkb,from_wkt\n",
    "import pygeos\n",
    "from tqdm import tqdm\n",
    "from shapely.wkb import loads\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from shapely.geometry import mapping\n",
    "pd.options.mode.chained_assignment = None\n",
    "from rasterio.mask import mask\n",
    "import rioxarray\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate\n",
    "from collections.abc import Iterable\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy import integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11a902-f512-4fd3-b035-af38041ee083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdal.SetConfigOption(\"OSM_CONFIG_FILE\", os.path.join('..',\"osmconf.ini\"))\n",
    "\n",
    "# change paths to make it work on your own machine\n",
    "data_path = os.path.join('C:\\\\','Data','pg_risk_analysis')\n",
    "tc_path = os.path.join(data_path,'tc_netcdf')\n",
    "fl_path = os.path.join(data_path,'GLOFRIS')\n",
    "osm_data_path = os.path.join('C:\\\\','Data','country_osm')\n",
    "pg_data_path = os.path.join(data_path,'pg_data')\n",
    "vul_curve_path = os.path.join(data_path,'vulnerability_curves','input_vulnerability_data.xlsx')\n",
    "output_path = os.path.join('C:\\\\','projects','pg_risk_analysis','output')\n",
    "ne_path = os.path.join(data_path,'..',\"natural_earth\",\"ne_10m_admin_0_countries.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc83d355-8c98-4ae6-97b1-3203a29a4fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten(xs):\n",
    "    for x in xs:\n",
    "        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):\n",
    "            yield from flatten(x)\n",
    "        else:\n",
    "            yield x\n",
    "\n",
    "def query_b(geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    This function builds an SQL query from the values passed to the retrieve() function.\n",
    "    Arguments:\n",
    "         *geoType* : Type of geometry (osm layer) to search for.\n",
    "         *keyCol* : A list of keys/columns that should be selected from the layer.\n",
    "         ***valConstraint* : A dictionary of constraints for the values. e.g. WHERE 'value'>20 or 'value'='constraint'\n",
    "    Returns:\n",
    "        *string: : a SQL query string.\n",
    "    \"\"\"\n",
    "    query = \"SELECT \" + \"osm_id\"\n",
    "    for a in keyCol: query+= \",\"+ a  \n",
    "    query += \" FROM \" + geoType + \" WHERE \"\n",
    "    # If there are values in the dictionary, add constraint clauses\n",
    "    if valConstraint: \n",
    "        for a in [*valConstraint]:\n",
    "            # For each value of the key, add the constraint\n",
    "            for b in valConstraint[a]: query += a + b\n",
    "        query+= \" AND \"\n",
    "    # Always ensures the first key/col provided is not Null.\n",
    "    query+= \"\"+str(keyCol[0]) +\" IS NOT NULL\" \n",
    "    return query \n",
    "\n",
    "\n",
    "def retrieve(osm_path,geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    Function to extract specified geometry and keys/values from OpenStreetMap\n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.     \n",
    "        *geoType* : Type of Geometry to retrieve. e.g. lines, multipolygons, etc.\n",
    "        *keyCol* : These keys will be returned as columns in the dataframe.\n",
    "        ***valConstraint: A dictionary specifiying the value constraints.  \n",
    "        A key can have multiple values (as a list) for more than one constraint for key/value.  \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all columns, geometries, and constraints specified.    \n",
    "    \"\"\"\n",
    "    driver=ogr.GetDriverByName('OSM')\n",
    "    data = driver.Open(osm_path)\n",
    "    query = query_b(geoType,keyCol,**valConstraint)\n",
    "    sql_lyr = data.ExecuteSQL(query)\n",
    "    features =[]\n",
    "    # cl = columns \n",
    "    cl = ['osm_id'] \n",
    "    for a in keyCol: cl.append(a)\n",
    "    if data is not None:\n",
    "        print('query is finished, lets start the loop')\n",
    "        for feature in tqdm(sql_lyr,desc='extract'):\n",
    "            #try:\n",
    "            if feature.GetField(keyCol[0]) is not None:\n",
    "                geom1 = (feature.geometry().ExportToWkt())\n",
    "                #print(geom1)\n",
    "                geom = from_wkt(feature.geometry().ExportToWkt()) \n",
    "                if geom is None:\n",
    "                    continue\n",
    "                # field will become a row in the dataframe.\n",
    "                field = []\n",
    "                for i in cl: field.append(feature.GetField(i))\n",
    "                field.append(geom)   \n",
    "                features.append(field)\n",
    "            #except:\n",
    "            #    print(\"WARNING: skipped OSM feature\")   \n",
    "    else:\n",
    "        print(\"ERROR: Nonetype error when requesting SQL. Check required.\")    \n",
    "    cl.append('geometry')                   \n",
    "    if len(features) > 0:\n",
    "        return pd.DataFrame(features,columns=cl)\n",
    "    else:\n",
    "        print(\"WARNING: No features or No Memory. returning empty GeoDataFrame\") \n",
    "        return pd.DataFrame(columns=['osm_id','geometry'])\n",
    "\n",
    "def power_polyline(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract all energy linestrings from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'lines',['power','voltage'])\n",
    "    \n",
    "    df = df.reset_index(drop=True).rename(columns={'power': 'asset'})\n",
    "    \n",
    "    #print(df) #check infra keys\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "# def power_polygon(osm_path): # check with joel, something was wrong here with extracting substations\n",
    "#     \"\"\"\n",
    "#     Function to extract energy polygons from OpenStreetMap  \n",
    "#     Arguments:\n",
    "#         *osm_path* : file path to the .osm.pbf file of the region \n",
    "#         for which we want to do the analysis.        \n",
    "#     Returns:\n",
    "#         *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "#     \"\"\"\n",
    "#     df = retrieve(osm_path,'multipolygons',['other_tags']) \n",
    "    \n",
    "#     df = df.loc[(df.other_tags.str.contains('power'))]   #keep rows containing power data         \n",
    "#     df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})     \n",
    "    \n",
    "#     df['asset'].loc[df['asset'].str.contains('\"power\"=>\"substation\"', case=False)]  = 'substation' #specify row\n",
    "#     df['asset'].loc[df['asset'].str.contains('\"power\"=>\"plant\"', case=False)] = 'plant' #specify row\n",
    "    \n",
    "#     df = df.loc[(df.asset == 'substation') | (df.asset == 'plant')]\n",
    "            \n",
    "#     return df.reset_index(drop=True) \n",
    "\n",
    "def electricity(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract building polygons from OpenStreetMap    \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all unique building polygons.    \n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['power'])\n",
    "    \n",
    "    df = df.reset_index(drop=True).rename(columns={'power': 'asset'})\n",
    "    \n",
    "    #df = df[df.asset!='generator']\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"substation\"', case=False)]  = 'substation' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"plant\"', case=False)] = 'plant' #specify row\n",
    "        \n",
    "    df = df.loc[(df.asset == 'substation') | (df.asset == 'plant')]\n",
    "    \n",
    "    print(df['asset'].unique())\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "# def retrieve_poly_subs(osm_path, w_list, b_list):\n",
    "#     \"\"\"\n",
    "#     Function to extract electricity substation polygons from OpenStreetMap\n",
    "#     Arguments:\n",
    "#         *osm_path* : file path to the .osm.pbf file of the region\n",
    "#         for which we want to do the analysis.\n",
    "#         *w_list* :  white list of keywords to search in the other_tags columns\n",
    "#         *b_list* :  black list of keywords of rows that should not be selected\n",
    "#     Returns:\n",
    "#         *GeoDataFrame* : a geopandas GeoDataFrame with specified unique substation.\n",
    "#     \"\"\"\n",
    "#     df = retrieve(osm_path,'multipolygons',['other_tags'])\n",
    "#     df = df[df.other_tags.str.contains('substation', case=False, na=False)]\n",
    "#     #df = df.loc[(df.other_tags.str.contains('substation'))]\n",
    "#     df = df[~df.other_tags.str.contains('|'.join(b_list))]\n",
    "#     #df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})\n",
    "#     df['asset']  = 'substation' #specify row\n",
    "#     #df = df.loc[(df.asset == 'substation')] #specify row\n",
    "#     return df.reset_index(drop=True)\n",
    "\n",
    "def power_point(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract energy points from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"   \n",
    "    df = retrieve(osm_path,'points',['other_tags']) \n",
    "    df = df.loc[(df.other_tags.str.contains('power'))]  #keep rows containing power data       \n",
    "    df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})     \n",
    "        \n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"tower\"', case=False)]  = 'power_tower' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"pole\"', case=False)] = 'power_pole' #specify row\n",
    "    #df['asset'].loc[df['asset'].str.contains('\"utility\"=>\"power\"', case=False)] = 'power_tower' #specify row\n",
    "    \n",
    "    df = df.loc[(df.asset == 'power_tower') | (df.asset == 'power_pole')]\n",
    "            \n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "36fe9f2e-0be0-47fd-83ca-67f3a272279d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reproject(df_ds, current_crs=\"epsg:4326\", approximate_crs=\"epsg:3857\"):\n",
    "\n",
    "    # Extract the input geometries as a numpy array of coordinates\n",
    "    geometries = df_ds['geometry']\n",
    "    coords = pygeos.get_coordinates(geometries)\n",
    "\n",
    "    # Transform the coordinates using pyproj\n",
    "    transformer = pyproj.Transformer.from_crs(current_crs, approximate_crs, always_xy=True)\n",
    "    new_coords = transformer.transform(coords[:, 0], coords[:, 1])\n",
    "\n",
    "    # Create a new GeoSeries with the reprojected coordinates\n",
    "    return pygeos.set_coordinates(geometries.copy(), np.array(new_coords).T)\n",
    "\n",
    "def buffer_assets(assets, buffer_size=100):\n",
    "    \"\"\"\n",
    "    Create a buffer of a specified size around the geometries in a GeoDataFrame.\n",
    "    \n",
    "    Args:\n",
    "        assets (GeoDataFrame): A GeoDataFrame containing geometries to be buffered.\n",
    "        buffer_size (int, optional): The distance in the units of the GeoDataFrame's CRS to buffer the geometries.\n",
    "            Defaults to 100.\n",
    "    \n",
    "    Returns:\n",
    "        GeoDataFrame: A new GeoDataFrame with an additional column named 'buffered' containing the buffered\n",
    "            geometries.\n",
    "    \"\"\"\n",
    "    # Create a buffer of the specified size around the geometries\n",
    "    assets['buffered'] = pygeos.buffer(assets.geometry.values, buffer_size)\n",
    "    \n",
    "    return assets\n",
    "\n",
    "def load_curves_maxdam(country_code,vul_curve_path,hazard_type):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        data_path ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    \n",
    "    # dictionary of GDP per capita ratio for each country\n",
    "    gdp_ratio = {\n",
    "        \"BRN\": {\n",
    "            \"ratio_usa\": 0.5201},\n",
    "        \"KHM\": {\n",
    "            \"ratio_usa\": 0.0240},\n",
    "        \"CHN\": {\n",
    "            \"ratio_usa\": 0.1772},\n",
    "        \"IDN\": {\n",
    "            \"ratio_usa\": 0.0647},\n",
    "        \"JPN\": {\n",
    "            \"ratio_usa\": 0.5912},\n",
    "        \"LAO\": {\n",
    "            \"ratio_usa\": 0.0434},\n",
    "        \"MYS\": {\n",
    "            \"ratio_usa\": 0.1775},\n",
    "        \"MNG\": {\n",
    "            \"ratio_usa\": 0.0703},\n",
    "        \"MMR\": {\n",
    "            \"ratio_usa\": 0.0276},\n",
    "        \"PRK\": {\n",
    "            \"ratio_usa\": 0.0106},\n",
    "        \"PHL\": {\n",
    "            \"ratio_usa\": 0.0547},\n",
    "        \"SGP\": {\n",
    "            \"ratio_usa\": 1.0091},\n",
    "        \"KOR\": {\n",
    "            \"ratio_usa\": 0.5367},\n",
    "        \"TWN\": {\n",
    "            \"ratio_usa\": 0.4888},\n",
    "        \"THA\": {\n",
    "            \"ratio_usa\": 0.1034},\n",
    "        \"VNM\": {\n",
    "            \"ratio_usa\": 0.0573},\n",
    "        \"HKG\": {\n",
    "            \"ratio_usa\": 0.7091},\n",
    "        \"MAC\": {\n",
    "            \"ratio_usa\": 0.5913}\n",
    "    }\n",
    "\n",
    "    if hazard_type == 'tc':\n",
    "        sheet_name = 'wind_curves'\n",
    "    \n",
    "    elif hazard_type == 'fl':\n",
    "        sheet_name = 'flooding_curves'\n",
    "    \n",
    "    # load curves and maximum damages as separate inputs\n",
    "    curves = pd.read_excel(vul_curve_path,sheet_name=sheet_name,skiprows=11,index_col=[0])\n",
    "    \n",
    "    maxdam = pd.read_excel(vul_curve_path,sheet_name=sheet_name,index_col=[0],header=[0,1]).iloc[:8]\n",
    "    maxdam = maxdam.rename({'substation_point':'substation'},level=0,axis=1)\n",
    "\n",
    "    curves.columns = maxdam.columns\n",
    "        \n",
    "    #transpose maxdam so its easier work with the dataframe\n",
    "    maxdam = maxdam.T\n",
    "    \n",
    "    ratio_usa = gdp_ratio.get(country_code, {}).get(\"ratio_usa\", None)\n",
    "\n",
    "    if ratio_usa is not None:\n",
    "        print(f\"The ratio_usa for {country_code} is {ratio_usa}\")\n",
    "    else:\n",
    "        print(f\"No ratio_usa found for {country_code}\")\n",
    "        \n",
    "    maxdam['MaxDam'] = maxdam['MaxDam'] * ratio_usa\n",
    "    maxdam['LowerDam'] = maxdam['LowerDam'] * ratio_usa\n",
    "    maxdam['UpperDam'] = maxdam['UpperDam'] * ratio_usa\n",
    "\n",
    "    #interpolate the curves to fill missing values\n",
    "    curves = curves.interpolate()\n",
    "       \n",
    "    return curves,maxdam\n",
    "\n",
    "\n",
    "def overlay_hazard_assets(df_ds, assets):\n",
    "    \"\"\"\n",
    "    Overlay a set of assets with a hazard dataset and return the subset of assets that intersect with\n",
    "    one or more hazard polygons or lines.\n",
    "    \n",
    "    Args:\n",
    "        df_ds (GeoDataFrame): A GeoDataFrame containing the hazard dataset.\n",
    "        assets (GeoDataFrame): A GeoDataFrame containing the assets to be overlaid with the hazard dataset.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: A numpy array of integers representing the indices of the hazard geometries that intersect with\n",
    "            the assets. If the assets have a 'buffered' column, the buffered geometries are used for the overlay.\n",
    "    \"\"\"\n",
    "    hazard_tree = pygeos.STRtree(df_ds.geometry.values)\n",
    "    if (pygeos.get_type_id(assets.iloc[0].geometry) == 3) | (pygeos.get_type_id(assets.iloc[0].geometry) == 6):\n",
    "        return  hazard_tree.query_bulk(assets.geometry,predicate='intersects')    \n",
    "    else:\n",
    "        return  hazard_tree.query_bulk(assets.buffered,predicate='intersects')\n",
    "    \n",
    "    \n",
    "def get_damage_per_asset_per_rp(asset,df_ds,assets,curves,maxdam,return_period,country):\n",
    "    \"\"\"\n",
    "    Calculates the damage per asset per return period based on asset type, hazard curves and maximum damage\n",
    "\n",
    "    Args:\n",
    "        asset (tuple): Tuple with two dictionaries, containing the asset index and the hazard point index of the asset\n",
    "        df_ds (pandas.DataFrame): A pandas DataFrame containing hazard points with a 'geometry' column\n",
    "        assets (geopandas.GeoDataFrame): A GeoDataFrame containing asset geometries and asset type information\n",
    "        curves (dict): A dictionary with the asset types as keys and their corresponding hazard curves as values\n",
    "        maxdam (pandas.DataFrame): A pandas DataFrame containing the maximum damage for each asset type\n",
    "        return_period (str): The return period for which the damage should be calculated\n",
    "        country (str): The country for which the damage should be calculated\n",
    "\n",
    "    Returns:\n",
    "        list or tuple: Depending on the input, the function either returns a list of tuples with the asset index, the curve name and the calculated damage, or a tuple with None, None, None if no hazard points are found\n",
    "    \"\"\"\n",
    "    \n",
    "    # find the exact hazard overlays:\n",
    "    get_hazard_points = df_ds.iloc[asset[1]['hazard_point'].values].reset_index()\n",
    "    get_hazard_points = get_hazard_points.loc[pygeos.intersects(get_hazard_points.geometry.values,assets.iloc[asset[0]].geometry)]\n",
    "\n",
    "    asset_type = assets.iloc[asset[0]].asset\n",
    "    asset_geom = assets.iloc[asset[0]].geometry\n",
    "\n",
    "    if asset_type in ['plant','substation','generator']:\n",
    "        #if plant,substation are points, do not calculate the area\n",
    "        if pygeos.area(asset_geom) == 0:\n",
    "            maxdam_asset = maxdam.loc[asset_type].MaxDam\n",
    "            lowerdam_asset = maxdam.loc[asset_type].LowerDam\n",
    "            upperdam_asset = maxdam.loc[asset_type].UpperDam\n",
    "        else:\n",
    "            maxdam_asset = maxdam.loc[asset_type].MaxDam/pygeos.area(asset_geom)\n",
    "            lowerdam_asset = maxdam.loc[asset_type].LowerDam/pygeos.area(asset_geom)\n",
    "            upperdam_asset = maxdam.loc[asset_type].UpperDam/pygeos.area(asset_geom)\n",
    "    else:\n",
    "        maxdam_asset = maxdam.loc[asset_type].MaxDam\n",
    "        lowerdam_asset = maxdam.loc[asset_type].LowerDam\n",
    "        upperdam_asset = maxdam.loc[asset_type].UpperDam\n",
    "\n",
    "    hazard_intensity = curves[asset_type].index.values\n",
    "    \n",
    "    if isinstance(curves[asset_type],pd.core.series.Series):\n",
    "        fragility_values = curves[asset_type].values.flatten()\n",
    "        only_one = True\n",
    "        curve_name = curves[asset_type].name\n",
    "    elif len(curves[asset_type].columns) == 1:\n",
    "        fragility_values = curves[asset_type].values.flatten()      \n",
    "        only_one = True   \n",
    "        curve_name = curves[asset_type].columns[0]\n",
    "    else:\n",
    "        fragility_values = curves[asset_type].values#.T[0]\n",
    "        maxdam_asset = maxdam_asset.values#[0]\n",
    "        only_one = False\n",
    "\n",
    "    if len(get_hazard_points) == 0:\n",
    "        if only_one:\n",
    "            return [return_period,asset[0],curve_name,0,0,0]\n",
    "        else:\n",
    "            return [return_period,asset[0],curves[asset_type].columns[0],0,0,0]\n",
    "            \n",
    "    else:\n",
    "        if only_one:    \n",
    "            # run the calculation as normal when the asset just has a single curve\n",
    "            if pygeos.get_type_id(asset_geom) == 1:            \n",
    "                get_hazard_points['overlay_meters'] = pygeos.length(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "                return [return_period,asset[0],curve_name,np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*maxdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*lowerdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*upperdam_asset)]\n",
    "\n",
    "            elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                get_hazard_points['overlay_m2'] = pygeos.area(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "                return [return_period,asset[0],curve_name,get_hazard_points.apply(lambda x: np.interp(x[return_period],hazard_intensity, \n",
    "                                                                  fragility_values)*maxdam_asset*x.overlay_m2,axis=1).sum(),\n",
    "                                                          get_hazard_points.apply(lambda x: np.interp(x[return_period],hazard_intensity, \n",
    "                                                                  fragility_values)*lowerdam_asset*x.overlay_m2,axis=1).sum(),\n",
    "                                                          get_hazard_points.apply(lambda x: np.interp(x[return_period],hazard_intensity, \n",
    "                                                                  fragility_values)*upperdam_asset*x.overlay_m2,axis=1).sum()]  \n",
    "\n",
    "            else:\n",
    "                return [return_period,asset[0],curve_name,np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*maxdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*lowerdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*upperdam_asset)]\n",
    "        else:\n",
    "            # run the calculation when the asset has multiple curves\n",
    "            if pygeos.get_type_id(asset_geom) == 1:            \n",
    "                get_hazard_points['overlay_meters'] = pygeos.length(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                get_hazard_points['overlay_m2'] = pygeos.area(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            \n",
    "            collect_all = []\n",
    "            for iter_,curve_ids in enumerate(curves[asset_type].columns):\n",
    "                if pygeos.get_type_id(asset_geom) == 1:\n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*get_hazard_points.overlay_meters*maxdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*get_hazard_points.overlay_meters*lowerdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*get_hazard_points.overlay_meters*upperdam_asset[iter_])])\n",
    "                                   \n",
    "                elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                        get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity,\n",
    "                                                                                    fragility_values.T[iter_])*maxdam_asset[iter_]*x.overlay_m2,axis=1).sum(),\n",
    "                                        get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity,\n",
    "                                                                                    fragility_values.T[iter_])*lowerdam_asset[iter_]*x.overlay_m2,axis=1).sum(),\n",
    "                                        get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity,\n",
    "                                                                                    fragility_values.T[iter_])*upperdam_asset[iter_]*x.overlay_m2,axis=1).sum()])\n",
    "\n",
    "                else:\n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*maxdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*lowerdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*upperdam_asset[iter_])])\n",
    "            return collect_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57465957-5b97-40c7-aa75-40e808716d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio_usa for CHN is 0.1772\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Type vulnerability data</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Specific occupancy</th>\n",
       "      <th>Cost type</th>\n",
       "      <th>Reference</th>\n",
       "      <th>MaxDam</th>\n",
       "      <th>LowerDam</th>\n",
       "      <th>UpperDam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infrastructure type</th>\n",
       "      <th>Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">plant</th>\n",
       "      <th>F1_1_1</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>Small power plants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2021</td>\n",
       "      <td>27318080.586376</td>\n",
       "      <td>20488560.439782</td>\n",
       "      <td>34147600.73297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_1_2</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>Medium power plants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2021</td>\n",
       "      <td>137375405.247579</td>\n",
       "      <td>103031553.935684</td>\n",
       "      <td>171719256.559473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_1_3</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>Large power plants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2021</td>\n",
       "      <td>137375405.247579</td>\n",
       "      <td>103031553.935684</td>\n",
       "      <td>171719256.559473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">substation</th>\n",
       "      <th>F2_1_1</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>low votage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2012</td>\n",
       "      <td>1785647.560022</td>\n",
       "      <td>1339235.670017</td>\n",
       "      <td>2232059.450028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2_1_2</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>medium votage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2012</td>\n",
       "      <td>3571295.120044</td>\n",
       "      <td>2678471.340033</td>\n",
       "      <td>4464118.900055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2_1_3</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>high votage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2012</td>\n",
       "      <td>8928237.800111</td>\n",
       "      <td>6696178.350083</td>\n",
       "      <td>11160297.250139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">power_tower</th>\n",
       "      <th>F3_1_1</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quanta, 2009</td>\n",
       "      <td>1622.348462</td>\n",
       "      <td>1216.761346</td>\n",
       "      <td>2027.935577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F3_1_2</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>5291.896085</td>\n",
       "      <td>3968.922064</td>\n",
       "      <td>6614.870106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">power_pole</th>\n",
       "      <th>F4_1_1</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quanta, 2009</td>\n",
       "      <td>711.275927</td>\n",
       "      <td>533.456945</td>\n",
       "      <td>889.094908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F4_1_2</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>concrete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quanta, 2009</td>\n",
       "      <td>925.603198</td>\n",
       "      <td>694.202398</td>\n",
       "      <td>1157.003997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F4_1_3</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>steel monopole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quanta, 2009</td>\n",
       "      <td>1230.747109</td>\n",
       "      <td>923.060332</td>\n",
       "      <td>1538.433886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F4_1_4</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>steel monopole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quanta, 2009</td>\n",
       "      <td>745.907339</td>\n",
       "      <td>559.430504</td>\n",
       "      <td>932.384173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">line</th>\n",
       "      <th>F5_1_1</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>71.320209</td>\n",
       "      <td>53.490157</td>\n",
       "      <td>89.150261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_2</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>78.45223</td>\n",
       "      <td>58.839173</td>\n",
       "      <td>98.065288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_3</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>92.716272</td>\n",
       "      <td>69.537204</td>\n",
       "      <td>115.89534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_4</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>116.251941</td>\n",
       "      <td>87.188956</td>\n",
       "      <td>145.314926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_5</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>127.877262</td>\n",
       "      <td>95.907947</td>\n",
       "      <td>159.846578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_6</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>151.127481</td>\n",
       "      <td>113.345611</td>\n",
       "      <td>188.909351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_7</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>47.78454</td>\n",
       "      <td>35.838405</td>\n",
       "      <td>59.730675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_8</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>52.562867</td>\n",
       "      <td>39.42215</td>\n",
       "      <td>65.703583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_9</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>62.119945</td>\n",
       "      <td>46.589958</td>\n",
       "      <td>77.649931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_10</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>77.888975</td>\n",
       "      <td>58.416731</td>\n",
       "      <td>97.361218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_11</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>85.677702</td>\n",
       "      <td>64.258277</td>\n",
       "      <td>107.097128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_12</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>101.255582</td>\n",
       "      <td>75.941686</td>\n",
       "      <td>126.569477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minor_line</th>\n",
       "      <th>F5_2</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>minor line</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.78454</td>\n",
       "      <td>35.838405</td>\n",
       "      <td>59.730675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cable</th>\n",
       "      <th>F5_3_1</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>cable: Distribution circuits elevated crossings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>356.601046</td>\n",
       "      <td>467.255688</td>\n",
       "      <td>9769.891665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_3_2</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>cable: Distribution circuits elevated crossings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>570.561673</td>\n",
       "      <td>467.255688</td>\n",
       "      <td>9769.891665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Type vulnerability data           Unit  \\\n",
       "Infrastructure type Code                                             \n",
       "plant               F1_1_1                    curve  euro/facility   \n",
       "                    F1_1_2                    curve  euro/facility   \n",
       "                    F1_1_3                    curve  euro/facility   \n",
       "substation          F2_1_1                    curve  euro/facility   \n",
       "                    F2_1_2                    curve  euro/facility   \n",
       "                    F2_1_3                    curve  euro/facility   \n",
       "power_tower         F3_1_1                    curve  euro/facility   \n",
       "                    F3_1_2                    curve  euro/facility   \n",
       "power_pole          F4_1_1                    curve  euro/facility   \n",
       "                    F4_1_2                    curve  euro/facility   \n",
       "                    F4_1_3                    curve  euro/facility   \n",
       "                    F4_1_4                    curve  euro/facility   \n",
       "line                F5_1_1                    curve         euro/m   \n",
       "                    F5_1_2                    curve         euro/m   \n",
       "                    F5_1_3                    curve         euro/m   \n",
       "                    F5_1_4                    curve         euro/m   \n",
       "                    F5_1_5                    curve         euro/m   \n",
       "                    F5_1_6                    curve         euro/m   \n",
       "                    F5_1_7                    curve         euro/m   \n",
       "                    F5_1_8                    curve         euro/m   \n",
       "                    F5_1_9                    curve         euro/m   \n",
       "                    F5_1_10                   curve         euro/m   \n",
       "                    F5_1_11                   curve         euro/m   \n",
       "                    F5_1_12                   curve         euro/m   \n",
       "minor_line          F5_2                      curve         euro/m   \n",
       "cable               F5_3_1                    curve         euro/m   \n",
       "                    F5_3_2                    curve         euro/m   \n",
       "\n",
       "                                                          Specific occupancy  \\\n",
       "Infrastructure type Code                                                       \n",
       "plant               F1_1_1                                Small power plants   \n",
       "                    F1_1_2                               Medium power plants   \n",
       "                    F1_1_3                                Large power plants   \n",
       "substation          F2_1_1                                        low votage   \n",
       "                    F2_1_2                                     medium votage   \n",
       "                    F2_1_3                                       high votage   \n",
       "power_tower         F3_1_1                                               NaN   \n",
       "                    F3_1_2                                               NaN   \n",
       "power_pole          F4_1_1                                              wood   \n",
       "                    F4_1_2                                          concrete   \n",
       "                    F4_1_3                                    steel monopole   \n",
       "                    F4_1_4                                    steel monopole   \n",
       "line                F5_1_1                                              wood   \n",
       "                    F5_1_2                                              wood   \n",
       "                    F5_1_3                                              wood   \n",
       "                    F5_1_4                                              wood   \n",
       "                    F5_1_5                                              wood   \n",
       "                    F5_1_6                                              wood   \n",
       "                    F5_1_7                                              wood   \n",
       "                    F5_1_8                                              wood   \n",
       "                    F5_1_9                                              wood   \n",
       "                    F5_1_10                                             wood   \n",
       "                    F5_1_11                                             wood   \n",
       "                    F5_1_12                                             wood   \n",
       "minor_line          F5_2                                          minor line   \n",
       "cable               F5_3_1   cable: Distribution circuits elevated crossings   \n",
       "                    F5_3_2   cable: Distribution circuits elevated crossings   \n",
       "\n",
       "                            Cost type     Reference            MaxDam  \\\n",
       "Infrastructure type Code                                                \n",
       "plant               F1_1_1        NaN    FEMA, 2021   27318080.586376   \n",
       "                    F1_1_2        NaN    FEMA, 2021  137375405.247579   \n",
       "                    F1_1_3        NaN    FEMA, 2021  137375405.247579   \n",
       "substation          F2_1_1        NaN    FEMA, 2012    1785647.560022   \n",
       "                    F2_1_2        NaN    FEMA, 2012    3571295.120044   \n",
       "                    F2_1_3        NaN    FEMA, 2012    8928237.800111   \n",
       "power_tower         F3_1_1        NaN  Quanta, 2009       1622.348462   \n",
       "                    F3_1_2        NaN     ICF, 2002       5291.896085   \n",
       "power_pole          F4_1_1        NaN  Quanta, 2009        711.275927   \n",
       "                    F4_1_2        NaN  Quanta, 2009        925.603198   \n",
       "                    F4_1_3        NaN  Quanta, 2009       1230.747109   \n",
       "                    F4_1_4        NaN  Quanta, 2009        745.907339   \n",
       "line                F5_1_1        NaN     ICF, 2002         71.320209   \n",
       "                    F5_1_2        NaN     ICF, 2002          78.45223   \n",
       "                    F5_1_3        NaN     ICF, 2002         92.716272   \n",
       "                    F5_1_4        NaN     ICF, 2002        116.251941   \n",
       "                    F5_1_5        NaN     ICF, 2002        127.877262   \n",
       "                    F5_1_6        NaN     ICF, 2002        151.127481   \n",
       "                    F5_1_7        NaN     ICF, 2002          47.78454   \n",
       "                    F5_1_8        NaN     ICF, 2002         52.562867   \n",
       "                    F5_1_9        NaN     ICF, 2002         62.119945   \n",
       "                    F5_1_10       NaN     ICF, 2002         77.888975   \n",
       "                    F5_1_11       NaN     ICF, 2002         85.677702   \n",
       "                    F5_1_12       NaN     ICF, 2002        101.255582   \n",
       "minor_line          F5_2          NaN           NaN          47.78454   \n",
       "cable               F5_3_1        NaN     ICF, 2002        356.601046   \n",
       "                    F5_3_2        NaN     ICF, 2002        570.561673   \n",
       "\n",
       "                                     LowerDam          UpperDam  \n",
       "Infrastructure type Code                                         \n",
       "plant               F1_1_1    20488560.439782    34147600.73297  \n",
       "                    F1_1_2   103031553.935684  171719256.559473  \n",
       "                    F1_1_3   103031553.935684  171719256.559473  \n",
       "substation          F2_1_1     1339235.670017    2232059.450028  \n",
       "                    F2_1_2     2678471.340033    4464118.900055  \n",
       "                    F2_1_3     6696178.350083   11160297.250139  \n",
       "power_tower         F3_1_1        1216.761346       2027.935577  \n",
       "                    F3_1_2        3968.922064       6614.870106  \n",
       "power_pole          F4_1_1         533.456945        889.094908  \n",
       "                    F4_1_2         694.202398       1157.003997  \n",
       "                    F4_1_3         923.060332       1538.433886  \n",
       "                    F4_1_4         559.430504        932.384173  \n",
       "line                F5_1_1          53.490157         89.150261  \n",
       "                    F5_1_2          58.839173         98.065288  \n",
       "                    F5_1_3          69.537204         115.89534  \n",
       "                    F5_1_4          87.188956        145.314926  \n",
       "                    F5_1_5          95.907947        159.846578  \n",
       "                    F5_1_6         113.345611        188.909351  \n",
       "                    F5_1_7          35.838405         59.730675  \n",
       "                    F5_1_8           39.42215         65.703583  \n",
       "                    F5_1_9          46.589958         77.649931  \n",
       "                    F5_1_10         58.416731         97.361218  \n",
       "                    F5_1_11         64.258277        107.097128  \n",
       "                    F5_1_12         75.941686        126.569477  \n",
       "minor_line          F5_2            35.838405         59.730675  \n",
       "cable               F5_3_1         467.255688       9769.891665  \n",
       "                    F5_3_2         467.255688       9769.891665  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxdam = load_curves_maxdam('CHN',vul_curve_path,'fl')[1]\n",
    "maxdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1bf0e992-b4d1-46b0-a952-488ac8c5b2b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Type vulnerability data</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Specific occupancy</th>\n",
       "      <th>Cost type</th>\n",
       "      <th>Reference</th>\n",
       "      <th>MaxDam</th>\n",
       "      <th>LowerDam</th>\n",
       "      <th>UpperDam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infrastructure type</th>\n",
       "      <th>Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">plant</th>\n",
       "      <th>F1_1_1</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>Small power plants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2021</td>\n",
       "      <td>154165240.329434</td>\n",
       "      <td>115623930.247075</td>\n",
       "      <td>192706550.411792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_1_2</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>Medium power plants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2021</td>\n",
       "      <td>775256237.288818</td>\n",
       "      <td>581442177.966614</td>\n",
       "      <td>969070296.611023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_1_3</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>Large power plants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2021</td>\n",
       "      <td>775256237.288818</td>\n",
       "      <td>581442177.966614</td>\n",
       "      <td>969070296.611023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">substation</th>\n",
       "      <th>F2_1_1</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>low votage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2012</td>\n",
       "      <td>10077017.833082</td>\n",
       "      <td>7557763.374812</td>\n",
       "      <td>12596272.291353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2_1_2</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>medium votage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2012</td>\n",
       "      <td>20154035.666164</td>\n",
       "      <td>15115526.749623</td>\n",
       "      <td>25192544.582706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2_1_3</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>high votage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2012</td>\n",
       "      <td>50385089.165411</td>\n",
       "      <td>37788816.874058</td>\n",
       "      <td>62981361.456764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">power_tower</th>\n",
       "      <th>F3_1_1</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quanta, 2009</td>\n",
       "      <td>9155.465359</td>\n",
       "      <td>6866.59902</td>\n",
       "      <td>11444.331699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F3_1_2</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>29863.973392</td>\n",
       "      <td>22397.980044</td>\n",
       "      <td>37329.96674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">power_pole</th>\n",
       "      <th>F4_1_1</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quanta, 2009</td>\n",
       "      <td>4013.972498</td>\n",
       "      <td>3010.479373</td>\n",
       "      <td>5017.465622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F4_1_2</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>concrete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quanta, 2009</td>\n",
       "      <td>5223.494343</td>\n",
       "      <td>3917.620757</td>\n",
       "      <td>6529.367929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F4_1_3</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>steel monopole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quanta, 2009</td>\n",
       "      <td>6945.525445</td>\n",
       "      <td>5209.144084</td>\n",
       "      <td>8681.906806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F4_1_4</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>steel monopole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quanta, 2009</td>\n",
       "      <td>4209.409361</td>\n",
       "      <td>3157.057021</td>\n",
       "      <td>5261.761701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">line</th>\n",
       "      <th>F5_1_1</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>136.361664</td>\n",
       "      <td>102.271248</td>\n",
       "      <td>170.45208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_2</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>149.99783</td>\n",
       "      <td>112.498373</td>\n",
       "      <td>187.497288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_3</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>177.270163</td>\n",
       "      <td>132.952622</td>\n",
       "      <td>221.587704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_4</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>222.269512</td>\n",
       "      <td>166.702134</td>\n",
       "      <td>277.83689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_5</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>244.496707</td>\n",
       "      <td>183.37253</td>\n",
       "      <td>305.620884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_6</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>288.950285</td>\n",
       "      <td>216.712714</td>\n",
       "      <td>361.187856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_7</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>91.362315</td>\n",
       "      <td>68.521736</td>\n",
       "      <td>114.202894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_8</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>100.498303</td>\n",
       "      <td>75.373727</td>\n",
       "      <td>125.622878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_9</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>118.771091</td>\n",
       "      <td>89.078318</td>\n",
       "      <td>148.463863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_10</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>148.920906</td>\n",
       "      <td>111.69068</td>\n",
       "      <td>186.151133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_11</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>163.812672</td>\n",
       "      <td>122.859504</td>\n",
       "      <td>204.76584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_1_12</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>193.597016</td>\n",
       "      <td>145.197762</td>\n",
       "      <td>241.99627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minor_line</th>\n",
       "      <th>F5_2</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>minor line</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.362315</td>\n",
       "      <td>68.521736</td>\n",
       "      <td>114.202894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cable</th>\n",
       "      <th>F5_3_1</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>cable: Distribution circuits elevated crossings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>681.80832</td>\n",
       "      <td>893.376</td>\n",
       "      <td>18679.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5_3_2</th>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>cable: Distribution circuits elevated crossings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICF, 2002</td>\n",
       "      <td>1090.893312</td>\n",
       "      <td>893.376</td>\n",
       "      <td>18679.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Type vulnerability data           Unit  \\\n",
       "Infrastructure type Code                                             \n",
       "plant               F1_1_1                    curve  euro/facility   \n",
       "                    F1_1_2                    curve  euro/facility   \n",
       "                    F1_1_3                    curve  euro/facility   \n",
       "substation          F2_1_1                    curve  euro/facility   \n",
       "                    F2_1_2                    curve  euro/facility   \n",
       "                    F2_1_3                    curve  euro/facility   \n",
       "power_tower         F3_1_1                    curve  euro/facility   \n",
       "                    F3_1_2                    curve  euro/facility   \n",
       "power_pole          F4_1_1                    curve  euro/facility   \n",
       "                    F4_1_2                    curve  euro/facility   \n",
       "                    F4_1_3                    curve  euro/facility   \n",
       "                    F4_1_4                    curve  euro/facility   \n",
       "line                F5_1_1                    curve         euro/m   \n",
       "                    F5_1_2                    curve         euro/m   \n",
       "                    F5_1_3                    curve         euro/m   \n",
       "                    F5_1_4                    curve         euro/m   \n",
       "                    F5_1_5                    curve         euro/m   \n",
       "                    F5_1_6                    curve         euro/m   \n",
       "                    F5_1_7                    curve         euro/m   \n",
       "                    F5_1_8                    curve         euro/m   \n",
       "                    F5_1_9                    curve         euro/m   \n",
       "                    F5_1_10                   curve         euro/m   \n",
       "                    F5_1_11                   curve         euro/m   \n",
       "                    F5_1_12                   curve         euro/m   \n",
       "minor_line          F5_2                      curve         euro/m   \n",
       "cable               F5_3_1                    curve         euro/m   \n",
       "                    F5_3_2                    curve         euro/m   \n",
       "\n",
       "                                                          Specific occupancy  \\\n",
       "Infrastructure type Code                                                       \n",
       "plant               F1_1_1                                Small power plants   \n",
       "                    F1_1_2                               Medium power plants   \n",
       "                    F1_1_3                                Large power plants   \n",
       "substation          F2_1_1                                        low votage   \n",
       "                    F2_1_2                                     medium votage   \n",
       "                    F2_1_3                                       high votage   \n",
       "power_tower         F3_1_1                                               NaN   \n",
       "                    F3_1_2                                               NaN   \n",
       "power_pole          F4_1_1                                              wood   \n",
       "                    F4_1_2                                          concrete   \n",
       "                    F4_1_3                                    steel monopole   \n",
       "                    F4_1_4                                    steel monopole   \n",
       "line                F5_1_1                                              wood   \n",
       "                    F5_1_2                                              wood   \n",
       "                    F5_1_3                                              wood   \n",
       "                    F5_1_4                                              wood   \n",
       "                    F5_1_5                                              wood   \n",
       "                    F5_1_6                                              wood   \n",
       "                    F5_1_7                                              wood   \n",
       "                    F5_1_8                                              wood   \n",
       "                    F5_1_9                                              wood   \n",
       "                    F5_1_10                                             wood   \n",
       "                    F5_1_11                                             wood   \n",
       "                    F5_1_12                                             wood   \n",
       "minor_line          F5_2                                          minor line   \n",
       "cable               F5_3_1   cable: Distribution circuits elevated crossings   \n",
       "                    F5_3_2   cable: Distribution circuits elevated crossings   \n",
       "\n",
       "                            Cost type     Reference            MaxDam  \\\n",
       "Infrastructure type Code                                                \n",
       "plant               F1_1_1        NaN    FEMA, 2021  154165240.329434   \n",
       "                    F1_1_2        NaN    FEMA, 2021  775256237.288818   \n",
       "                    F1_1_3        NaN    FEMA, 2021  775256237.288818   \n",
       "substation          F2_1_1        NaN    FEMA, 2012   10077017.833082   \n",
       "                    F2_1_2        NaN    FEMA, 2012   20154035.666164   \n",
       "                    F2_1_3        NaN    FEMA, 2012   50385089.165411   \n",
       "power_tower         F3_1_1        NaN  Quanta, 2009       9155.465359   \n",
       "                    F3_1_2        NaN     ICF, 2002      29863.973392   \n",
       "power_pole          F4_1_1        NaN  Quanta, 2009       4013.972498   \n",
       "                    F4_1_2        NaN  Quanta, 2009       5223.494343   \n",
       "                    F4_1_3        NaN  Quanta, 2009       6945.525445   \n",
       "                    F4_1_4        NaN  Quanta, 2009       4209.409361   \n",
       "line                F5_1_1        NaN     ICF, 2002        136.361664   \n",
       "                    F5_1_2        NaN     ICF, 2002         149.99783   \n",
       "                    F5_1_3        NaN     ICF, 2002        177.270163   \n",
       "                    F5_1_4        NaN     ICF, 2002        222.269512   \n",
       "                    F5_1_5        NaN     ICF, 2002        244.496707   \n",
       "                    F5_1_6        NaN     ICF, 2002        288.950285   \n",
       "                    F5_1_7        NaN     ICF, 2002         91.362315   \n",
       "                    F5_1_8        NaN     ICF, 2002        100.498303   \n",
       "                    F5_1_9        NaN     ICF, 2002        118.771091   \n",
       "                    F5_1_10       NaN     ICF, 2002        148.920906   \n",
       "                    F5_1_11       NaN     ICF, 2002        163.812672   \n",
       "                    F5_1_12       NaN     ICF, 2002        193.597016   \n",
       "minor_line          F5_2          NaN           NaN         91.362315   \n",
       "cable               F5_3_1        NaN     ICF, 2002         681.80832   \n",
       "                    F5_3_2        NaN     ICF, 2002       1090.893312   \n",
       "\n",
       "                                     LowerDam          UpperDam  \n",
       "Infrastructure type Code                                         \n",
       "plant               F1_1_1   115623930.247075  192706550.411792  \n",
       "                    F1_1_2   581442177.966614  969070296.611023  \n",
       "                    F1_1_3   581442177.966614  969070296.611023  \n",
       "substation          F2_1_1     7557763.374812   12596272.291353  \n",
       "                    F2_1_2    15115526.749623   25192544.582706  \n",
       "                    F2_1_3    37788816.874058   62981361.456764  \n",
       "power_tower         F3_1_1         6866.59902      11444.331699  \n",
       "                    F3_1_2       22397.980044       37329.96674  \n",
       "power_pole          F4_1_1        3010.479373       5017.465622  \n",
       "                    F4_1_2        3917.620757       6529.367929  \n",
       "                    F4_1_3        5209.144084       8681.906806  \n",
       "                    F4_1_4        3157.057021       5261.761701  \n",
       "line                F5_1_1         102.271248         170.45208  \n",
       "                    F5_1_2         112.498373        187.497288  \n",
       "                    F5_1_3         132.952622        221.587704  \n",
       "                    F5_1_4         166.702134         277.83689  \n",
       "                    F5_1_5          183.37253        305.620884  \n",
       "                    F5_1_6         216.712714        361.187856  \n",
       "                    F5_1_7          68.521736        114.202894  \n",
       "                    F5_1_8          75.373727        125.622878  \n",
       "                    F5_1_9          89.078318        148.463863  \n",
       "                    F5_1_10         111.69068        186.151133  \n",
       "                    F5_1_11        122.859504         204.76584  \n",
       "                    F5_1_12        145.197762         241.99627  \n",
       "minor_line          F5_2            68.521736        114.202894  \n",
       "cable               F5_3_1            893.376          18679.68  \n",
       "                    F5_3_2            893.376          18679.68  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxdam_old = load_curves_maxdam(vul_curve_path,'fl')[1]\n",
    "maxdam_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9896d9f-4592-4552-8876-c1340f3e09f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_storm_data(climate_model,basin,bbox):\n",
    "    \"\"\"\n",
    "    Load storm data from a NetCDF file and process it to return a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - climate_model (str): name of the climate model\n",
    "    - basin (str): name of the basin\n",
    "    - bbox (tuple): bounding box coordinates in the format (minx, miny, maxx, maxy)\n",
    "    - ne_crs (str): CRS string of the North-East projection\n",
    "\n",
    "    Returns:\n",
    "    - df_ds (pd.DataFrame): pandas DataFrame with interpolated wind speeds for different return periods and geometry column\n",
    "    \"\"\"\n",
    "    # set paths\n",
    "    # data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "\n",
    "    filename = os.path.join(tc_path, f'STORM_FIXED_RETURN_PERIODS{climate_model}_{basin}.nc')\n",
    "    \n",
    "    # load data from NetCDF file\n",
    "    with xr.open_dataset(filename) as ds:\n",
    "        \n",
    "        # convert data to WGS84 CRS\n",
    "        ds.rio.write_crs(4326, inplace=True)\n",
    "        ds = ds.rio.clip_box(minx=bbox[0], miny=bbox[1], maxx=bbox[2], maxy=bbox[3])\n",
    "        \n",
    "        #convert 10-min sustained wind speed to 3-s gust wind speed\n",
    "        ds['mean_3s'] = ds['mean']/0.88*1.11\n",
    "\n",
    "        # get the mean values\n",
    "        df_ds = ds['mean_3s'].to_dataframe().unstack(level=2).reset_index()\n",
    "\n",
    "        # create geometry values and drop lat lon columns\n",
    "        df_ds['geometry'] = [pygeos.points(x) for x in list(zip(df_ds['lon'], df_ds['lat']))]\n",
    "        df_ds = df_ds.drop(['lat', 'lon'], axis=1, level=0)\n",
    "        \n",
    "        # interpolate wind speeds of 1,2,5,25,and 250-yr return period\n",
    "        ## rename columns to return periods (must be integer for interpolating)\n",
    "        df_ds_geometry = pd.DataFrame()\n",
    "        df_ds_geometry['geometry'] = df_ds['geometry']\n",
    "        df_ds = df_ds.drop(['geometry'], axis=1, level=0)\n",
    "        df_ds = df_ds['mean_3s']\n",
    "        df_ds.columns = [int(x) for x in ds['mean_3s']['rp']]\n",
    "        df_ds[1] = np.nan\n",
    "        df_ds[2] = np.nan\n",
    "        df_ds[5] = np.nan\n",
    "        df_ds[25] = np.nan\n",
    "        df_ds[250] = np.nan\n",
    "        df_ds = df_ds.reindex(sorted(df_ds.columns), axis=1)\n",
    "        df_ds = df_ds.interpolate(method='pchip', axis=1, limit_direction='both')\n",
    "        df_ds['geometry'] = df_ds_geometry['geometry']\n",
    "        df_ds = df_ds[[1, 2, 5, 10, 25, 50, 100, 250, 500, 1000, 'geometry']]\n",
    "        \n",
    "        # rename columns to return periods\n",
    "        df_ds.columns = ['1_{}{}'.format(int(x), climate_model) for x in [1, 2, 5, 10, 25, 50, 100, 250, 500, 1000]] +['geometry']\n",
    "        df_ds['geometry'] = pygeos.buffer(df_ds.geometry, radius=0.1/2, cap_style='square').values\n",
    "        \n",
    "        # reproject the geometry column to the specified CRS\n",
    "        df_ds['geometry'] = reproject(df_ds)\n",
    "            \n",
    "        # drop all non values to reduce size\n",
    "        #df_ds = df_ds.loc[~df_ds['1_10000{}'.format(climate_model)].isna()].reset_index(drop=True)\n",
    "        df_ds = df_ds.fillna(0)\n",
    "\n",
    "    return df_ds\n",
    "\n",
    "def open_storm_data(country_code):\n",
    "    \"\"\"\n",
    "    This function loads STORM data for a given country code, clips it based on the country geometry,\n",
    "    and combines data from different basins and climate models.\n",
    "\n",
    "    Args:\n",
    "    - country_code (str): a 3-letter ISO code of the country of interest\n",
    "\n",
    "    Returns:\n",
    "    - df_ds (dict): a dictionary containing STORM data for different climate models, organized by basin\n",
    "    \"\"\"\n",
    "    # set paths\n",
    "    # data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "    \n",
    "    # list of available climate models\n",
    "    climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "\n",
    "    # dictionary of basins for each country\n",
    "    country_basin = {\n",
    "        \"BRN\": [\"WP\"],\n",
    "        \"KHM\": [\"WP\"],\n",
    "        \"CHN\": [\"WP\", \"NI\"],\n",
    "        \"IDN\": [\"SI\", \"SP\", \"NI\", \"WP\"],\n",
    "        \"JPN\": [\"WP\"],\n",
    "        \"LAO\": [\"WP\"],\n",
    "        \"MYS\": [\"WP\", \"NI\"],\n",
    "        \"MNG\": [\"WP\", \"NI\"],\n",
    "        \"MMR\": [\"NI\", \"WP\"],\n",
    "        \"PRK\": [\"WP\"],\n",
    "        \"PHL\": [\"WP\"],\n",
    "        \"SGP\": [\"WP\"],\n",
    "        \"KOR\": [\"WP\"],\n",
    "        \"TWN\": [\"WP\"],\n",
    "        \"THA\": [\"WP\", \"NI\"],\n",
    "        \"VNM\": [\"WP\"]\n",
    "    }\n",
    "\n",
    "    # load country geometry file and create geometry to clip\n",
    "    ne_countries = gpd.read_file(os.path.join(data_path,'..',\"natural_earth\",\"ne_10m_admin_0_countries.shp\"))\n",
    "    bbox = ne_countries.loc[ne_countries['ISO_A3']==country_code].geometry.buffer(1).values[0].bounds\n",
    "    # ne_countries = gpd.read_file('C:/Users/mye500/OneDrive - Vrije Universiteit Amsterdam/01_Research-Projects/01_risk_assessment/base_map/base_map_adm_0.gpkg')\n",
    "    # bbox = ne_countries.loc[ne_countries['GID_0']==country_code].geometry.buffer(1).values[0].bounds\n",
    "\n",
    "    df_ds = {}\n",
    "    for climate_model in climate_models:\n",
    "        concat_prep = []\n",
    "\n",
    "        #combine STORM data from different basins\n",
    "        if \"WP\" in country_basin[country_code]:\n",
    "            WP = load_storm_data(climate_model,'WP',bbox)\n",
    "            concat_prep.append(WP)\n",
    "        if \"SP\" in country_basin[country_code]:\n",
    "            SP = load_storm_data(climate_model,'SP',bbox)\n",
    "            concat_prep.append(SP)\n",
    "        if \"NI\" in country_basin[country_code]:            \n",
    "            NI = load_storm_data(climate_model,'NI',bbox)\n",
    "            concat_prep.append(NI)            \n",
    "        if \"SI\" in country_basin[country_code]:       \n",
    "            SI = load_storm_data(climate_model,'SI',bbox)\n",
    "            concat_prep.append(SI)            \n",
    "                   \n",
    "        df_ds_cl = pd.concat(concat_prep, keys=country_basin[country_code])\n",
    "        df_ds_cl = df_ds_cl.reset_index(drop=True)\n",
    "        df_ds[climate_model] = df_ds_cl\n",
    "\n",
    "    return df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67f24e70-2570-4b51-b5a2-d238b74abba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twn_wind = open_storm_data('TWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e9b1fa7-e368-4f50-a046-0ee32690bad2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.77332750074388"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ne\n",
    "twn_wind['_CMCC-CM2-VHR4']['1_1_CMCC-CM2-VHR4'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6b43b71-49ee-4aee-aca7-db18ecbd8b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.77332750074388"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gdam\n",
    "twn_wind('TWN')['_CMCC-CM2-VHR4']#['1_1_CMCC-CM2-VHR4'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c7ff6dd-a3f2-4e2a-becd-e5cffa38edde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clip_flood_data(country_code):\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "\n",
    "    # load country geometry file and create geometry to clip\n",
    "    ne_countries = gpd.read_file(ne_path)\n",
    "    geometry = ne_countries.loc[ne_countries['ISO_A3']==country_code].geometry.values[0]\n",
    "    geoms = [mapping(geometry)]\n",
    "    \n",
    "    #climate_model: historical, rcp4p5, rcp8p5; time_period: hist, 2030, 2050, 2080\n",
    "    rps = ['0001','0002','0005','0010','0025','0050','0100','0250','0500','1000']\n",
    "    climate_models = ['historical','rcp8p5']\n",
    "    \n",
    "    for rp in rps:\n",
    "        #global input_file\n",
    "        for climate_model in climate_models:\n",
    "            if climate_model=='historical':\n",
    "                input_file = os.path.join(fl_path,'global',\n",
    "                                          'inuncoast_{}_nosub_hist_rp{}_0.tif'.format(climate_model,rp)) \n",
    " \n",
    "            elif climate_model=='rcp8p5':\n",
    "                input_file = os.path.join(fl_path,'global',\n",
    "                                          'inuncoast_{}_nosub_2030_rp{}_0.tif'.format(climate_model,rp))\n",
    "\n",
    "            # load raster file and save clipped version\n",
    "            with rasterio.open(input_file) as src:\n",
    "                out_image, out_transform = mask(src, geoms, crop=True)\n",
    "                out_meta = src.meta\n",
    "\n",
    "                out_meta.update({\"driver\": \"GTiff\",\n",
    "                         \"height\": out_image.shape[1],\n",
    "                         \"width\": out_image.shape[2],\n",
    "                         \"transform\": out_transform})\n",
    "\n",
    "                if 'scistor' in fl_path:\n",
    "                    file_path = os.path.join(fl_path,'country','_'.join([country_code]+input_file.split('_')[6:]))\n",
    "                else:\n",
    "                    file_path = os.path.join(fl_path,'country','_'.join([country_code]+input_file.split('_')[3:]))\n",
    "\n",
    "                with rasterio.open(file_path, \"w\", **out_meta) as dest:\n",
    "                    dest.write(out_image)\n",
    "\n",
    "def load_flood_data(country_code,climate_model):\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "     \n",
    "    rps = ['0001','0002','0005','0010','0025','0050','0100','0250','0500','1000']\n",
    "    collect_df_ds = []\n",
    "    \n",
    "    if climate_model=='historical':\n",
    "        print('Loading historical coastal flood data ...')\n",
    "        for rp in rps:\n",
    "            #for file in files:\n",
    "            file_path = os.path.join(fl_path,'country','{}_{}_nosub_hist_rp{}_0.tif'.format(country_code,climate_model,rp))\n",
    "            with xr.open_dataset(file_path) as ds: #, engine=\"rasterio\"\n",
    "                df_ds = ds.to_dataframe().reset_index()\n",
    "                df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "                df_ds = df_ds.rename(columns={'band_data': 'rp'+rp}) #rename to return period\n",
    "                \n",
    "                # move from meters to centimeters\n",
    "                df_ds['rp'+rp] = (df_ds['rp'+rp]*100)         \n",
    "                df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "                df_ds = df_ds.dropna()\n",
    "                df_ds = df_ds.reset_index(drop=True)\n",
    "                df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=0.0089932/2,cap_style='square').values  # the original value here is 0.00833???\n",
    "                df_ds['geometry'] = reproject(df_ds)\n",
    "                collect_df_ds.append(df_ds)\n",
    "\n",
    "        df_all = collect_df_ds[0].merge(collect_df_ds[1]).merge(collect_df_ds[2]).merge(collect_df_ds[3]).merge(collect_df_ds[4])\\\n",
    "                 .merge(collect_df_ds[5]).merge(collect_df_ds[6]).merge(collect_df_ds[7]).merge(collect_df_ds[8]).merge(collect_df_ds[9])\n",
    "        df_all = df_all.loc[df_all['rp1000']>0].reset_index(drop=True)\n",
    "\n",
    "    elif climate_model=='rcp8p5':\n",
    "        print('Loading future coastal flood data ...')\n",
    "        for rp in rps:\n",
    "            #for file in files:\n",
    "            file_path = os.path.join(fl_path,'country','{}_{}_nosub_2030_rp{}_0.tif'.format(country_code,climate_model,rp))\n",
    "            with xr.open_dataset(file_path) as ds: #, engine=\"rasterio\"\n",
    "                df_ds = ds.to_dataframe().reset_index()\n",
    "                df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "                df_ds = df_ds.rename(columns={'band_data': 'rp'+rp}) #rename to return period\n",
    "                df_ds['rp'+rp] = (df_ds['rp'+rp]*100)\n",
    "                df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "                df_ds = df_ds.dropna()\n",
    "                df_ds = df_ds.reset_index(drop=True)\n",
    "                df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=0.00833/2,cap_style='square').values\n",
    "                df_ds['geometry'] = reproject(df_ds)\n",
    "                collect_df_ds.append(df_ds)\n",
    "\n",
    "        df_all = collect_df_ds[0].merge(collect_df_ds[1]).merge(collect_df_ds[2]).merge(collect_df_ds[3]).merge(collect_df_ds[4])\\\n",
    "                 .merge(collect_df_ds[5]).merge(collect_df_ds[6]).merge(collect_df_ds[7]).merge(collect_df_ds[8]).merge(collect_df_ds[9])\n",
    "\n",
    "        df_all = df_all.loc[df_all['rp1000']>0].reset_index(drop=True)\n",
    "    return df_all\n",
    "\n",
    "def open_flood_data(country_code):\n",
    "    climate_models = ['historical','rcp8p5']\n",
    "    df_ds = {}\n",
    "    for climate_model in climate_models:\n",
    "        df_ds_sc = load_flood_data(country_code,climate_model)\n",
    "        df_ds[climate_model] = df_ds_sc\n",
    "    \n",
    "    return df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2160cb1f-75ac-48f0-898e-6fdcb8bb3b59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clip_flood_data('KHM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5ac9f48-e434-4893-8c04-07e663921d94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n",
      "CPU times: total: 3min 57s\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "phl_flood = open_flood_data('PHL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a7afcc-11b5-47da-8ffc-bdb9a28134eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    }
   ],
   "source": [
    "khm_flood = open_flood_data('KHM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3de688-606c-4dd2-abe3-f37015c7442e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OSM data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "934161b6-5f01-4315-87b3-9e4a7bd70876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_osm_infrastructure(country_code,osm_data_path):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        country_code (_type_): _description_\n",
    "        osm_data_path (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "    \n",
    "    # lines\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    osm_lines = power_polyline(osm_path)\n",
    "    osm_lines['geometry'] = reproject(osm_lines)\n",
    "    osm_lines = buffer_assets(osm_lines.loc[osm_lines.asset.isin(\n",
    "        ['cable','minor_cable','line','minor_line'])],buffer_size=100).reset_index(drop=True)\n",
    "    \n",
    "    # polygons\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    osm_polygons = electricity(osm_path)\n",
    "    osm_polygons['geometry'] = reproject(osm_polygons)\n",
    "    \n",
    "    # points\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    osm_points = power_point(osm_path)\n",
    "    osm_points['geometry'] = reproject(osm_points)\n",
    "    osm_points = buffer_assets(osm_points.loc[osm_points.asset.isin(\n",
    "        ['power_tower','power_pole'])],buffer_size=100).reset_index(drop=True)\n",
    "    \n",
    "    return osm_lines,osm_polygons,osm_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b16fbb7a-d740-4b39-bfdd-127321fb4cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|| 8145/8145 [00:31<00:00, 259.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|| 365/365 [02:54<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['substation' 'plant']\n",
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|| 440360/440360 [00:46<00:00, 9499.69it/s]\n"
     ]
    }
   ],
   "source": [
    "osm_power_infra = extract_osm_infrastructure('PHL',osm_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abb7a943-1950-445c-8328-f6db95b7f163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def assess_damage_osm(country_code,osm_power_infra,hazard_type):\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "\n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(vul_curve_path,hazard_type)\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    osm_lines,osm_poly,osm_points = osm_power_infra\n",
    "    #print(osm_lines['asset'].unique())\n",
    "    \n",
    "    #calculate damaged lines/polygons/points in loop by climate_model\n",
    "    damaged_lines = {}\n",
    "    damaged_poly = {}\n",
    "    damaged_points = {}\n",
    "\n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = ['','_CMCC-CM2-VHR4'] #,'_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM'\n",
    "        df_ds = open_storm_data(country_code)\n",
    "\n",
    "        # remove assets that will not have any damage\n",
    "        osm_lines = osm_lines.loc[osm_lines.asset != 'cable'].reset_index(drop=True)\n",
    "        osm_lines['asset'] = osm_lines['asset'].replace(['minor_line'], 'line')\n",
    "        osm_poly = osm_poly.loc[osm_poly.asset != 'plant'].reset_index(drop=True)\n",
    "        \n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),'1_10{}'.format(climate_model),\n",
    "                              '1_25{}'.format(climate_model),'1_50{}'.format(climate_model),'1_100{}'.format(climate_model),\n",
    "                              '1_250{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "            \n",
    "            # assess damage for lines\n",
    "            overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_lines).T,\n",
    "                                         columns=['asset','hazard_point'])\n",
    "\n",
    "            if len(overlay_lines) == 0:\n",
    "                damaged_lines[climate_model] = pd.DataFrame()\n",
    "\n",
    "            else:\n",
    "                collect_line_damages = []\n",
    "                for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                                  desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                    for return_period in return_periods:\n",
    "                        collect_line_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                                df_ds[climate_model],\n",
    "                                                                                osm_lines,\n",
    "                                                                                curves,\n",
    "                                                                                maxdam,\n",
    "                                                                                return_period,\n",
    "                                                                                country_code))\n",
    "\n",
    "                get_asset_type_line = dict(zip(osm_lines.index,osm_lines.asset))\n",
    "                results = pd.DataFrame([item for sublist in collect_line_damages\n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "                damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "            # assess damage for polygons\n",
    "            if len(osm_poly) > 0:\n",
    "                overlay_poly = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_poly).T,\n",
    "                                        columns=['asset','hazard_point'])\n",
    "            else:\n",
    "                overlay_poly = pd.DataFrame()\n",
    "\n",
    "            if len(overlay_poly) == 0:\n",
    "                damaged_poly[climate_model] = pd.DataFrame()\n",
    "\n",
    "            else:\n",
    "                collect_poly_damages = []\n",
    "                for asset in tqdm(overlay_poly.groupby('asset'),total=len(overlay_poly.asset.unique()),\n",
    "                                  desc='polygon damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                    for return_period in return_periods:\n",
    "                        collect_poly_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                                df_ds[climate_model],\n",
    "                                                                                osm_poly,\n",
    "                                                                                curves,\n",
    "                                                                                maxdam,\n",
    "                                                                                return_period,\n",
    "                                                                                country_code))\n",
    "\n",
    "                get_asset_type_poly = dict(zip(osm_poly.index,osm_poly.asset))\n",
    "                \n",
    "                results = pd.DataFrame([item for sublist in collect_poly_damages \n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_poly[x])    \n",
    "\n",
    "                damaged_poly[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "            #assess damage for points\n",
    "            overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_points).T,\n",
    "                                          columns=['asset','hazard_point'])\n",
    "\n",
    "            if len(overlay_points) == 0:\n",
    "                damaged_points[climate_model] = pd.DataFrame()\n",
    "\n",
    "            else:\n",
    "                collect_point_damages = []\n",
    "                for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                                  desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                    for return_period in return_periods:\n",
    "                        collect_point_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                                df_ds[climate_model],\n",
    "                                                                                osm_points,\n",
    "                                                                                curves,\n",
    "                                                                                maxdam,\n",
    "                                                                                return_period,\n",
    "                                                                                country_code))\n",
    "\n",
    "                get_asset_type_point = dict(zip(osm_points.index,osm_points.asset))\n",
    "                \n",
    "                results = pd.DataFrame([item for sublist in collect_point_damages\n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_point[x])    \n",
    "\n",
    "                damaged_points[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "\n",
    "    elif hazard_type=='fl':\n",
    "        # read flood data\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "        df_ds = open_flood_data(country_code)\n",
    "    \n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000'] \n",
    "\n",
    "            # assess damage for lines\n",
    "            overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_lines).T,\n",
    "                                         columns=['asset','hazard_point'])\n",
    "\n",
    "            if len(overlay_lines) == 0:\n",
    "                damaged_lines[climate_model] = pd.DataFrame()\n",
    "\n",
    "            else:\n",
    "                collect_line_damages = []\n",
    "                for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                                  desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                    for return_period in return_periods:\n",
    "                        collect_line_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                                df_ds[climate_model],\n",
    "                                                                                osm_lines,\n",
    "                                                                                curves,\n",
    "                                                                                maxdam,\n",
    "                                                                                return_period,\n",
    "                                                                                country_code))\n",
    "\n",
    "                get_asset_type_line = dict(zip(osm_lines.index,osm_lines.asset))\n",
    "                results = pd.DataFrame(collect_line_damages,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                \n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "                #sum damage of line, cable, and minor_line\n",
    "                results['curve'] = results['curve'].replace(['cable', 'minor_line'], 'line')\n",
    "                results['asset_type'] = results['asset_type'].replace(['cable', 'minor_line'], 'line')\n",
    "\n",
    "                damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "            # assess damage for polygons\n",
    "            if len(osm_poly) > 0:\n",
    "                overlay_poly = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_poly).T,\n",
    "                                        columns=['asset','hazard_point'])\n",
    "            else:\n",
    "                overlay_poly = pd.DataFrame()\n",
    "\n",
    "            if len(overlay_poly) == 0:\n",
    "                damaged_poly[climate_model] = pd.DataFrame()\n",
    "\n",
    "            else:\n",
    "                collect_poly_damages = []\n",
    "                for asset in tqdm(overlay_poly.groupby('asset'),total=len(overlay_poly.asset.unique()),\n",
    "                                  desc='polygon damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                    for return_period in return_periods:\n",
    "                        collect_poly_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                                df_ds[climate_model],\n",
    "                                                                                osm_poly,\n",
    "                                                                                curves,\n",
    "                                                                                maxdam,\n",
    "                                                                                return_period,\n",
    "                                                                                country_code))\n",
    "\n",
    "                get_asset_type_poly = dict(zip(osm_poly.index,osm_poly.asset))\n",
    "                               \n",
    "                #results = pd.DataFrame(collect_poly_damages ,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                results = pd.DataFrame([item for sublist in collect_poly_damages \n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                \n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_poly[x])    \n",
    "\n",
    "                damaged_poly[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "            # assess damage for points\n",
    "            overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_points).T,\n",
    "                                          columns=['asset','hazard_point'])\n",
    "\n",
    "            if len(overlay_points) == 0:\n",
    "                damaged_points[climate_model] = pd.DataFrame()\n",
    "\n",
    "            else:\n",
    "                collect_point_damages = []\n",
    "                for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                                  desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                    for return_period in return_periods:\n",
    "                        collect_point_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                                df_ds[climate_model],\n",
    "                                                                                osm_points,\n",
    "                                                                                curves,\n",
    "                                                                                maxdam,\n",
    "                                                                                return_period,\n",
    "                                                                                country_code))\n",
    "\n",
    "                get_asset_type_point = dict(zip(osm_points.index,osm_points.asset))\n",
    "                \n",
    "               \n",
    "                #results = pd.DataFrame(collect_point_damages ,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                \n",
    "                results = pd.DataFrame(np.array(list(flatten(collect_point_damages))).reshape(\n",
    "                    int(len(list(flatten(collect_point_damages)))/6), 6),\n",
    "                                       columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                \n",
    "                results['asset'] = results['asset'].astype(int)\n",
    "                results[['meandam','lowerdam','upperdam']] = results[['meandam','lowerdam','upperdam']].astype(float)\n",
    "                \n",
    "                #return collect_point_damages,get_asset_type_point\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_point[x])    \n",
    "\n",
    "                damaged_points[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "    return damaged_lines,damaged_poly,damaged_points\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "de54851e-4aaa-4e38-88fc-a27efb33c918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#NEW VERSION!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "def assess_damage_osm(country_code,osm_power_infra,hazard_type):\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "\n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(country_code,vul_curve_path,hazard_type)\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    osm_lines,osm_poly,osm_points = osm_power_infra\n",
    "    #print(osm_lines['asset'].unique())\n",
    "    \n",
    "    #calculate damaged lines/polygons/points in loop by climate_model\n",
    "    damaged_lines = {}\n",
    "    damaged_poly = {}\n",
    "    damaged_points = {}\n",
    "\n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = ['','_CMCC-CM2-VHR4'] #,'_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM'\n",
    "        df_ds = open_storm_data(country_code)\n",
    "\n",
    "        # remove assets that will not have any damage\n",
    "        osm_lines = osm_lines.loc[osm_lines.asset != 'cable'].reset_index(drop=True)\n",
    "        osm_lines['asset'] = osm_lines['asset'].replace(['minor_line'], 'line')\n",
    "        osm_poly = osm_poly.loc[osm_poly.asset != 'plant'].reset_index(drop=True)            \n",
    "    \n",
    "    elif hazard_type=='fl':\n",
    "        # read flood data\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "        #df_ds = open_flood_data(country_code) #revise after test!!!!!!!!!!!!\n",
    "        df_ds = phl_flood\n",
    "        \n",
    "    for climate_model in climate_models:\n",
    "        if hazard_type=='tc':\n",
    "            return_periods = ['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),'1_10{}'.format(climate_model),\n",
    "                              '1_25{}'.format(climate_model),'1_50{}'.format(climate_model),'1_100{}'.format(climate_model),\n",
    "                              '1_250{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "        elif hazard_type == 'fl':\n",
    "            return_periods = ['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000']     \n",
    "    \n",
    "        # assess damage for lines\n",
    "        overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_lines).T,\n",
    "                                     columns=['asset','hazard_point'])\n",
    "\n",
    "        if len(overlay_lines) == 0:\n",
    "            damaged_lines[climate_model] = pd.DataFrame()\n",
    "\n",
    "        else:\n",
    "            collect_line_damages = []\n",
    "            for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                              desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_line_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                            df_ds[climate_model],\n",
    "                                                                            osm_lines,\n",
    "                                                                            curves,\n",
    "                                                                            maxdam,\n",
    "                                                                            return_period,\n",
    "                                                                            country_code))\n",
    "\n",
    "            get_asset_type_line = dict(zip(osm_lines.index,osm_lines.asset))\n",
    "            \n",
    "            if hazard_type == 'tc':\n",
    "                results = pd.DataFrame([item for sublist in collect_line_damages\n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "                damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "            elif hazard_type == 'fl':\n",
    "                #results = pd.DataFrame(collect_line_damages,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                results = pd.DataFrame(np.array(list(flatten(collect_line_damages))).reshape(\n",
    "                    int(len(list(flatten(collect_line_damages)))/6), 6),\n",
    "                                       columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                results['asset'] = results['asset'].astype(int)\n",
    "                results[['meandam','lowerdam','upperdam']] = results[['meandam','lowerdam','upperdam']].astype(float)\n",
    "                \n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "                #sum damage of line, cable, and minor_line\n",
    "                results['curve'] = results['curve'].replace(['cable', 'minor_line'], 'line')\n",
    "                results['asset_type'] = results['asset_type'].replace(['cable', 'minor_line'], 'line')\n",
    "\n",
    "                damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "                \n",
    "        # assess damage for polygons\n",
    "        if len(osm_poly) > 0:\n",
    "            overlay_poly = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_poly).T,\n",
    "                                    columns=['asset','hazard_point'])\n",
    "        else:\n",
    "            overlay_poly = pd.DataFrame()\n",
    "\n",
    "        if len(overlay_poly) == 0:\n",
    "            damaged_poly[climate_model] = pd.DataFrame()\n",
    "\n",
    "        else:\n",
    "            collect_poly_damages = []\n",
    "            for asset in tqdm(overlay_poly.groupby('asset'),total=len(overlay_poly.asset.unique()),\n",
    "                              desc='polygon damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_poly_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                            df_ds[climate_model],\n",
    "                                                                            osm_poly,\n",
    "                                                                            curves,\n",
    "                                                                            maxdam,\n",
    "                                                                            return_period,\n",
    "                                                                            country_code))\n",
    "\n",
    "            get_asset_type_poly = dict(zip(osm_poly.index,osm_poly.asset))\n",
    "            \n",
    "            results = pd.DataFrame([item for sublist in collect_poly_damages \n",
    "                                    for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "            results['asset_type'] = results.asset.apply(lambda x : get_asset_type_poly[x])    \n",
    "\n",
    "            damaged_poly[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "                \n",
    "\n",
    "        #assess damage for points\n",
    "        overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_points).T,\n",
    "                                      columns=['asset','hazard_point'])\n",
    "\n",
    "        if len(overlay_points) == 0:\n",
    "            damaged_points[climate_model] = pd.DataFrame()\n",
    "\n",
    "        else:\n",
    "            collect_point_damages = []\n",
    "            for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                              desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_point_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                            df_ds[climate_model],\n",
    "                                                                            osm_points,\n",
    "                                                                            curves,\n",
    "                                                                            maxdam,\n",
    "                                                                            return_period,\n",
    "                                                                            country_code))\n",
    "\n",
    "            get_asset_type_point = dict(zip(osm_points.index,osm_points.asset))\n",
    "            \n",
    "            if hazard_type == 'tc':\n",
    "                results = pd.DataFrame([item for sublist in collect_point_damages\n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_point[x])    \n",
    "                \n",
    "                damaged_points[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "            \n",
    "            elif hazard_type == 'fl':\n",
    "                results = pd.DataFrame(np.array(list(flatten(collect_point_damages))).reshape(\n",
    "                    int(len(list(flatten(collect_point_damages)))/6), 6),\n",
    "                                       columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                results['asset'] = results['asset'].astype(int)\n",
    "                results[['meandam','lowerdam','upperdam']] = results[['meandam','lowerdam','upperdam']].astype(float)\n",
    "                \n",
    "                #return collect_point_damages,get_asset_type_point\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_point[x])    \n",
    "\n",
    "                damaged_points[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "    return damaged_lines,damaged_poly,damaged_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d355b5f-1ad4-4d91-b4a3-1506667bb7b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for PHL fl (historical): 100%|| 146/146 [00:19<00:00,  7.53it/s]\n",
      "polygon damage calculation for PHL fl (historical): 100%|| 7/7 [00:00<00:00,  7.38it/s]\n",
      "point damage calculation for PHL fl (historical): 100%|| 877/877 [00:40<00:00, 21.55it/s]\n",
      "polyline damage calculation for PHL fl (rcp8p5): 100%|| 133/133 [00:18<00:00,  7.22it/s]\n",
      "polygon damage calculation for PHL fl (rcp8p5): 100%|| 7/7 [00:00<00:00,  7.31it/s]\n",
      "point damage calculation for PHL fl (rcp8p5): 100%|| 877/877 [00:41<00:00, 21.14it/s]\n"
     ]
    }
   ],
   "source": [
    "osm_damage_infra = assess_damage_osm('PHL',osm_power_infra,'fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ed54a7-7634-44ec-b0e9-c37718656cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "osm_damage_infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "313d91ab-0996-4aa6-8de6-49b0cb2bf424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rp</th>\n",
       "      <th>curve</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>meandam</th>\n",
       "      <th>lowerdam</th>\n",
       "      <th>upperdam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>W2_1_1</td>\n",
       "      <td>substation</td>\n",
       "      <td>2.396356e+08</td>\n",
       "      <td>1.797267e+08</td>\n",
       "      <td>2.995445e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>W2_1_2</td>\n",
       "      <td>substation</td>\n",
       "      <td>4.792712e+08</td>\n",
       "      <td>3.594534e+08</td>\n",
       "      <td>5.990890e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>W2_1_3</td>\n",
       "      <td>substation</td>\n",
       "      <td>1.198178e+09</td>\n",
       "      <td>8.986336e+08</td>\n",
       "      <td>1.497723e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>W2_2_1</td>\n",
       "      <td>substation</td>\n",
       "      <td>2.047256e+08</td>\n",
       "      <td>1.535442e+08</td>\n",
       "      <td>2.559070e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>W2_2_2</td>\n",
       "      <td>substation</td>\n",
       "      <td>4.094511e+08</td>\n",
       "      <td>3.070884e+08</td>\n",
       "      <td>5.118139e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.200</td>\n",
       "      <td>W2_6_2</td>\n",
       "      <td>substation</td>\n",
       "      <td>1.817048e+08</td>\n",
       "      <td>1.362786e+08</td>\n",
       "      <td>2.271310e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.200</td>\n",
       "      <td>W2_6_3</td>\n",
       "      <td>substation</td>\n",
       "      <td>4.542620e+08</td>\n",
       "      <td>3.406965e+08</td>\n",
       "      <td>5.678275e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.200</td>\n",
       "      <td>W2_7_1</td>\n",
       "      <td>substation</td>\n",
       "      <td>4.891202e+07</td>\n",
       "      <td>3.668402e+07</td>\n",
       "      <td>6.114003e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.200</td>\n",
       "      <td>W2_7_2</td>\n",
       "      <td>substation</td>\n",
       "      <td>9.782404e+07</td>\n",
       "      <td>7.336803e+07</td>\n",
       "      <td>1.222801e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.200</td>\n",
       "      <td>W2_7_3</td>\n",
       "      <td>substation</td>\n",
       "      <td>2.445601e+08</td>\n",
       "      <td>1.834201e+08</td>\n",
       "      <td>3.057001e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rp   curve  asset_type       meandam      lowerdam      upperdam\n",
       "0    0.001  W2_1_1  substation  2.396356e+08  1.797267e+08  2.995445e+08\n",
       "1    0.001  W2_1_2  substation  4.792712e+08  3.594534e+08  5.990890e+08\n",
       "2    0.001  W2_1_3  substation  1.198178e+09  8.986336e+08  1.497723e+09\n",
       "3    0.001  W2_2_1  substation  2.047256e+08  1.535442e+08  2.559070e+08\n",
       "4    0.001  W2_2_2  substation  4.094511e+08  3.070884e+08  5.118139e+08\n",
       "..     ...     ...         ...           ...           ...           ...\n",
       "205  0.200  W2_6_2  substation  1.817048e+08  1.362786e+08  2.271310e+08\n",
       "206  0.200  W2_6_3  substation  4.542620e+08  3.406965e+08  5.678275e+08\n",
       "207  0.200  W2_7_1  substation  4.891202e+07  3.668402e+07  6.114003e+07\n",
       "208  0.200  W2_7_2  substation  9.782404e+07  7.336803e+07  1.222801e+08\n",
       "209  0.200  W2_7_3  substation  2.445601e+08  1.834201e+08  3.057001e+08\n",
       "\n",
       "[210 rows x 6 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract nested dict by key\n",
    "osm_damage_infra[1]['_CMCC-CM2-VHR4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e56c1d61-40b5-4892-ac70-c20c522eb661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def country_analysis_osm(country_code,hazard_type):\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "    \n",
    "    # extract infrastructure data from OSM\n",
    "    osm_power_infra = extract_osm_infrastructure(country_code,osm_data_path)\n",
    "    \n",
    "    # assess damage to hazard_type\n",
    "    osm_damage_infra = assess_damage_osm(country_code,osm_power_infra,hazard_type)\n",
    "    \n",
    "    line_risk = {}\n",
    "    plant_risk = {}\n",
    "    substation_risk = {}\n",
    "    tower_risk = {}\n",
    "    pole_risk = {}\n",
    "\n",
    "    if hazard_type=='tc':\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "\n",
    "        for i in range(len(osm_damage_infra)):\n",
    "            for climate_model in climate_models:\n",
    "                df = osm_damage_infra[i][climate_model]\n",
    "\n",
    "                if len(df) == 0:\n",
    "                    print(\"No {}_{} risk of infra_type {} in {}\".format(hazard_type,climate_model,i,country_code))\n",
    "\n",
    "                else:\n",
    "                    with pd.ExcelWriter(os.path.join(output_path,'damage','{}_osm_{}{}_damage_{}'.format(country_code,hazard_type,climate_model,i)+'.xlsx')) as writer:\n",
    "                        df.to_excel(writer)\n",
    "\n",
    "                    df['rp'] = df['rp'].replace(['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),\n",
    "                                                '1_10{}'.format(climate_model),'1_25{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                                                '1_100{}'.format(climate_model),'1_250{}'.format(climate_model),'1_500{}'.format(climate_model),\n",
    "                                                '1_1000{}'.format(climate_model)],\n",
    "                                                [1,0.5,0.2,0.1,0.04,0.02,0.01,0.004,0.002,0.001])\n",
    "\n",
    "                    curve_code_substation = ['W2_1_1','W2_1_2','W2_1_3','W2_2_1','W2_2_2','W2_2_3','W2_3_1','W2_3_2','W2_3_3',\n",
    "                                            'W2_4_1','W2_4_2','W2_4_3','W2_5_1','W2_5_2','W2_5_3','W2_6_1','W2_6_2','W2_6_3',\n",
    "                                            'W2_7_1','W2_7_2','W2_7_3']\n",
    "\n",
    "                    curve_code_tower = ['W3_1','W3_2','W3_3','W3_4','W3_5','W3_6','W3_7','W3_8','W3_9','W3_10','W3_11','W3_12',\n",
    "                                        'W3_13','W3_14','W3_15','W3_16','W3_17','W3_18','W3_19','W3_20','W3_21','W3_22','W3_23',\n",
    "                                        'W3_24','W3_25','W3_26','W3_27','W3_28']\n",
    "\n",
    "                    curve_code_pole = ['W4_1','W4_2','W4_3','W4_4','W4_5','W4_6','W4_7','W4_8','W4_9','W4_10','W4_11','W4_12',\n",
    "                                    'W4_13','W4_14','W4_15','W4_16','W4_17','W4_18','W4_19','W4_20','W4_21','W4_22','W4_23',\n",
    "                                    'W4_24','W4_25','W4_26','W4_27','W4_28','W4_29','W4_30','W4_31','W4_32','W4_33','W4_34',\n",
    "                                    'W4_35','W4_36','W4_37','W4_38','W4_39','W4_40','W4_41','W4_42','W4_43','W4_44','W4_45',\n",
    "                                    'W4_46','W4_47','W4_48','W4_49','W4_50','W4_51','W4_52','W4_53','W4_54','W4_55','W4_56']\n",
    "\n",
    "                    curve_code_line = ['W5_1','W5_2','W5_3','W5_4']\n",
    "\n",
    "                    #assess risk for power lines\n",
    "                    if i == 0:\n",
    "                        for curve_code in curve_code_line:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            loss_list = loss_list.sort_values(by='rp',ascending=False)\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of power lines ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                line_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "\n",
    "                    #assess risk for power substations                \n",
    "                    elif i == 1:                        \n",
    "                        for curve_code in curve_code_substation:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            loss_list = loss_list.sort_values(by='rp',ascending=False)\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of substations ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                substation_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "\n",
    "                    #assess risk for power towers and power poles\n",
    "                    elif i == 2:\n",
    "                        for curve_code in curve_code_tower:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            loss_list = loss_list.sort_values(by='rp',ascending=False)\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of power towers ...\")\n",
    "\n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                tower_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "\n",
    "                            for curve_code in curve_code_pole:\n",
    "                                loss_list = df.loc[df['curve'] == curve_code]\n",
    "                                loss_list = loss_list.sort_values(by='rp',ascending=False)\n",
    "                                if len(loss_list) == 0:\n",
    "                                    print(\"No risk of power poles ...\")\n",
    "\n",
    "                                else:                    \n",
    "                                    loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                    loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                    loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                    RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                    RPS = RPS.rp.values.tolist()\n",
    "                                    pole_risk[climate_model,curve_code] = {\n",
    "                                        'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                        'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                        'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                    }\n",
    "\n",
    "    elif hazard_type=='fl':\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "    \n",
    "        for i in range(len(osm_damage_infra)):\n",
    "            for climate_model in climate_models:\n",
    "                df = osm_damage_infra[i][climate_model]\n",
    "                    \n",
    "                if len(df) == 0:\n",
    "                    print(\"No {}_{} risk of infra_type {} in {}\".format(hazard_type,climate_model,i,country_code))\n",
    "\n",
    "                else:\n",
    "                    with pd.ExcelWriter(os.path.join(output_path,'damage','{}_osm_{}_{}_damage_{}'.format(country_code,hazard_type,climate_model,i)+'.xlsx')) as writer:\n",
    "                        df.to_excel(writer)\n",
    "\n",
    "                    df['rp'] = df['rp'].replace(['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000'],\n",
    "                                                [1,0.5,0.2,0.1,0.04,0.02,0.01,0.004,0.002,0.001])\n",
    "                    \n",
    "                    curve_code_plant = ['F1_1_1','F1_1_2','F1_1_3']\n",
    "                    curve_code_substation = ['F2_1_1','F2_1_2','F2_1_3']\n",
    "                    curve_code_tower = ['F3_1_1','F3_1_2']\n",
    "                    curve_code_pole = ['F4_1_1','F4_1_2','F4_1_3','F4_1_4']\n",
    "                    curve_code_line = ['F5_1_1','F5_1_2','F5_1_3','F5_1_4','F5_1_5','F5_1_6','F5_1_7','F5_1_8',\n",
    "                                      'F5_1_9','F5_1_10','F5_1_11','F5_1_12']\n",
    "                    curve_code_minor_line = ['F5_2']\n",
    "                    curve_code_cable = ['F5_3_1','F5_3_2']\n",
    "\n",
    "                    #assess risk for power lines\n",
    "                    if i == 0:\n",
    "                        for curve_code in curve_code_line:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of power lines ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                line_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "\n",
    "                    #assess risk for power plants and substations                \n",
    "                    elif i == 1:\n",
    "                        for curve_code in curve_code_plant:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of plants ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                plant_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "\n",
    "                        for curve_code in curve_code_substation:    \n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of substations ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                substation_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                    }\n",
    "\n",
    "                    #assess risk for power towers and power poles\n",
    "                    elif i == 2:\n",
    "                        for curve_code in curve_code_tower:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of power towers ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                tower_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "                            \n",
    "                        for curve_code in curve_code_pole:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of power poles ...\")\n",
    "                            \n",
    "                            else:                    \n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                pole_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "                                \n",
    "    return pd.DataFrame(line_risk),pd.DataFrame(plant_risk),pd.DataFrame(substation_risk),pd.DataFrame(tower_risk),pd.DataFrame(pole_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ba717-0015-4527-bf1a-a9556f87a541",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Government data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef53a27c-f539-43db-9870-1ee933ddf7c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_pg_infrastructure(country_code):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        country_code (_type_): _description_\n",
    "        pg_type (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "\n",
    "    files = [x for x in os.listdir(pg_data_path)  if country_code in x ]\n",
    "    pg_types = ['line','point']\n",
    "    \n",
    "    for pg_type in pg_types:\n",
    "        if os.path.isfile(os.path.join(pg_data_path,'{}_{}.gpkg'.format(country_code,pg_type))):\n",
    "            if pg_type=='line':\n",
    "                for file in files: \n",
    "                    file_path = os.path.join(pg_data_path,'{}_{}.gpkg'.format(country_code,pg_type))\n",
    "\n",
    "                    pg_data_country = gpd.read_file(file_path)\n",
    "                    pg_data_country = pd.DataFrame(pg_data_country.copy())\n",
    "                    pg_data_country.geometry = pygeos.from_shapely(pg_data_country.geometry)\n",
    "                    pg_data_country['geometry'] = reproject(pg_data_country)\n",
    "\n",
    "                pg_lines = buffer_assets(pg_data_country.loc[pg_data_country.asset.isin(['line'])],buffer_size=100).reset_index(drop=True)\n",
    "\n",
    "            elif pg_type=='point':\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(pg_data_path,'{}_{}.gpkg'.format(country_code,pg_type))\n",
    "\n",
    "                    pg_data_country = gpd.read_file(file_path)\n",
    "                    pg_data_country = pd.DataFrame(pg_data_country.copy())\n",
    "                    pg_data_country.geometry = pygeos.from_shapely(pg_data_country.geometry)\n",
    "                    pg_data_country['geometry'] = reproject(pg_data_country)\n",
    "\n",
    "                pg_points = buffer_assets(pg_data_country.loc[pg_data_country.asset.isin(['plant','substation','power_tower','power_pole'])],buffer_size=100).reset_index(drop=True)\n",
    "\n",
    "    return pg_lines,pg_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6a7cdb0-f9a6-4d0c-9dd9-c9d88d7e98e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "pg_infra = extract_pg_infrastructure('JPN')\n",
    "print(type(pg_infra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c78d9c1-f773-42ea-ad91-0acb4aad54bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asset</th>\n",
       "      <th>geometry</th>\n",
       "      <th>buffered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>substation</td>\n",
       "      <td>POINT (15911096.018 5305017.559)</td>\n",
       "      <td>POLYGON ((15911196.018 5305017.559, 15911194.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>substation</td>\n",
       "      <td>POINT (15830095.626 5281047.141)</td>\n",
       "      <td>POLYGON ((15830195.626 5281047.141, 15830193.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>substation</td>\n",
       "      <td>POINT (15784471.912 5372262.28)</td>\n",
       "      <td>POLYGON ((15784571.912 5372262.28, 15784569.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>substation</td>\n",
       "      <td>POINT (15725429.458 5296354.502)</td>\n",
       "      <td>POLYGON ((15725529.458 5296354.502, 15725527.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>substation</td>\n",
       "      <td>POINT (15678341.881 5273735.047)</td>\n",
       "      <td>POLYGON ((15678441.881 5273735.047, 15678439.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>substation</td>\n",
       "      <td>POINT (14654065.093 3892423.909)</td>\n",
       "      <td>POLYGON ((14654165.093 3892423.909, 14654163.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>substation</td>\n",
       "      <td>POINT (14567941.182 3869470.184)</td>\n",
       "      <td>POLYGON ((14568041.182 3869470.184, 14568039.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>substation</td>\n",
       "      <td>POINT (14554522.443 3832084.632)</td>\n",
       "      <td>POLYGON ((14554622.443 3832084.632, 14554620.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>substation</td>\n",
       "      <td>POINT (14530856.666 3761834.532)</td>\n",
       "      <td>POLYGON ((14530956.666 3761834.532, 14530954.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>substation</td>\n",
       "      <td>POINT (14591119.005 3740566.664)</td>\n",
       "      <td>POLYGON ((14591219.005 3740566.664, 14591217.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id       asset                          geometry  \\\n",
       "0    1  substation  POINT (15911096.018 5305017.559)   \n",
       "1    2  substation  POINT (15830095.626 5281047.141)   \n",
       "2    3  substation   POINT (15784471.912 5372262.28)   \n",
       "3    4  substation  POINT (15725429.458 5296354.502)   \n",
       "4    5  substation  POINT (15678341.881 5273735.047)   \n",
       "..  ..         ...                               ...   \n",
       "63  64  substation  POINT (14654065.093 3892423.909)   \n",
       "64  65  substation  POINT (14567941.182 3869470.184)   \n",
       "65  66  substation  POINT (14554522.443 3832084.632)   \n",
       "66  67  substation  POINT (14530856.666 3761834.532)   \n",
       "67  68  substation  POINT (14591119.005 3740566.664)   \n",
       "\n",
       "                                             buffered  \n",
       "0   POLYGON ((15911196.018 5305017.559, 15911194.0...  \n",
       "1   POLYGON ((15830195.626 5281047.141, 15830193.7...  \n",
       "2   POLYGON ((15784571.912 5372262.28, 15784569.99...  \n",
       "3   POLYGON ((15725529.458 5296354.502, 15725527.5...  \n",
       "4   POLYGON ((15678441.881 5273735.047, 15678439.9...  \n",
       "..                                                ...  \n",
       "63  POLYGON ((14654165.093 3892423.909, 14654163.1...  \n",
       "64  POLYGON ((14568041.182 3869470.184, 14568039.2...  \n",
       "65  POLYGON ((14554622.443 3832084.632, 14554620.5...  \n",
       "66  POLYGON ((14530956.666 3761834.532, 14530954.7...  \n",
       "67  POLYGON ((14591219.005 3740566.664, 14591217.0...  \n",
       "\n",
       "[68 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_infra[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c0797c42-fd24-45f7-a0c0-51783767aa2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assess_damage_pg(country_code,pg_infra,hazard_type):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        country_code (_type_): _description_\n",
    "        pg_data_country (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "\n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(country_code,vul_curve_path,hazard_type)\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    pg_lines,pg_points = pg_infra\n",
    "    \n",
    "    #calculate damaged lines/polygons/points in loop by climate_model\n",
    "    damaged_lines = {}\n",
    "    damaged_points = {}\n",
    "\n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "        df_ds = open_storm_data(country_code)\n",
    "        \n",
    "        # remove assets that will not have any damage\n",
    "        pg_points = pg_points.loc[pg_points.asset != 'plant'].reset_index(drop=True)\n",
    "    \n",
    "    elif hazard_type == 'fl':\n",
    "        # read flood data\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "        df_ds = open_flood_data(country_code)\n",
    "        \n",
    "    for climate_model in climate_models:\n",
    "        if hazard_type=='tc':\n",
    "            return_periods = ['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),'1_10{}'.format(climate_model),\n",
    "                              '1_25{}'.format(climate_model),'1_50{}'.format(climate_model),'1_100{}'.format(climate_model),\n",
    "                              '1_250{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "        elif hazard_type == 'fl':\n",
    "            return_periods = ['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000'] \n",
    "            \n",
    "        # assess damage for lines\n",
    "        overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],pg_lines).T,\n",
    "                                     columns=['asset','hazard_point'])\n",
    "\n",
    "        if len(overlay_lines) == 0:\n",
    "            damaged_lines[climate_model] = pd.DataFrame()\n",
    "\n",
    "        else:\n",
    "            collect_line_damages = []\n",
    "            for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                              desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_line_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                            df_ds[climate_model],\n",
    "                                                                            pg_lines,\n",
    "                                                                            curves,\n",
    "                                                                            maxdam,\n",
    "                                                                            return_period,\n",
    "                                                                            country_code))\n",
    "\n",
    "            get_asset_type_line = dict(zip(pg_lines.index,pg_lines.asset))\n",
    "            \n",
    "            if hazard_type=='tc':\n",
    "                results = pd.DataFrame([item for sublist in collect_line_damages\n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "                damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "                \n",
    "            elif hazard_type == 'fl':\n",
    "                results = pd.DataFrame(collect_line_damages,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "                #sum damage of line, cable, and minor_line\n",
    "                results['curve'] = results['curve'].replace(['cable', 'minor_line'], 'line')\n",
    "                results['asset_type'] = results['asset_type'].replace(['cable', 'minor_line'], 'line')\n",
    "\n",
    "                damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index() \n",
    "\n",
    "        # assess damage for points\n",
    "        overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],pg_points).T,\n",
    "                                      columns=['asset','hazard_point'])\n",
    "\n",
    "        if len(overlay_points) == 0:\n",
    "            damaged_points[climate_model] = pd.DataFrame()\n",
    "\n",
    "        else:\n",
    "            collect_point_damages = []\n",
    "            for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                              desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_point_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                            df_ds[climate_model],\n",
    "                                                                            pg_points,\n",
    "                                                                            curves,\n",
    "                                                                            maxdam,\n",
    "                                                                            return_period,\n",
    "                                                                            country_code))\n",
    "\n",
    "            get_asset_type_point = dict(zip(pg_points.index,pg_points.asset))\n",
    "            \n",
    "            if hazard_type == 'tc':\n",
    "                results = pd.DataFrame([item for sublist in collect_point_damages\n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "            elif hazard_type == 'fl':\n",
    "                results = pd.DataFrame(collect_point_damages ,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "            results['asset_type'] = results.asset.apply(lambda x : get_asset_type_point[x])    \n",
    "\n",
    "            damaged_points[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "                \n",
    "    return damaged_lines,damaged_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9a76e-2690-4f96-bc6d-255885bbe73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_damage_pg(country_code,pg_power_infra,hazard_type):\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "\n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(country_code,vul_curve_path,hazard_type)\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    osm_lines,osm_poly,osm_points = osm_power_infra\n",
    "    #print(osm_lines['asset'].unique())\n",
    "    \n",
    "    #calculate damaged lines/polygons/points in loop by climate_model\n",
    "    damaged_lines = {}\n",
    "    damaged_poly = {}\n",
    "    damaged_points = {}\n",
    "\n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = ['','_CMCC-CM2-VHR4'] #,'_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM'\n",
    "        df_ds = open_storm_data(country_code)\n",
    "\n",
    "        # remove assets that will not have any damage\n",
    "        osm_lines = osm_lines.loc[osm_lines.asset != 'cable'].reset_index(drop=True)\n",
    "        osm_lines['asset'] = osm_lines['asset'].replace(['minor_line'], 'line')\n",
    "        osm_poly = osm_poly.loc[osm_poly.asset != 'plant'].reset_index(drop=True)\n",
    "        \n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),'1_10{}'.format(climate_model),\n",
    "                              '1_25{}'.format(climate_model),'1_50{}'.format(climate_model),'1_100{}'.format(climate_model),\n",
    "                              '1_250{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "            \n",
    "            # assess damage for lines\n",
    "            overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_lines).T,\n",
    "                                         columns=['asset','hazard_point'])\n",
    "\n",
    "            if len(overlay_lines) == 0:\n",
    "                damaged_lines[climate_model] = pd.DataFrame()\n",
    "\n",
    "            else:\n",
    "                collect_line_damages = []\n",
    "                for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                                  desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                    for return_period in return_periods:\n",
    "                        collect_line_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                                df_ds[climate_model],\n",
    "                                                                                osm_lines,\n",
    "                                                                                curves,\n",
    "                                                                                maxdam,\n",
    "                                                                                return_period,\n",
    "                                                                                country_code))\n",
    "\n",
    "                get_asset_type_line = dict(zip(osm_lines.index,osm_lines.asset))\n",
    "                results = pd.DataFrame([item for sublist in collect_line_damages\n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "                damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "            # assess damage for polygons\n",
    "            if len(osm_poly) > 0:\n",
    "                overlay_poly = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_poly).T,\n",
    "                                        columns=['asset','hazard_point'])\n",
    "            else:\n",
    "                overlay_poly = pd.DataFrame()\n",
    "\n",
    "            if len(overlay_poly) == 0:\n",
    "                damaged_poly[climate_model] = pd.DataFrame()\n",
    "\n",
    "            else:\n",
    "                collect_poly_damages = []\n",
    "                for asset in tqdm(overlay_poly.groupby('asset'),total=len(overlay_poly.asset.unique()),\n",
    "                                  desc='polygon damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                    for return_period in return_periods:\n",
    "                        collect_poly_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                                df_ds[climate_model],\n",
    "                                                                                osm_poly,\n",
    "                                                                                curves,\n",
    "                                                                                maxdam,\n",
    "                                                                                return_period,\n",
    "                                                                                country_code))\n",
    "\n",
    "                get_asset_type_poly = dict(zip(osm_poly.index,osm_poly.asset))\n",
    "                \n",
    "                results = pd.DataFrame([item for sublist in collect_poly_damages \n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_poly[x])    \n",
    "\n",
    "                damaged_poly[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "            #assess damage for points\n",
    "            overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_points).T,\n",
    "                                          columns=['asset','hazard_point'])\n",
    "\n",
    "            if len(overlay_points) == 0:\n",
    "                damaged_points[climate_model] = pd.DataFrame()\n",
    "\n",
    "            else:\n",
    "                collect_point_damages = []\n",
    "                for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                                  desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                    for return_period in return_periods:\n",
    "                        collect_point_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                                df_ds[climate_model],\n",
    "                                                                                osm_points,\n",
    "                                                                                curves,\n",
    "                                                                                maxdam,\n",
    "                                                                                return_period,\n",
    "                                                                                country_code))\n",
    "\n",
    "                get_asset_type_point = dict(zip(osm_points.index,osm_points.asset))\n",
    "                \n",
    "                results = pd.DataFrame([item for sublist in collect_point_damages\n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_point[x])    \n",
    "\n",
    "                damaged_points[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "\n",
    "    elif hazard_type=='fl':\n",
    "        # read flood data\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "        df_ds = open_flood_data(country_code)\n",
    "    \n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000'] \n",
    "\n",
    "            # assess damage for lines\n",
    "            overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_lines).T,\n",
    "                                         columns=['asset','hazard_point'])\n",
    "\n",
    "            if len(overlay_lines) == 0:\n",
    "                damaged_lines[climate_model] = pd.DataFrame()\n",
    "\n",
    "            else:\n",
    "                collect_line_damages = []\n",
    "                for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                                  desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                    for return_period in return_periods:\n",
    "                        collect_line_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                                df_ds[climate_model],\n",
    "                                                                                osm_lines,\n",
    "                                                                                curves,\n",
    "                                                                                maxdam,\n",
    "                                                                                return_period,\n",
    "                                                                                country_code))\n",
    "\n",
    "                get_asset_type_line = dict(zip(osm_lines.index,osm_lines.asset))\n",
    "                results = pd.DataFrame(collect_line_damages,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                \n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "                #sum damage of line, cable, and minor_line\n",
    "                results['curve'] = results['curve'].replace(['cable', 'minor_line'], 'line')\n",
    "                results['asset_type'] = results['asset_type'].replace(['cable', 'minor_line'], 'line')\n",
    "\n",
    "                damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "            # assess damage for polygons\n",
    "            if len(osm_poly) > 0:\n",
    "                overlay_poly = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_poly).T,\n",
    "                                        columns=['asset','hazard_point'])\n",
    "            else:\n",
    "                overlay_poly = pd.DataFrame()\n",
    "\n",
    "            if len(overlay_poly) == 0:\n",
    "                damaged_poly[climate_model] = pd.DataFrame()\n",
    "\n",
    "            else:\n",
    "                collect_poly_damages = []\n",
    "                for asset in tqdm(overlay_poly.groupby('asset'),total=len(overlay_poly.asset.unique()),\n",
    "                                  desc='polygon damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                    for return_period in return_periods:\n",
    "                        collect_poly_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                                df_ds[climate_model],\n",
    "                                                                                osm_poly,\n",
    "                                                                                curves,\n",
    "                                                                                maxdam,\n",
    "                                                                                return_period,\n",
    "                                                                                country_code))\n",
    "\n",
    "                get_asset_type_poly = dict(zip(osm_poly.index,osm_poly.asset))\n",
    "                               \n",
    "                #results = pd.DataFrame(collect_poly_damages ,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                results = pd.DataFrame([item for sublist in collect_poly_damages \n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                \n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_poly[x])    \n",
    "\n",
    "                damaged_poly[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "            # assess damage for points\n",
    "            overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_points).T,\n",
    "                                          columns=['asset','hazard_point'])\n",
    "\n",
    "            if len(overlay_points) == 0:\n",
    "                damaged_points[climate_model] = pd.DataFrame()\n",
    "\n",
    "            else:\n",
    "                collect_point_damages = []\n",
    "                for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                                  desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                    for return_period in return_periods:\n",
    "                        collect_point_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                                df_ds[climate_model],\n",
    "                                                                                osm_points,\n",
    "                                                                                curves,\n",
    "                                                                                maxdam,\n",
    "                                                                                return_period,\n",
    "                                                                                country_code))\n",
    "\n",
    "                get_asset_type_point = dict(zip(osm_points.index,osm_points.asset))\n",
    "                \n",
    "               \n",
    "                #results = pd.DataFrame(collect_point_damages ,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                \n",
    "                results = pd.DataFrame(np.array(list(flatten(collect_point_damages))).reshape(\n",
    "                    int(len(list(flatten(collect_point_damages)))/6), 6),\n",
    "                                       columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                \n",
    "                results['asset'] = results['asset'].astype(int)\n",
    "                results[['meandam','lowerdam','upperdam']] = results[['meandam','lowerdam','upperdam']].astype(float)\n",
    "                \n",
    "                #return collect_point_damages,get_asset_type_point\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_point[x])    \n",
    "\n",
    "                damaged_points[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "    return damaged_lines,damaged_poly,damaged_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5680499-fc0f-454f-ab9b-4452a2c120ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for JPN tc (): 100%|| 31/31 [00:03<00:00,  9.78it/s]\n",
      "point damage calculation for JPN tc (): 100%|| 68/68 [00:08<00:00,  7.87it/s]\n",
      "polyline damage calculation for JPN tc (_CMCC-CM2-VHR4): 100%|| 31/31 [00:03<00:00,  9.75it/s]\n",
      "point damage calculation for JPN tc (_CMCC-CM2-VHR4): 100%|| 68/68 [00:08<00:00,  7.79it/s]\n",
      "polyline damage calculation for JPN tc (_CNRM-CM6-1-HR): 100%|| 31/31 [00:03<00:00,  9.72it/s]\n",
      "point damage calculation for JPN tc (_CNRM-CM6-1-HR): 100%|| 68/68 [00:08<00:00,  7.76it/s]\n",
      "polyline damage calculation for JPN tc (_EC-Earth3P-HR): 100%|| 31/31 [00:03<00:00,  9.77it/s]\n",
      "point damage calculation for JPN tc (_EC-Earth3P-HR): 100%|| 68/68 [00:08<00:00,  7.71it/s]\n",
      "polyline damage calculation for JPN tc (_HadGEM3-GC31-HM): 100%|| 31/31 [00:03<00:00,  9.77it/s]\n",
      "point damage calculation for JPN tc (_HadGEM3-GC31-HM): 100%|| 68/68 [00:08<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 50s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pg_damage_infra_tc = assess_damage_pg('JPN',pg_infra,'tc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64cfcf4a-3381-4a83-9f58-6b254ce75336",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rp</th>\n",
       "      <th>curve</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>meandam</th>\n",
       "      <th>lowerdam</th>\n",
       "      <th>upperdam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_1</td>\n",
       "      <td>W2_1_1</td>\n",
       "      <td>substation</td>\n",
       "      <td>2.638182e+05</td>\n",
       "      <td>1.978637e+05</td>\n",
       "      <td>3.297728e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_1</td>\n",
       "      <td>W2_1_2</td>\n",
       "      <td>substation</td>\n",
       "      <td>5.276365e+05</td>\n",
       "      <td>3.957274e+05</td>\n",
       "      <td>6.595456e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_1</td>\n",
       "      <td>W2_1_3</td>\n",
       "      <td>substation</td>\n",
       "      <td>1.319091e+06</td>\n",
       "      <td>9.893184e+05</td>\n",
       "      <td>1.648864e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_1</td>\n",
       "      <td>W2_2_1</td>\n",
       "      <td>substation</td>\n",
       "      <td>1.826395e+04</td>\n",
       "      <td>1.369796e+04</td>\n",
       "      <td>2.282994e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_1</td>\n",
       "      <td>W2_2_2</td>\n",
       "      <td>substation</td>\n",
       "      <td>3.652790e+04</td>\n",
       "      <td>2.739592e+04</td>\n",
       "      <td>4.565987e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1_500</td>\n",
       "      <td>W2_6_2</td>\n",
       "      <td>substation</td>\n",
       "      <td>2.243239e+08</td>\n",
       "      <td>1.682430e+08</td>\n",
       "      <td>2.804049e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1_500</td>\n",
       "      <td>W2_6_3</td>\n",
       "      <td>substation</td>\n",
       "      <td>5.608099e+08</td>\n",
       "      <td>4.206074e+08</td>\n",
       "      <td>7.010123e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1_500</td>\n",
       "      <td>W2_7_1</td>\n",
       "      <td>substation</td>\n",
       "      <td>4.358600e+07</td>\n",
       "      <td>3.268950e+07</td>\n",
       "      <td>5.448250e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1_500</td>\n",
       "      <td>W2_7_2</td>\n",
       "      <td>substation</td>\n",
       "      <td>8.717200e+07</td>\n",
       "      <td>6.537900e+07</td>\n",
       "      <td>1.089650e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1_500</td>\n",
       "      <td>W2_7_3</td>\n",
       "      <td>substation</td>\n",
       "      <td>2.179300e+08</td>\n",
       "      <td>1.634475e+08</td>\n",
       "      <td>2.724125e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rp   curve  asset_type       meandam      lowerdam      upperdam\n",
       "0      1_1  W2_1_1  substation  2.638182e+05  1.978637e+05  3.297728e+05\n",
       "1      1_1  W2_1_2  substation  5.276365e+05  3.957274e+05  6.595456e+05\n",
       "2      1_1  W2_1_3  substation  1.319091e+06  9.893184e+05  1.648864e+06\n",
       "3      1_1  W2_2_1  substation  1.826395e+04  1.369796e+04  2.282994e+04\n",
       "4      1_1  W2_2_2  substation  3.652790e+04  2.739592e+04  4.565987e+04\n",
       "..     ...     ...         ...           ...           ...           ...\n",
       "205  1_500  W2_6_2  substation  2.243239e+08  1.682430e+08  2.804049e+08\n",
       "206  1_500  W2_6_3  substation  5.608099e+08  4.206074e+08  7.010123e+08\n",
       "207  1_500  W2_7_1  substation  4.358600e+07  3.268950e+07  5.448250e+07\n",
       "208  1_500  W2_7_2  substation  8.717200e+07  6.537900e+07  1.089650e+08\n",
       "209  1_500  W2_7_3  substation  2.179300e+08  1.634475e+08  2.724125e+08\n",
       "\n",
       "[210 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_damage_infra_tc[1]['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f7d5fb3-c1c9-4e1e-a73c-fea26042357f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for JPN fl (historical): 100%|| 5/5 [00:00<00:00, 25.00it/s]\n",
      "point damage calculation for JPN fl (historical): 100%|| 1/1 [00:00<00:00, 45.45it/s]\n",
      "polyline damage calculation for JPN fl (rcp8p5): 100%|| 5/5 [00:00<00:00, 24.04it/s]\n",
      "point damage calculation for JPN fl (rcp8p5): 100%|| 1/1 [00:00<00:00, 50.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8min 7s\n",
      "Wall time: 8min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pg_damage_infra_fl = assess_damage_pg('JPN',pg_infra,'fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc6d1154-a26e-4dfe-9ee0-86f6bb80c10d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'historical':        rp       curve  asset_type        meandam       lowerdam       upperdam\n",
       "  0  rp0001  substation  substation  490588.160384  367941.120288  613235.200480\n",
       "  1  rp0002  substation  substation  517498.328609  388123.746457  646872.910762\n",
       "  2  rp0005  substation  substation  559647.208366  419735.406274  699559.010457\n",
       "  3  rp0010  substation  substation  579966.806294  434975.104721  724958.507868\n",
       "  4  rp0025  substation  substation  608736.040167  456552.030125  760920.050208\n",
       "  5  rp0050  substation  substation  632107.357808  474080.518356  790134.197260\n",
       "  6  rp0100  substation  substation  652340.431603  489255.323702  815425.539504\n",
       "  7  rp0250  substation  substation  682990.145845  512242.609384  853737.682306\n",
       "  8  rp0500  substation  substation  699857.025260  524892.768945  874821.281575\n",
       "  9  rp1000  substation  substation  721527.021566  541145.266174  901908.776957,\n",
       "  'rcp8p5':        rp       curve  asset_type        meandam       lowerdam       upperdam\n",
       "  0  rp0001  substation  substation  563081.188997  422310.891747  703851.486246\n",
       "  1  rp0002  substation  substation  576128.595727  432096.446795  720160.744658\n",
       "  2  rp0005  substation  substation  610238.220801  457678.665601  762797.776001\n",
       "  3  rp0010  substation  substation  636848.474749  477636.356061  796060.593436\n",
       "  4  rp0025  substation  substation  663008.857279  497256.642959  828761.071599\n",
       "  5  rp0050  substation  substation  688989.026262  516741.769697  861236.282828\n",
       "  6  rp0100  substation  substation  707410.163024  530557.622268  884262.703781\n",
       "  7  rp0250  substation  substation  731011.743016  548258.807262  913764.678770\n",
       "  8  rp0500  substation  substation  756650.033516  567487.525137  945812.541895\n",
       "  9  rp1000  substation  substation  773409.866355  580057.399766  966762.332944},\n",
       " {})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_damage_infra_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98d174ad-3c24-44ea-88cb-0b88ee406e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def country_analysis_pg(country_code,hazard_type):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        country_code (_type_): _description_\n",
    "        hazard_type (str, optional): _description_. Defaults to 'OSM'.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "    \n",
    "    # extract infrastructure data from gov data\n",
    "    pg_power_infra = extract_pg_infrastructure(country_code)\n",
    "    \n",
    "    # assess damage to hazard_type\n",
    "    pg_damage_infra = assess_damage_pg(country_code,pg_power_infra,hazard_type)\n",
    "    \n",
    "    line_risk = {}\n",
    "    plant_risk = {}\n",
    "    substation_risk = {}\n",
    "\n",
    "    if hazard_type=='tc':\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "\n",
    "        for i in range(len(pg_damage_infra)):\n",
    "            for climate_model in climate_models:\n",
    "                df = pg_damage_infra[i][climate_model]\n",
    "                    \n",
    "                if len(df) == 0:\n",
    "                    print(\"No {}_{} risk of infra_type {} in {}\".format(hazard_type,climate_model,i,country_code))\n",
    "\n",
    "                else:\n",
    "                    with pd.ExcelWriter(os.path.join(output_path,'damage','{}_pg_{}{}_damage_{}'.format(country_code,hazard_type,climate_model,i)+'.xlsx')) as writer:\n",
    "                        df.to_excel(writer)\n",
    "\n",
    "                    df['rp'] = df['rp'].replace(['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),\n",
    "                                                '1_10{}'.format(climate_model),'1_25{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                                                '1_100{}'.format(climate_model),'1_250{}'.format(climate_model),'1_500{}'.format(climate_model),\n",
    "                                                '1_1000{}'.format(climate_model)],\n",
    "                                                [1,0.5,0.2,0.1,0.04,0.02,0.01,0.004,0.002,0.001])\n",
    "                    \n",
    "                    curve_code_substation = ['W2_1_1','W2_1_2','W2_1_3','W2_2_1','W2_2_2','W2_2_3','W2_3_1','W2_3_2','W2_3_3',\n",
    "                                            'W2_4_1','W2_4_2','W2_4_3','W2_5_1','W2_5_2','W2_5_3','W2_6_1','W2_6_2','W2_6_3',\n",
    "                                            'W2_7_1','W2_7_2','W2_7_3']\n",
    "                    \n",
    "                    curve_code_line = ['W5_1','W5_2','W5_3']\n",
    "\n",
    "                    #assess risk for power lines\n",
    "                    if i == 0:\n",
    "                        for curve_code in curve_code_line:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            loss_list = loss_list.sort_values(by='rp',ascending=False)\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of power lines ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "\n",
    "                                line_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "                            #print(line_risk_curve)\n",
    "                    \n",
    "                    #assess risk for power substations                \n",
    "                    elif i == 1:                        \n",
    "                        for curve_code in curve_code_substation:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            loss_list = loss_list.sort_values(by='rp',ascending=False)\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of substations ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "\n",
    "                                substation_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "\n",
    "\n",
    "    elif hazard_type=='fl':\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "    \n",
    "        for i in range(len(pg_damage_infra)):\n",
    "            for climate_model in climate_models:\n",
    "                df = pg_damage_infra[i][climate_model]\n",
    "                    \n",
    "                if len(df) == 0:\n",
    "                    print(\"No {}_{} risk of infra_type {} in {}\".format(hazard_type,climate_model,i,country_code))\n",
    "\n",
    "                else:\n",
    "                    with pd.ExcelWriter(os.path.join(output_path,'damage','{}_pg_{}_{}_damage_{}'.format(country_code,hazard_type,climate_model,i)+'.xlsx')) as writer:\n",
    "                        df.to_excel(writer)\n",
    "\n",
    "                    df['rp'] = df['rp'].replace(['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000'],\n",
    "                                                [1,0.5,0.2,0.1,0.04,0.02,0.01,0.004,0.002,0.001])\n",
    "                    \n",
    "                    curve_code_plant = ['F1_1_1','F1_1_2','F1_1_3']\n",
    "                    curve_code_substation = ['F2_1_1','F2_1_2','F2_1_3']\n",
    "                    curve_code_line = ['F5_1']\n",
    "\n",
    "                    #assess risk for power lines\n",
    "                    if i == 0:\n",
    "                        for curve_code in curve_code_line:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of power lines ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                line_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "\n",
    "                    #assess risk for power plants and substations                \n",
    "                    elif i == 1:\n",
    "                        for curve_code in curve_code_plant:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of plants ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                plant_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "                            \n",
    "                        for curve_code in curve_code_substation:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of substations ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                substation_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                    }\n",
    "                            \n",
    "    return pd.DataFrame(line_risk),pd.DataFrame(plant_risk),pd.DataFrame(substation_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0b2f45-0e6a-4452-b85a-1cf009ec3d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pg_risk_tc = country_analysis_pg('JPN','tc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c6222f6c-3c12-4b7a-84ba-544e31de677f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_CMCC-CM2-VHR4</th>\n",
       "      <th>_CNRM-CM6-1-HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W2_7_3\n",
       "mean_risk   1.434933e...</td>\n",
       "      <td>W2_7_3\n",
       "mean_risk   1.544563e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      _CMCC-CM2-VHR4  \\\n",
       "0                    W2_7_3\n",
       "mean_risk   1.434933e...   \n",
       "\n",
       "                                      _CNRM-CM6-1-HR  \n",
       "0                    W2_7_3\n",
       "mean_risk   1.544563e...  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pg_risk_tc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5755396e-ef87-4815-ba01-1f91eb685bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for JPN fl (historical): 100%|| 5/5 [00:00<00:00, 24.88it/s]\n",
      "point damage calculation for JPN fl (historical): 100%|| 1/1 [00:00<00:00, 41.67it/s]\n",
      "polyline damage calculation for JPN fl (rcp8p5): 100%|| 5/5 [00:00<00:00, 23.80it/s]\n",
      "point damage calculation for JPN fl (rcp8p5): 100%|| 1/1 [00:00<00:00, 49.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No risk of plants ...\n",
      "No risk of plants ...\n"
     ]
    }
   ],
   "source": [
    "pg_risk_fl = country_analysis_pg('JPN','fl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f076a1e2-6f11-47d7-b19b-595720d8de7b",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dda764da-ee7e-49ea-9572-e263c80ddecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def risk_output(country_code,hazard_type,infra_type):\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "  \n",
    "    if infra_type == 'osm':\n",
    "        line_risk,plant_risk,substation_risk,tower_risk,pole_risk = country_analysis_osm(country_code,hazard_type)\n",
    "        \n",
    "        if hazard_type == 'tc':\n",
    "            climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "\n",
    "            for climate_model in climate_models:\n",
    "                if climate_model == '':\n",
    "                    writer = pd.ExcelWriter(os.path.join(output_path,'risk','{}_{}_{}_{}_risk'.format(country_code,infra_type,hazard_type,'present')+'.xlsx'),\n",
    "                                            engine='openpyxl')\n",
    "                else:\n",
    "                    writer = pd.ExcelWriter(os.path.join(output_path,'risk','{}_{}_{}{}_risk'.format(country_code,infra_type,hazard_type,climate_model)+'.xlsx'),\n",
    "                                            engine='openpyxl')\n",
    "                    \n",
    "                # write each dataframe to a different sheet\n",
    "                if len(line_risk) != 0:\n",
    "                    line_risk[climate_model].to_excel(writer, sheet_name='line_risk')\n",
    "                if len(substation_risk) != 0:\n",
    "                    substation_risk[climate_model].to_excel(writer, sheet_name='substation_risk')\n",
    "                if len(tower_risk) != 0:\n",
    "                    tower_risk[climate_model].to_excel(writer, sheet_name='tower_risk')\n",
    "                if len(pole_risk) != 0:\n",
    "                    pole_risk[climate_model].to_excel(writer, sheet_name='pole_risk')\n",
    "                \n",
    "                # save the Excel file\n",
    "                writer.save()\n",
    "\n",
    "        elif hazard_type == 'fl':\n",
    "            climate_models = ['historical','rcp8p5']\n",
    "\n",
    "            for climate_model in climate_models:\n",
    "\n",
    "                # create a Pandas Excel writer using openpyxl engine\n",
    "                writer = pd.ExcelWriter(os.path.join(output_path,'risk','{}_{}_{}_{}_risk'.format(country_code,infra_type,hazard_type,climate_model)+'.xlsx'), engine='openpyxl')\n",
    "                \n",
    "                # write each dataframe to a different sheet\n",
    "                if len(line_risk) != 0:\n",
    "                    line_risk[climate_model].to_excel(writer, sheet_name='line_risk')\n",
    "                if len(plant_risk) != 0:\n",
    "                    plant_risk[climate_model].to_excel(writer, sheet_name='plant_risk')\n",
    "                if len(substation_risk) != 0:\n",
    "                    substation_risk[climate_model].to_excel(writer, sheet_name='substation_risk')\n",
    "                if len(tower_risk) != 0:\n",
    "                    tower_risk[climate_model].to_excel(writer, sheet_name='tower_risk')\n",
    "                if len(pole_risk) != 0:\n",
    "                    pole_risk[climate_model].to_excel(writer, sheet_name='pole_risk')\n",
    "                \n",
    "                # save the Excel file\n",
    "                writer.save()\n",
    "\n",
    "    elif infra_type == 'gov':\n",
    "        line_risk,plant_risk,substation_risk = country_analysis_pg(country_code,hazard_type)\n",
    "        \n",
    "        if hazard_type == 'tc':\n",
    "            climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "\n",
    "            for climate_model in climate_models:\n",
    "                if climate_model == '':\n",
    "                    writer = pd.ExcelWriter(os.path.join(output_path,'risk','{}_{}_{}_{}_risk'.format(country_code,infra_type,hazard_type,'present')+'.xlsx'),\n",
    "                                            engine='openpyxl')\n",
    "                else:\n",
    "                    writer = pd.ExcelWriter(os.path.join(output_path,'risk','{}_{}_{}{}_risk'.format(country_code,infra_type,hazard_type,climate_model)+'.xlsx'),\n",
    "                                            engine='openpyxl')\n",
    "                \n",
    "                # write each dataframe to a different sheet\n",
    "                if len(line_risk) != 0:\n",
    "                    line_risk[climate_model].to_excel(writer, sheet_name='line_risk')\n",
    "                if len(substation_risk) != 0:\n",
    "                    substation_risk[climate_model].to_excel(writer, sheet_name='substation_risk')\n",
    "                    \n",
    "                # save the Excel file\n",
    "                writer.save()\n",
    "\n",
    "        elif hazard_type == 'fl':\n",
    "            climate_models = ['historical','rcp8p5']\n",
    "\n",
    "            for climate_model in climate_models:\n",
    "\n",
    "                # create a Pandas Excel writer using openpyxl engine\n",
    "                writer = pd.ExcelWriter(os.path.join(output_path,'risk','{}_{}_{}_risk'.format(country_code,infra_type,hazard_type)+'.xlsx'), engine='openpyxl')\n",
    "                \n",
    "                # write each dataframe to a different sheet\n",
    "                if len(line_risk) != 0:\n",
    "                    line_risk[climate_model].to_excel(writer, sheet_name='line_risk')\n",
    "                if len(plant_risk) != 0:\n",
    "                    plant_risk[climate_model].to_excel(writer, sheet_name='plant_risk')\n",
    "                if len(substation_risk) != 0:\n",
    "                    substation_risk[climate_model].to_excel(writer, sheet_name='substation_risk')\n",
    "\n",
    "                # save the Excel file\n",
    "                writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d978c878-bbbf-47c5-abc2-2df27355e8c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|| 8145/8145 [00:31<00:00, 261.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|| 365/365 [02:48<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['substation' 'plant']\n",
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|| 440360/440360 [00:48<00:00, 9061.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio_usa for PHL is 0.0547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for PHL fl (historical): 100%|| 146/146 [00:20<00:00,  7.29it/s]\n",
      "polygon damage calculation for PHL fl (historical): 100%|| 7/7 [00:01<00:00,  6.73it/s]\n",
      "point damage calculation for PHL fl (historical): 100%|| 877/877 [00:41<00:00, 21.07it/s]\n",
      "polyline damage calculation for PHL fl (rcp8p5): 100%|| 133/133 [00:18<00:00,  7.27it/s]\n",
      "polygon damage calculation for PHL fl (rcp8p5): 100%|| 7/7 [00:00<00:00,  7.27it/s]\n",
      "point damage calculation for PHL fl (rcp8p5): 100%|| 877/877 [00:41<00:00, 21.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10min 36s\n",
      "Wall time: 10min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "risk_output('PHL','fl','osm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "f25448e6-5b5d-434d-8332-8471a4a7e2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rp</th>\n",
       "      <th>curve</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>meandam</th>\n",
       "      <th>lowerdam</th>\n",
       "      <th>upperdam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>1.658665e+09</td>\n",
       "      <td>4.523633e+08</td>\n",
       "      <td>2.261816e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>1.730781e+09</td>\n",
       "      <td>4.720311e+08</td>\n",
       "      <td>2.360156e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.388258e+09</td>\n",
       "      <td>6.513430e+08</td>\n",
       "      <td>3.256715e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.100</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.552940e+09</td>\n",
       "      <td>6.962564e+08</td>\n",
       "      <td>3.481282e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.040</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.767454e+09</td>\n",
       "      <td>7.547601e+08</td>\n",
       "      <td>3.773801e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.020</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.921201e+09</td>\n",
       "      <td>7.966912e+08</td>\n",
       "      <td>3.983456e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.010</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.080762e+09</td>\n",
       "      <td>8.402079e+08</td>\n",
       "      <td>4.201039e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.004</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.356950e+09</td>\n",
       "      <td>9.155320e+08</td>\n",
       "      <td>4.577660e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.528684e+09</td>\n",
       "      <td>9.623684e+08</td>\n",
       "      <td>4.811842e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.698459e+09</td>\n",
       "      <td>1.008671e+09</td>\n",
       "      <td>5.043354e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rp  curve asset_type       meandam      lowerdam      upperdam\n",
       "0   1.000  plant      plant  1.658665e+09  4.523633e+08  2.261816e+09\n",
       "2   0.500  plant      plant  1.730781e+09  4.720311e+08  2.360156e+09\n",
       "4   0.200  plant      plant  2.388258e+09  6.513430e+08  3.256715e+09\n",
       "6   0.100  plant      plant  2.552940e+09  6.962564e+08  3.481282e+09\n",
       "8   0.040  plant      plant  2.767454e+09  7.547601e+08  3.773801e+09\n",
       "10  0.020  plant      plant  2.921201e+09  7.966912e+08  3.983456e+09\n",
       "12  0.010  plant      plant  3.080762e+09  8.402079e+08  4.201039e+09\n",
       "14  0.004  plant      plant  3.356950e+09  9.155320e+08  4.577660e+09\n",
       "16  0.002  plant      plant  3.528684e+09  9.623684e+08  4.811842e+09\n",
       "18  0.001  plant      plant  3.698459e+09  1.008671e+09  5.043354e+09"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_damage_infra[1]['historical'].loc[osm_damage_infra[1]['historical']['asset_type'] == 'plant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "b3065e13-2e48-4dd3-b027-5d7815a9f94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.000\n",
       "1     1.000\n",
       "2     1.000\n",
       "3     0.500\n",
       "4     0.500\n",
       "5     0.500\n",
       "6     0.200\n",
       "7     0.200\n",
       "8     0.200\n",
       "9     0.100\n",
       "10    0.100\n",
       "11    0.100\n",
       "12    0.040\n",
       "13    0.040\n",
       "14    0.040\n",
       "15    0.020\n",
       "16    0.020\n",
       "17    0.020\n",
       "18    0.010\n",
       "19    0.010\n",
       "20    0.010\n",
       "21    0.004\n",
       "22    0.004\n",
       "23    0.004\n",
       "24    0.002\n",
       "25    0.002\n",
       "26    0.002\n",
       "27    0.001\n",
       "28    0.001\n",
       "29    0.001\n",
       "Name: rp, dtype: float64"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_damage_infra[0]['historical'].loc[:,\"rp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769479e-4a85-4931-af47-fb1ff09b73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def clip_gridfinder(country_code):\n",
    "    base_map_path = os.path.join(data_path,'base_map')\n",
    "\n",
    "    cty_boundary_path = os.path.join(base_map_path,'gadm41_{}.gpkg'.format(country_code))\n",
    "    cty_boundary = gpd.read_file(cty_boundary_path)\n",
    "    #mask = pd.DataFrame(mask.copy())\n",
    "    #mask.geometry = pygeos.from_shapely(mask.geometry)\n",
    "    #mask['geometry'] = reproject(mask)\n",
    "\n",
    "    gridfinder_path = r'C:\\Users\\mye500\\OneDrive - Vrije Universiteit Amsterdam\\01_Research-Projects\\01_risk_assessment\\PG_data\\gridfinder\\grid.gpkg'\n",
    "    gridfinder = gpd.read_file(gridfinder_path)\n",
    "    #gridfinder = pd.DataFrame(gridfinder.copy())\n",
    "    #gridfinder.geometry = pygeos.from_shapely(gridfinder.geometry)\n",
    "    #gridfinder['geometry'] = reproject(gridfinder)\n",
    "\n",
    "    clipped = gpd.clip(gridfinder,cty_boundary)\n",
    "\n",
    "    return clipped\n",
    "\n",
    "clip_gridfinder('TWN')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
