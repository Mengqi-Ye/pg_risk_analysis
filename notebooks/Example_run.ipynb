{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5a5263e9-087d-4863-a4e5-839dc33017bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osgeo import ogr,gdal\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pyproj\n",
    "from pygeos import from_wkb,from_wkt\n",
    "import pygeos\n",
    "from tqdm import tqdm\n",
    "from shapely.wkb import loads\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from shapely.geometry import mapping\n",
    "pd.options.mode.chained_assignment = None\n",
    "from rasterio.mask import mask\n",
    "import rioxarray\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate\n",
    "from collections.abc import Iterable\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy import integrate\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11a902-f512-4fd3-b035-af38041ee083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdal.SetConfigOption(\"OSM_CONFIG_FILE\", os.path.join('..',\"osmconf.ini\"))\n",
    "\n",
    "# change paths to make it work on your own machine\n",
    "data_path = os.path.join('C:\\\\','Data','pg_risk_analysis')\n",
    "tc_path = os.path.join(data_path,'tc_netcdf')\n",
    "fl_path = os.path.join(data_path,'GLOFRIS')\n",
    "osm_data_path = os.path.join('C:\\\\','Data','country_osm')\n",
    "pg_data_path = os.path.join(data_path,'pg_data')\n",
    "vul_curve_path = os.path.join(data_path,'vulnerability_curves','input_vulnerability_data.xlsx')\n",
    "output_path = os.path.join('C:\\\\','projects','pg_risk_analysis_output','output')\n",
    "ne_path = os.path.join(data_path,'..',\"natural_earth\",\"ne_10m_admin_0_countries.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc83d355-8c98-4ae6-97b1-3203a29a4fe1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten(xs):\n",
    "    for x in xs:\n",
    "        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):\n",
    "            yield from flatten(x)\n",
    "        else:\n",
    "            yield x\n",
    "\n",
    "def query_b(geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    This function builds an SQL query from the values passed to the retrieve() function.\n",
    "    Arguments:\n",
    "         *geoType* : Type of geometry (osm layer) to search for.\n",
    "         *keyCol* : A list of keys/columns that should be selected from the layer.\n",
    "         ***valConstraint* : A dictionary of constraints for the values. e.g. WHERE 'value'>20 or 'value'='constraint'\n",
    "    Returns:\n",
    "        *string: : a SQL query string.\n",
    "    \"\"\"\n",
    "    query = \"SELECT \" + \"osm_id\"\n",
    "    for a in keyCol: query+= \",\"+ a  \n",
    "    query += \" FROM \" + geoType + \" WHERE \"\n",
    "    # If there are values in the dictionary, add constraint clauses\n",
    "    if valConstraint: \n",
    "        for a in [*valConstraint]:\n",
    "            # For each value of the key, add the constraint\n",
    "            for b in valConstraint[a]: query += a + b\n",
    "        query+= \" AND \"\n",
    "    # Always ensures the first key/col provided is not Null.\n",
    "    query+= \"\"+str(keyCol[0]) +\" IS NOT NULL\" \n",
    "    return query \n",
    "\n",
    "\n",
    "def retrieve(osm_path,geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    Function to extract specified geometry and keys/values from OpenStreetMap\n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.     \n",
    "        *geoType* : Type of Geometry to retrieve. e.g. lines, multipolygons, etc.\n",
    "        *keyCol* : These keys will be returned as columns in the dataframe.\n",
    "        ***valConstraint: A dictionary specifiying the value constraints.  \n",
    "        A key can have multiple values (as a list) for more than one constraint for key/value.  \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all columns, geometries, and constraints specified.    \n",
    "    \"\"\"\n",
    "    driver=ogr.GetDriverByName('OSM')\n",
    "    data = driver.Open(osm_path)\n",
    "    query = query_b(geoType,keyCol,**valConstraint)\n",
    "    sql_lyr = data.ExecuteSQL(query)\n",
    "    features =[]\n",
    "    # cl = columns \n",
    "    cl = ['osm_id'] \n",
    "    for a in keyCol: cl.append(a)\n",
    "    if data is not None:\n",
    "        print('query is finished, lets start the loop')\n",
    "        for feature in tqdm(sql_lyr,desc='extract'):\n",
    "            #try:\n",
    "            if feature.GetField(keyCol[0]) is not None:\n",
    "                geom1 = (feature.geometry().ExportToWkt())\n",
    "                #print(geom1)\n",
    "                geom = from_wkt(feature.geometry().ExportToWkt()) \n",
    "                if geom is None:\n",
    "                    continue\n",
    "                # field will become a row in the dataframe.\n",
    "                field = []\n",
    "                for i in cl: field.append(feature.GetField(i))\n",
    "                field.append(geom)   \n",
    "                features.append(field)\n",
    "            #except:\n",
    "            #    print(\"WARNING: skipped OSM feature\")   \n",
    "    else:\n",
    "        print(\"ERROR: Nonetype error when requesting SQL. Check required.\")    \n",
    "    cl.append('geometry')                   \n",
    "    if len(features) > 0:\n",
    "        return pd.DataFrame(features,columns=cl)\n",
    "    else:\n",
    "        print(\"WARNING: No features or No Memory. returning empty GeoDataFrame\") \n",
    "        return pd.DataFrame(columns=['osm_id','geometry'])\n",
    "\n",
    "def power_polyline(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract all energy linestrings from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'lines',['power','voltage'])\n",
    "    \n",
    "    df = df.reset_index(drop=True).rename(columns={'power': 'asset'})\n",
    "    \n",
    "    #print(df) #check infra keys\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "# def power_polygon(osm_path): # check with joel, something was wrong here with extracting substations\n",
    "#     \"\"\"\n",
    "#     Function to extract energy polygons from OpenStreetMap  \n",
    "#     Arguments:\n",
    "#         *osm_path* : file path to the .osm.pbf file of the region \n",
    "#         for which we want to do the analysis.        \n",
    "#     Returns:\n",
    "#         *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "#     \"\"\"\n",
    "#     df = retrieve(osm_path,'multipolygons',['other_tags']) \n",
    "    \n",
    "#     df = df.loc[(df.other_tags.str.contains('power'))]   #keep rows containing power data         \n",
    "#     df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})     \n",
    "    \n",
    "#     df['asset'].loc[df['asset'].str.contains('\"power\"=>\"substation\"', case=False)]  = 'substation' #specify row\n",
    "#     df['asset'].loc[df['asset'].str.contains('\"power\"=>\"plant\"', case=False)] = 'plant' #specify row\n",
    "    \n",
    "#     df = df.loc[(df.asset == 'substation') | (df.asset == 'plant')]\n",
    "            \n",
    "#     return df.reset_index(drop=True) \n",
    "\n",
    "def electricity(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract building polygons from OpenStreetMap    \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all unique building polygons.    \n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['power'])\n",
    "    \n",
    "    df = df.reset_index(drop=True).rename(columns={'power': 'asset'})\n",
    "    \n",
    "    #df = df[df.asset!='generator']\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"substation\"', case=False)]  = 'substation' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"plant\"', case=False)] = 'plant' #specify row\n",
    "        \n",
    "    df = df.loc[(df.asset == 'substation') | (df.asset == 'plant')]\n",
    "    \n",
    "    #print(df['asset'].unique())\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "# def retrieve_poly_subs(osm_path, w_list, b_list):\n",
    "#     \"\"\"\n",
    "#     Function to extract electricity substation polygons from OpenStreetMap\n",
    "#     Arguments:\n",
    "#         *osm_path* : file path to the .osm.pbf file of the region\n",
    "#         for which we want to do the analysis.\n",
    "#         *w_list* :  white list of keywords to search in the other_tags columns\n",
    "#         *b_list* :  black list of keywords of rows that should not be selected\n",
    "#     Returns:\n",
    "#         *GeoDataFrame* : a geopandas GeoDataFrame with specified unique substation.\n",
    "#     \"\"\"\n",
    "#     df = retrieve(osm_path,'multipolygons',['other_tags'])\n",
    "#     df = df[df.other_tags.str.contains('substation', case=False, na=False)]\n",
    "#     #df = df.loc[(df.other_tags.str.contains('substation'))]\n",
    "#     df = df[~df.other_tags.str.contains('|'.join(b_list))]\n",
    "#     #df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})\n",
    "#     df['asset']  = 'substation' #specify row\n",
    "#     #df = df.loc[(df.asset == 'substation')] #specify row\n",
    "#     return df.reset_index(drop=True)\n",
    "\n",
    "def power_point(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract energy points from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"   \n",
    "    df = retrieve(osm_path,'points',['other_tags']) \n",
    "    df = df.loc[(df.other_tags.str.contains('power'))]  #keep rows containing power data       \n",
    "    df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})     \n",
    "        \n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"tower\"', case=False)]  = 'power_tower' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"pole\"', case=False)] = 'power_pole' #specify row\n",
    "    #df['asset'].loc[df['asset'].str.contains('\"utility\"=>\"power\"', case=False)] = 'power_tower' #specify row\n",
    "    \n",
    "    df = df.loc[(df.asset == 'power_tower') | (df.asset == 'power_pole')]\n",
    "            \n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36fe9f2e-0be0-47fd-83ca-67f3a272279d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reproject(df_ds, current_crs=\"epsg:4326\", approximate_crs=\"epsg:3857\"):\n",
    "\n",
    "    # Extract the input geometries as a numpy array of coordinates\n",
    "    geometries = df_ds['geometry']\n",
    "    coords = pygeos.get_coordinates(geometries)\n",
    "\n",
    "    # Transform the coordinates using pyproj\n",
    "    transformer = pyproj.Transformer.from_crs(current_crs, approximate_crs, always_xy=True)\n",
    "    new_coords = transformer.transform(coords[:, 0], coords[:, 1])\n",
    "\n",
    "    # Create a new GeoSeries with the reprojected coordinates\n",
    "    return pygeos.set_coordinates(geometries.copy(), np.array(new_coords).T)\n",
    "\n",
    "def buffer_assets(assets, buffer_size=100):\n",
    "    \"\"\"\n",
    "    Create a buffer of a specified size around the geometries in a GeoDataFrame.\n",
    "    \n",
    "    Args:\n",
    "        assets (GeoDataFrame): A GeoDataFrame containing geometries to be buffered.\n",
    "        buffer_size (int, optional): The distance in the units of the GeoDataFrame's CRS to buffer the geometries.\n",
    "            Defaults to 100.\n",
    "    \n",
    "    Returns:\n",
    "        GeoDataFrame: A new GeoDataFrame with an additional column named 'buffered' containing the buffered\n",
    "            geometries.\n",
    "    \"\"\"\n",
    "    # Create a buffer of the specified size around the geometries\n",
    "    assets['buffered'] = pygeos.buffer(assets.geometry.values, buffer_size)\n",
    "    \n",
    "    return assets\n",
    "\n",
    "def load_curves_maxdam(country_code,vul_curve_path,hazard_type):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        data_path ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    \n",
    "    # dictionary of GDP per capita ratio for each country\n",
    "    gdp_ratio = {\n",
    "        \"BRN\": {\"ratio_usa\": 0.5201},\n",
    "        \"KHM\": {\"ratio_usa\": 0.0240},\n",
    "        \"CHN\": {\"ratio_usa\": 0.1772},\n",
    "        \"IDN\": {\"ratio_usa\": 0.0647},\n",
    "        \"JPN\": {\"ratio_usa\": 0.5912},\n",
    "        \"LAO\": {\"ratio_usa\": 0.0434},\n",
    "        \"MYS\": {\"ratio_usa\": 0.1775},\n",
    "        \"MNG\": {\"ratio_usa\": 0.0703},\n",
    "        \"MMR\": {\"ratio_usa\": 0.0276},\n",
    "        \"PRK\": {\"ratio_usa\": 0.0106},\n",
    "        \"PHL\": {\"ratio_usa\": 0.0547},\n",
    "        \"SGP\": {\"ratio_usa\": 1.0091},\n",
    "        \"KOR\": {\"ratio_usa\": 0.5367},\n",
    "        \"TWN\": {\"ratio_usa\": 0.4888},\n",
    "        \"THA\": {\"ratio_usa\": 0.1034},\n",
    "        \"VNM\": {\"ratio_usa\": 0.0573},\n",
    "        \"HKG\": {\"ratio_usa\": 0.7091},\n",
    "        \"MAC\": {\"ratio_usa\": 0.5913}}\n",
    "    \n",
    "    if hazard_type == 'tc':\n",
    "        sheet_name = 'wind_curves'\n",
    "        \n",
    "        # dictionary of design wind speeds for each country\n",
    "        design_wind_speed = {\n",
    "            \"BRN\": {\"dws\": 32},\n",
    "            \"KHM\": {\"dws\": 32},\n",
    "            \"CHN\": {\"dws\": 52},\n",
    "            \"IDN\": {\"dws\": 32},\n",
    "            \"JPN\": {\"dws\": 52},\n",
    "            \"LAO\": {\"dws\": 32},\n",
    "            \"MYS\": {\"dws\": 32},\n",
    "            \"MNG\": {\"dws\": 0},\n",
    "            \"MMR\": {\"dws\": 39},\n",
    "            \"PRK\": {\"dws\": 39},\n",
    "            \"PHL\": {\"dws\": 52},\n",
    "            \"SGP\": {\"dws\": 32},\n",
    "            \"KOR\": {\"dws\": 52},\n",
    "            \"TWN\": {\"dws\": 60},\n",
    "            \"THA\": {\"dws\": 39},\n",
    "            \"VNM\": {\"dws\": 44}}\n",
    "        \n",
    "        curves = pd.read_excel(vul_curve_path,sheet_name=sheet_name,skiprows=11)\n",
    "        \n",
    "        dws = design_wind_speed.get(country_code, {}).get(\"dws\", None)\n",
    "        scaling_factor = dws / 60 #shift design wind speed of all curves to 60 m/s\n",
    "\n",
    "        curves = curves.apply(lambda x: x * scaling_factor if pd.api.types.is_numeric_dtype(x) else x)\n",
    "        \n",
    "        curves = curves.set_index('Wind speed (m/s)')\n",
    "        \n",
    "    elif hazard_type == 'fl':\n",
    "        sheet_name = 'flooding_curves'    \n",
    "        \n",
    "        # load curves and maximum damages as separate inputs\n",
    "        curves = pd.read_excel(vul_curve_path,sheet_name=sheet_name,skiprows=11,index_col=[0])\n",
    "\n",
    "    maxdam = pd.read_excel(vul_curve_path,sheet_name=sheet_name,index_col=[0],header=[0,1]).iloc[:8]\n",
    "    #maxdam = maxdam.rename({'substation_point':'substation'},level=0,axis=1)        \n",
    "        \n",
    "    curves.columns = maxdam.columns\n",
    "    \n",
    "    #interpolate the curves to fill missing values\n",
    "    curves = curves.interpolate()\n",
    "    #print(curves.tail(10))\n",
    "    \n",
    "    #transpose maxdam so its easier work with the dataframe\n",
    "    maxdam = maxdam.T\n",
    "    \n",
    "    ratio_usa = gdp_ratio.get(country_code, {}).get(\"ratio_usa\", None)\n",
    "\n",
    "    if ratio_usa is not None:\n",
    "        print(f\"The ratio_usa for {country_code} is {ratio_usa}\")\n",
    "    else:\n",
    "        print(f\"No ratio_usa found for {country_code}\")\n",
    "        \n",
    "    maxdam['MaxDam'] = maxdam['MaxDam'] * ratio_usa\n",
    "    maxdam['LowerDam'] = maxdam['LowerDam'] * ratio_usa\n",
    "    maxdam['UpperDam'] = maxdam['UpperDam'] * ratio_usa\n",
    "\n",
    "    return curves,maxdam\n",
    "\n",
    "\n",
    "def overlay_hazard_assets(df_ds, assets):\n",
    "    \"\"\"\n",
    "    Overlay a set of assets with a hazard dataset and return the subset of assets that intersect with\n",
    "    one or more hazard polygons or lines.\n",
    "    \n",
    "    Args:\n",
    "        df_ds (GeoDataFrame): A GeoDataFrame containing the hazard dataset.\n",
    "        assets (GeoDataFrame): A GeoDataFrame containing the assets to be overlaid with the hazard dataset.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: A numpy array of integers representing the indices of the hazard geometries that intersect with\n",
    "            the assets. If the assets have a 'buffered' column, the buffered geometries are used for the overlay.\n",
    "    \"\"\"\n",
    "    hazard_tree = pygeos.STRtree(df_ds.geometry.values)\n",
    "    #if (pygeos.get_type_id(assets.iloc[0].geometry) == 3) | (pygeos.get_type_id(assets.iloc[0].geometry) == 6):\n",
    "    if len(assets) > 0:\n",
    "        if (pygeos.get_type_id(assets.iloc[0].geometry) == 3) or (pygeos.get_type_id(assets.iloc[0].geometry) == 6):\n",
    "            return hazard_tree.query_bulk(assets.geometry,predicate='intersects')    \n",
    "        else:\n",
    "            return hazard_tree.query_bulk(assets.buffered,predicate='intersects')\n",
    "    \n",
    "    else:\n",
    "        return hazard_tree.query_bulk(assets.buffered,predicate='intersects')\n",
    "    \n",
    "    \n",
    "def get_damage_per_asset_per_rp(asset,df_ds,assets,curves,maxdam,return_period,country):\n",
    "    \"\"\"\n",
    "    Calculates the damage per asset per return period based on asset type, hazard curves and maximum damage\n",
    "\n",
    "    Args:\n",
    "        asset (tuple): Tuple with two dictionaries, containing the asset index and the hazard point index of the asset\n",
    "        df_ds (pandas.DataFrame): A pandas DataFrame containing hazard points with a 'geometry' column\n",
    "        assets (geopandas.GeoDataFrame): A GeoDataFrame containing asset geometries and asset type information\n",
    "        curves (dict): A dictionary with the asset types as keys and their corresponding hazard curves as values\n",
    "        maxdam (pandas.DataFrame): A pandas DataFrame containing the maximum damage for each asset type\n",
    "        return_period (str): The return period for which the damage should be calculated\n",
    "        country (str): The country for which the damage should be calculated\n",
    "\n",
    "    Returns:\n",
    "        list or tuple: Depending on the input, the function either returns a list of tuples with the asset index, the curve name and the calculated damage, or a tuple with None, None, None if no hazard points are found\n",
    "    \"\"\"\n",
    "    \n",
    "    # find the exact hazard overlays:\n",
    "    get_hazard_points = df_ds.iloc[asset[1]['hazard_point'].values].reset_index()\n",
    "    get_hazard_points = get_hazard_points.loc[pygeos.intersects(get_hazard_points.geometry.values,assets.iloc[asset[0]].geometry)]\n",
    "\n",
    "    asset_type = assets.iloc[asset[0]].asset\n",
    "    asset_geom = assets.iloc[asset[0]].geometry\n",
    "\n",
    "    if asset_type in ['plant','substation','generator']:\n",
    "        #if plant,substation are points, do not calculate the area\n",
    "        if pygeos.area(asset_geom) == 0:\n",
    "            maxdam_asset = maxdam.loc[asset_type].MaxDam\n",
    "            lowerdam_asset = maxdam.loc[asset_type].LowerDam\n",
    "            upperdam_asset = maxdam.loc[asset_type].UpperDam\n",
    "        else:\n",
    "            maxdam_asset = maxdam.loc[asset_type].MaxDam/pygeos.area(asset_geom)\n",
    "            lowerdam_asset = maxdam.loc[asset_type].LowerDam/pygeos.area(asset_geom)\n",
    "            upperdam_asset = maxdam.loc[asset_type].UpperDam/pygeos.area(asset_geom)\n",
    "    else:\n",
    "        maxdam_asset = maxdam.loc[asset_type].MaxDam\n",
    "        lowerdam_asset = maxdam.loc[asset_type].LowerDam\n",
    "        upperdam_asset = maxdam.loc[asset_type].UpperDam\n",
    "\n",
    "    hazard_intensity = curves[asset_type].index.values\n",
    "    \n",
    "    if isinstance(curves[asset_type],pd.core.series.Series):\n",
    "        fragility_values = curves[asset_type].values.flatten()\n",
    "        only_one = True\n",
    "        curve_name = curves[asset_type].name\n",
    "    elif len(curves[asset_type].columns) == 1:\n",
    "        fragility_values = curves[asset_type].values.flatten()      \n",
    "        only_one = True   \n",
    "        curve_name = curves[asset_type].columns[0]\n",
    "    else:\n",
    "        fragility_values = curves[asset_type].values#.T[0]\n",
    "        maxdam_asset = maxdam_asset.values#[0]\n",
    "        only_one = False\n",
    "\n",
    "    if len(get_hazard_points) == 0:\n",
    "        if only_one:\n",
    "            return [return_period,asset[0],curve_name,0,0,0]\n",
    "        else:\n",
    "            return [return_period,asset[0],curves[asset_type].columns[0],0,0,0]\n",
    "            \n",
    "    else:\n",
    "        if only_one:    \n",
    "            # run the calculation as normal when the asset just has a single curve\n",
    "            if pygeos.get_type_id(asset_geom) == 1:            \n",
    "                get_hazard_points['overlay_meters'] = pygeos.length(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "                return [return_period,asset[0],curve_name,np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*maxdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*lowerdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*upperdam_asset)]\n",
    "\n",
    "            elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                get_hazard_points['overlay_m2'] = pygeos.area(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "                return [return_period,asset[0],curve_name,get_hazard_points.apply(lambda x: np.interp(x[return_period],hazard_intensity, \n",
    "                                                                  fragility_values)*maxdam_asset*x.overlay_m2,axis=1).sum(),\n",
    "                                                          get_hazard_points.apply(lambda x: np.interp(x[return_period],hazard_intensity, \n",
    "                                                                  fragility_values)*lowerdam_asset*x.overlay_m2,axis=1).sum(),\n",
    "                                                          get_hazard_points.apply(lambda x: np.interp(x[return_period],hazard_intensity, \n",
    "                                                                  fragility_values)*upperdam_asset*x.overlay_m2,axis=1).sum()]  \n",
    "\n",
    "            else:\n",
    "                return [return_period,asset[0],curve_name,np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*maxdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*lowerdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*upperdam_asset)]\n",
    "        else:\n",
    "            # run the calculation when the asset has multiple curves\n",
    "            if pygeos.get_type_id(asset_geom) == 1:            \n",
    "                get_hazard_points['overlay_meters'] = pygeos.length(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                get_hazard_points['overlay_m2'] = pygeos.area(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            \n",
    "            collect_all = []\n",
    "            for iter_,curve_ids in enumerate(curves[asset_type].columns):\n",
    "                if pygeos.get_type_id(asset_geom) == 1:\n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*get_hazard_points.overlay_meters*maxdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*get_hazard_points.overlay_meters*lowerdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*get_hazard_points.overlay_meters*upperdam_asset[iter_])])\n",
    "                                   \n",
    "                elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                        get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity,\n",
    "                                                                                    fragility_values.T[iter_])*maxdam_asset[iter_]*x.overlay_m2,axis=1).sum(),\n",
    "                                        get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity,\n",
    "                                                                                    fragility_values.T[iter_])*lowerdam_asset[iter_]*x.overlay_m2,axis=1).sum(),\n",
    "                                        get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity,\n",
    "                                                                                    fragility_values.T[iter_])*upperdam_asset[iter_]*x.overlay_m2,axis=1).sum()])\n",
    "\n",
    "                else:\n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*maxdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*lowerdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*upperdam_asset[iter_])])\n",
    "            return collect_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "57465957-5b97-40c7-aa75-40e808716d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infrastructure type substation                                                \n",
      "Code                    W2_1_1   W2_1_2   W2_1_3   W2_1_4   W2_1_5   W2_1_6   \n",
      "Wind speed (m/s)                                                              \n",
      "190.666667             0.49713  0.49713  0.49713  0.49713  0.49713  0.49713  \\\n",
      "194.333333             0.49713  0.49713  0.49713  0.49713  0.49713  0.49713   \n",
      "198.000000             0.49713  0.49713  0.49713  0.49713  0.49713  0.49713   \n",
      "201.666667             0.49713  0.49713  0.49713  0.49713  0.49713  0.49713   \n",
      "205.333333             0.49713  0.49713  0.49713  0.49713  0.49713  0.49713   \n",
      "209.000000             0.49713  0.49713  0.49713  0.49713  0.49713  0.49713   \n",
      "212.666667             0.49713  0.49713  0.49713  0.49713  0.49713  0.49713   \n",
      "216.333333             0.49713  0.49713  0.49713  0.49713  0.49713  0.49713   \n",
      "220.000000             0.49713  0.49713  0.49713  0.49713  0.49713  0.49713   \n",
      "223.666667             0.49713  0.49713  0.49713  0.49713  0.49713  0.49713   \n",
      "\n",
      "Infrastructure type                                          ...      line   \n",
      "Code                   W2_2_1    W2_2_2    W2_2_3    W2_2_4  ...    W5_7_3   \n",
      "Wind speed (m/s)                                             ...             \n",
      "190.666667           0.497205  0.497205  0.497205  0.497205  ...  0.627147  \\\n",
      "194.333333           0.497205  0.497205  0.497205  0.497205  ...  0.627147   \n",
      "198.000000           0.497205  0.497205  0.497205  0.497205  ...  0.627147   \n",
      "201.666667           0.497205  0.497205  0.497205  0.497205  ...  0.627147   \n",
      "205.333333           0.497205  0.497205  0.497205  0.497205  ...  0.627147   \n",
      "209.000000           0.497205  0.497205  0.497205  0.497205  ...  0.627147   \n",
      "212.666667           0.497205  0.497205  0.497205  0.497205  ...  0.627147   \n",
      "216.333333           0.497205  0.497205  0.497205  0.497205  ...  0.627147   \n",
      "220.000000           0.497205  0.497205  0.497205  0.497205  ...  0.627147   \n",
      "223.666667           0.497205  0.497205  0.497205  0.497205  ...  0.627147   \n",
      "\n",
      "Infrastructure type                                                     \n",
      "Code                   W5_7_4    W5_7_5    W5_7_6    W5_7_7    W5_7_8   \n",
      "Wind speed (m/s)                                                        \n",
      "190.666667           0.627147  0.627147  0.627147  0.627147  0.627147  \\\n",
      "194.333333           0.627147  0.627147  0.627147  0.627147  0.627147   \n",
      "198.000000           0.627147  0.627147  0.627147  0.627147  0.627147   \n",
      "201.666667           0.627147  0.627147  0.627147  0.627147  0.627147   \n",
      "205.333333           0.627147  0.627147  0.627147  0.627147  0.627147   \n",
      "209.000000           0.627147  0.627147  0.627147  0.627147  0.627147   \n",
      "212.666667           0.627147  0.627147  0.627147  0.627147  0.627147   \n",
      "216.333333           0.627147  0.627147  0.627147  0.627147  0.627147   \n",
      "220.000000           0.627147  0.627147  0.627147  0.627147  0.627147   \n",
      "223.666667           0.627147  0.627147  0.627147  0.627147  0.627147   \n",
      "\n",
      "Infrastructure type                                          \n",
      "Code                   W5_7_9   W5_7_10   W5_7_11   W5_7_12  \n",
      "Wind speed (m/s)                                             \n",
      "190.666667           0.627147  0.627147  0.627147  0.627147  \n",
      "194.333333           0.627147  0.627147  0.627147  0.627147  \n",
      "198.000000           0.627147  0.627147  0.627147  0.627147  \n",
      "201.666667           0.627147  0.627147  0.627147  0.627147  \n",
      "205.333333           0.627147  0.627147  0.627147  0.627147  \n",
      "209.000000           0.627147  0.627147  0.627147  0.627147  \n",
      "212.666667           0.627147  0.627147  0.627147  0.627147  \n",
      "216.333333           0.627147  0.627147  0.627147  0.627147  \n",
      "220.000000           0.627147  0.627147  0.627147  0.627147  \n",
      "223.666667           0.627147  0.627147  0.627147  0.627147  \n",
      "\n",
      "[10 rows x 210 columns]\n",
      "The ratio_usa for VNM is 0.0573\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Infrastructure type</th>\n",
       "      <th colspan=\"10\" halign=\"left\">substation</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">line</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Code</th>\n",
       "      <th>W2_1_1</th>\n",
       "      <th>W2_1_2</th>\n",
       "      <th>W2_1_3</th>\n",
       "      <th>W2_1_4</th>\n",
       "      <th>W2_1_5</th>\n",
       "      <th>W2_1_6</th>\n",
       "      <th>W2_2_1</th>\n",
       "      <th>W2_2_2</th>\n",
       "      <th>W2_2_3</th>\n",
       "      <th>W2_2_4</th>\n",
       "      <th>...</th>\n",
       "      <th>W5_7_3</th>\n",
       "      <th>W5_7_4</th>\n",
       "      <th>W5_7_5</th>\n",
       "      <th>W5_7_6</th>\n",
       "      <th>W5_7_7</th>\n",
       "      <th>W5_7_8</th>\n",
       "      <th>W5_7_9</th>\n",
       "      <th>W5_7_10</th>\n",
       "      <th>W5_7_11</th>\n",
       "      <th>W5_7_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.327556</th>\n",
       "      <td>2.830435e-113</td>\n",
       "      <td>2.830435e-113</td>\n",
       "      <td>2.830435e-113</td>\n",
       "      <td>2.830435e-113</td>\n",
       "      <td>2.830435e-113</td>\n",
       "      <td>2.830435e-113</td>\n",
       "      <td>3.687061e-167</td>\n",
       "      <td>3.687061e-167</td>\n",
       "      <td>3.687061e-167</td>\n",
       "      <td>3.687061e-167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.565787</th>\n",
       "      <td>5.660870e-113</td>\n",
       "      <td>5.660870e-113</td>\n",
       "      <td>5.660870e-113</td>\n",
       "      <td>5.660870e-113</td>\n",
       "      <td>5.660870e-113</td>\n",
       "      <td>5.660870e-113</td>\n",
       "      <td>7.374122e-167</td>\n",
       "      <td>7.374122e-167</td>\n",
       "      <td>7.374122e-167</td>\n",
       "      <td>7.374122e-167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.655111</th>\n",
       "      <td>8.491306e-113</td>\n",
       "      <td>8.491306e-113</td>\n",
       "      <td>8.491306e-113</td>\n",
       "      <td>8.491306e-113</td>\n",
       "      <td>8.491306e-113</td>\n",
       "      <td>8.491306e-113</td>\n",
       "      <td>1.106118e-166</td>\n",
       "      <td>1.106118e-166</td>\n",
       "      <td>1.106118e-166</td>\n",
       "      <td>1.106118e-166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.721451</th>\n",
       "      <td>1.132174e-112</td>\n",
       "      <td>1.132174e-112</td>\n",
       "      <td>1.132174e-112</td>\n",
       "      <td>1.132174e-112</td>\n",
       "      <td>1.132174e-112</td>\n",
       "      <td>1.132174e-112</td>\n",
       "      <td>1.474824e-166</td>\n",
       "      <td>1.474824e-166</td>\n",
       "      <td>1.474824e-166</td>\n",
       "      <td>1.474824e-166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209.000000</th>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212.666667</th>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216.333333</th>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220.000000</th>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223.666667</th>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.971302e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>4.972049e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "      <td>0.627147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1197 rows Ã— 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Infrastructure type     substation                                 \n",
       "Code                        W2_1_1         W2_1_2         W2_1_3   \n",
       "Wind speed (m/s)                                                   \n",
       "0.000000              0.000000e+00   0.000000e+00   0.000000e+00  \\\n",
       "0.327556             2.830435e-113  2.830435e-113  2.830435e-113   \n",
       "0.565787             5.660870e-113  5.660870e-113  5.660870e-113   \n",
       "0.655111             8.491306e-113  8.491306e-113  8.491306e-113   \n",
       "0.721451             1.132174e-112  1.132174e-112  1.132174e-112   \n",
       "...                            ...            ...            ...   \n",
       "209.000000            4.971302e-01   4.971302e-01   4.971302e-01   \n",
       "212.666667            4.971302e-01   4.971302e-01   4.971302e-01   \n",
       "216.333333            4.971302e-01   4.971302e-01   4.971302e-01   \n",
       "220.000000            4.971302e-01   4.971302e-01   4.971302e-01   \n",
       "223.666667            4.971302e-01   4.971302e-01   4.971302e-01   \n",
       "\n",
       "Infrastructure type                                                \n",
       "Code                        W2_1_4         W2_1_5         W2_1_6   \n",
       "Wind speed (m/s)                                                   \n",
       "0.000000              0.000000e+00   0.000000e+00   0.000000e+00  \\\n",
       "0.327556             2.830435e-113  2.830435e-113  2.830435e-113   \n",
       "0.565787             5.660870e-113  5.660870e-113  5.660870e-113   \n",
       "0.655111             8.491306e-113  8.491306e-113  8.491306e-113   \n",
       "0.721451             1.132174e-112  1.132174e-112  1.132174e-112   \n",
       "...                            ...            ...            ...   \n",
       "209.000000            4.971302e-01   4.971302e-01   4.971302e-01   \n",
       "212.666667            4.971302e-01   4.971302e-01   4.971302e-01   \n",
       "216.333333            4.971302e-01   4.971302e-01   4.971302e-01   \n",
       "220.000000            4.971302e-01   4.971302e-01   4.971302e-01   \n",
       "223.666667            4.971302e-01   4.971302e-01   4.971302e-01   \n",
       "\n",
       "Infrastructure type                                                \n",
       "Code                        W2_2_1         W2_2_2         W2_2_3   \n",
       "Wind speed (m/s)                                                   \n",
       "0.000000              0.000000e+00   0.000000e+00   0.000000e+00  \\\n",
       "0.327556             3.687061e-167  3.687061e-167  3.687061e-167   \n",
       "0.565787             7.374122e-167  7.374122e-167  7.374122e-167   \n",
       "0.655111             1.106118e-166  1.106118e-166  1.106118e-166   \n",
       "0.721451             1.474824e-166  1.474824e-166  1.474824e-166   \n",
       "...                            ...            ...            ...   \n",
       "209.000000            4.972049e-01   4.972049e-01   4.972049e-01   \n",
       "212.666667            4.972049e-01   4.972049e-01   4.972049e-01   \n",
       "216.333333            4.972049e-01   4.972049e-01   4.972049e-01   \n",
       "220.000000            4.972049e-01   4.972049e-01   4.972049e-01   \n",
       "223.666667            4.972049e-01   4.972049e-01   4.972049e-01   \n",
       "\n",
       "Infrastructure type                 ...      line                       \n",
       "Code                        W2_2_4  ...    W5_7_3    W5_7_4    W5_7_5   \n",
       "Wind speed (m/s)                    ...                                 \n",
       "0.000000              0.000000e+00  ...  0.000000  0.000000  0.000000  \\\n",
       "0.327556             3.687061e-167  ...  0.000000  0.000000  0.000000   \n",
       "0.565787             7.374122e-167  ...  0.000000  0.000000  0.000000   \n",
       "0.655111             1.106118e-166  ...  0.000000  0.000000  0.000000   \n",
       "0.721451             1.474824e-166  ...  0.000000  0.000000  0.000000   \n",
       "...                            ...  ...       ...       ...       ...   \n",
       "209.000000            4.972049e-01  ...  0.627147  0.627147  0.627147   \n",
       "212.666667            4.972049e-01  ...  0.627147  0.627147  0.627147   \n",
       "216.333333            4.972049e-01  ...  0.627147  0.627147  0.627147   \n",
       "220.000000            4.972049e-01  ...  0.627147  0.627147  0.627147   \n",
       "223.666667            4.972049e-01  ...  0.627147  0.627147  0.627147   \n",
       "\n",
       "Infrastructure type                                                     \n",
       "Code                   W5_7_6    W5_7_7    W5_7_8    W5_7_9   W5_7_10   \n",
       "Wind speed (m/s)                                                        \n",
       "0.000000             0.000000  0.000000  0.000000  0.000000  0.000000  \\\n",
       "0.327556             0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "0.565787             0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "0.655111             0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "0.721451             0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "209.000000           0.627147  0.627147  0.627147  0.627147  0.627147   \n",
       "212.666667           0.627147  0.627147  0.627147  0.627147  0.627147   \n",
       "216.333333           0.627147  0.627147  0.627147  0.627147  0.627147   \n",
       "220.000000           0.627147  0.627147  0.627147  0.627147  0.627147   \n",
       "223.666667           0.627147  0.627147  0.627147  0.627147  0.627147   \n",
       "\n",
       "Infrastructure type                      \n",
       "Code                  W5_7_11   W5_7_12  \n",
       "Wind speed (m/s)                         \n",
       "0.000000             0.000000  0.000000  \n",
       "0.327556             0.000000  0.000000  \n",
       "0.565787             0.000000  0.000000  \n",
       "0.655111             0.000000  0.000000  \n",
       "0.721451             0.000000  0.000000  \n",
       "...                       ...       ...  \n",
       "209.000000           0.627147  0.627147  \n",
       "212.666667           0.627147  0.627147  \n",
       "216.333333           0.627147  0.627147  \n",
       "220.000000           0.627147  0.627147  \n",
       "223.666667           0.627147  0.627147  \n",
       "\n",
       "[1197 rows x 210 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_curves_maxdam('VNM',vul_curve_path,'tc')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62cc89fb-7f17-40ee-b3a2-c94675ab6532",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Specific occupancy</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Type vulnerability data</th>\n",
       "      <th>Cost type</th>\n",
       "      <th>Unit</th>\n",
       "      <th>MaxDam</th>\n",
       "      <th>LowerDam</th>\n",
       "      <th>UpperDam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infrastructure type</th>\n",
       "      <th>Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">substation</th>\n",
       "      <th>W2_1_1</th>\n",
       "      <td>Open</td>\n",
       "      <td>Watson and Etemadi, 2020</td>\n",
       "      <td>curve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>4748773.05</td>\n",
       "      <td>3561579.7875</td>\n",
       "      <td>5935966.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2_1_2</th>\n",
       "      <td>Open</td>\n",
       "      <td>Watson and Etemadi, 2020</td>\n",
       "      <td>curve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>2933686.462</td>\n",
       "      <td>2200264.8465</td>\n",
       "      <td>3667108.0775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2_1_3</th>\n",
       "      <td>Open</td>\n",
       "      <td>Watson and Etemadi, 2020</td>\n",
       "      <td>curve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>1582924.35</td>\n",
       "      <td>1187193.2625</td>\n",
       "      <td>1978655.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2_1_4</th>\n",
       "      <td>Open</td>\n",
       "      <td>Watson and Etemadi, 2020</td>\n",
       "      <td>curve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>997242.3405</td>\n",
       "      <td>747931.755375</td>\n",
       "      <td>1246552.925625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W2_1_5</th>\n",
       "      <td>Open</td>\n",
       "      <td>Watson and Etemadi, 2020</td>\n",
       "      <td>curve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>838949.9055</td>\n",
       "      <td>629212.429125</td>\n",
       "      <td>1048687.381875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">line</th>\n",
       "      <th>W5_7_8</th>\n",
       "      <td>Transmission line</td>\n",
       "      <td>Xue et al., 2020</td>\n",
       "      <td>curve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>154.277353</td>\n",
       "      <td>115.708015</td>\n",
       "      <td>192.846691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W5_7_9</th>\n",
       "      <td>Transmission line</td>\n",
       "      <td>Xue et al., 2020</td>\n",
       "      <td>curve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>182.328348</td>\n",
       "      <td>136.746261</td>\n",
       "      <td>227.910435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W5_7_10</th>\n",
       "      <td>Transmission line</td>\n",
       "      <td>Xue et al., 2020</td>\n",
       "      <td>curve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>228.612052</td>\n",
       "      <td>171.459039</td>\n",
       "      <td>285.765065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W5_7_11</th>\n",
       "      <td>Transmission line</td>\n",
       "      <td>Xue et al., 2020</td>\n",
       "      <td>curve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>251.472759</td>\n",
       "      <td>188.604569</td>\n",
       "      <td>314.340949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W5_7_12</th>\n",
       "      <td>Transmission line</td>\n",
       "      <td>Xue et al., 2020</td>\n",
       "      <td>curve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>297.195419</td>\n",
       "      <td>222.896564</td>\n",
       "      <td>371.494273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Specific occupancy                 Reference   \n",
       "Infrastructure type Code                                                   \n",
       "substation          W2_1_1                Open  Watson and Etemadi, 2020  \\\n",
       "                    W2_1_2                Open  Watson and Etemadi, 2020   \n",
       "                    W2_1_3                Open  Watson and Etemadi, 2020   \n",
       "                    W2_1_4                Open  Watson and Etemadi, 2020   \n",
       "                    W2_1_5                Open  Watson and Etemadi, 2020   \n",
       "...                                        ...                       ...   \n",
       "line                W5_7_8   Transmission line          Xue et al., 2020   \n",
       "                    W5_7_9   Transmission line          Xue et al., 2020   \n",
       "                    W5_7_10  Transmission line          Xue et al., 2020   \n",
       "                    W5_7_11  Transmission line          Xue et al., 2020   \n",
       "                    W5_7_12  Transmission line          Xue et al., 2020   \n",
       "\n",
       "                            Type vulnerability data Cost type           Unit   \n",
       "Infrastructure type Code                                                       \n",
       "substation          W2_1_1                    curve       NaN  euro/facility  \\\n",
       "                    W2_1_2                    curve       NaN  euro/facility   \n",
       "                    W2_1_3                    curve       NaN  euro/facility   \n",
       "                    W2_1_4                    curve       NaN  euro/facility   \n",
       "                    W2_1_5                    curve       NaN  euro/facility   \n",
       "...                                             ...       ...            ...   \n",
       "line                W5_7_8                    curve       NaN         euro/m   \n",
       "                    W5_7_9                    curve       NaN         euro/m   \n",
       "                    W5_7_10                   curve       NaN         euro/m   \n",
       "                    W5_7_11                   curve       NaN         euro/m   \n",
       "                    W5_7_12                   curve       NaN         euro/m   \n",
       "\n",
       "                                  MaxDam       LowerDam        UpperDam  \n",
       "Infrastructure type Code                                                 \n",
       "substation          W2_1_1    4748773.05   3561579.7875    5935966.3125  \n",
       "                    W2_1_2   2933686.462   2200264.8465    3667108.0775  \n",
       "                    W2_1_3    1582924.35   1187193.2625    1978655.4375  \n",
       "                    W2_1_4   997242.3405  747931.755375  1246552.925625  \n",
       "                    W2_1_5   838949.9055  629212.429125  1048687.381875  \n",
       "...                                  ...            ...             ...  \n",
       "line                W5_7_8    154.277353     115.708015      192.846691  \n",
       "                    W5_7_9    182.328348     136.746261      227.910435  \n",
       "                    W5_7_10   228.612052     171.459039      285.765065  \n",
       "                    W5_7_11   251.472759     188.604569      314.340949  \n",
       "                    W5_7_12   297.195419     222.896564      371.494273  \n",
       "\n",
       "[210 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brn_load[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9896d9f-4592-4552-8876-c1340f3e09f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_storm_data(climate_model,basin,bbox):\n",
    "    \"\"\"\n",
    "    Load storm data from a NetCDF file and process it to return a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - climate_model (str): name of the climate model\n",
    "    - basin (str): name of the basin\n",
    "    - bbox (tuple): bounding box coordinates in the format (minx, miny, maxx, maxy)\n",
    "    - ne_crs (str): CRS string of the North-East projection\n",
    "\n",
    "    Returns:\n",
    "    - df_ds (pd.DataFrame): pandas DataFrame with interpolated wind speeds for different return periods and geometry column\n",
    "    \"\"\"\n",
    "    # set paths\n",
    "    # data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "\n",
    "    filename = os.path.join(tc_path, f'STORM_FIXED_RETURN_PERIODS{climate_model}_{basin}.nc')\n",
    "    \n",
    "    # load data from NetCDF file\n",
    "    with xr.open_dataset(filename) as ds:\n",
    "        \n",
    "        # convert data to WGS84 CRS\n",
    "        ds.rio.write_crs(4326, inplace=True)\n",
    "        ds = ds.rio.clip_box(minx=bbox[0], miny=bbox[1], maxx=bbox[2], maxy=bbox[3])\n",
    "        \n",
    "        #convert 10-min sustained wind speed to 3-s gust wind speed\n",
    "        ds['mean_3s'] = ds['mean']/0.88*1.11\n",
    "\n",
    "        # get the mean values\n",
    "        df_ds = ds['mean_3s'].to_dataframe().unstack(level=2).reset_index()\n",
    "\n",
    "        # create geometry values and drop lat lon columns\n",
    "        df_ds['geometry'] = [pygeos.points(x) for x in list(zip(df_ds['lon'], df_ds['lat']))]\n",
    "        df_ds = df_ds.drop(['lat', 'lon'], axis=1, level=0)\n",
    "        \n",
    "        # interpolate wind speeds of 1,2,5,25,and 250-yr return period\n",
    "        ## rename columns to return periods (must be integer for interpolating)\n",
    "        df_ds_geometry = pd.DataFrame()\n",
    "        df_ds_geometry['geometry'] = df_ds['geometry']\n",
    "        df_ds = df_ds.drop(['geometry'], axis=1, level=0)\n",
    "        df_ds = df_ds['mean_3s']\n",
    "        df_ds.columns = [int(x) for x in ds['mean_3s']['rp']]\n",
    "        df_ds[1] = np.nan\n",
    "        df_ds[2] = np.nan\n",
    "        df_ds[5] = np.nan\n",
    "        df_ds[25] = np.nan\n",
    "        df_ds[250] = np.nan\n",
    "        df_ds = df_ds.reindex(sorted(df_ds.columns), axis=1)\n",
    "        df_ds = df_ds.interpolate(method='pchip', axis=1, limit_direction='both')\n",
    "        df_ds['geometry'] = df_ds_geometry['geometry']\n",
    "        df_ds = df_ds[[1, 2, 5, 10, 25, 50, 100, 250, 500, 1000, 'geometry']]\n",
    "        \n",
    "        # rename columns to return periods\n",
    "        df_ds.columns = ['1_{}{}'.format(int(x), climate_model) for x in [1, 2, 5, 10, 25, 50, 100, 250, 500, 1000]] +['geometry']\n",
    "        df_ds['geometry'] = pygeos.buffer(df_ds.geometry, radius=0.1/2, cap_style='square').values\n",
    "        \n",
    "        # reproject the geometry column to the specified CRS\n",
    "        df_ds['geometry'] = reproject(df_ds)\n",
    "            \n",
    "        # drop all non values to reduce size\n",
    "        #df_ds = df_ds.loc[~df_ds['1_10000{}'.format(climate_model)].isna()].reset_index(drop=True)\n",
    "        df_ds = df_ds.fillna(0)\n",
    "\n",
    "    return df_ds\n",
    "\n",
    "def open_storm_data(country_code):\n",
    "    \"\"\"\n",
    "    This function loads STORM data for a given country code, clips it based on the country geometry,\n",
    "    and combines data from different basins and climate models.\n",
    "\n",
    "    Args:\n",
    "    - country_code (str): a 3-letter ISO code of the country of interest\n",
    "\n",
    "    Returns:\n",
    "    - df_ds (dict): a dictionary containing STORM data for different climate models, organized by basin\n",
    "    \"\"\"\n",
    "    # set paths\n",
    "    # data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "    \n",
    "    # list of available climate models\n",
    "    climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "\n",
    "    # dictionary of basins for each country\n",
    "    country_basin = {\n",
    "        \"BRN\": [\"WP\"],\n",
    "        \"KHM\": [\"WP\"],\n",
    "        \"CHN\": [\"WP\", \"NI\"],\n",
    "        \"IDN\": [\"SI\", \"SP\", \"NI\", \"WP\"],\n",
    "        \"JPN\": [\"WP\"],\n",
    "        \"LAO\": [\"WP\"],\n",
    "        \"MYS\": [\"WP\", \"NI\"],\n",
    "        \"MNG\": [\"WP\", \"NI\"],\n",
    "        \"MMR\": [\"NI\", \"WP\"],\n",
    "        \"PRK\": [\"WP\"],\n",
    "        \"PHL\": [\"WP\"],\n",
    "        \"SGP\": [\"WP\"],\n",
    "        \"KOR\": [\"WP\"],\n",
    "        \"TWN\": [\"WP\"],\n",
    "        \"THA\": [\"WP\", \"NI\"],\n",
    "        \"VNM\": [\"WP\"]\n",
    "    }\n",
    "\n",
    "    # load country geometry file and create geometry to clip\n",
    "    ne_countries = gpd.read_file(os.path.join(data_path,'..',\"natural_earth\",\"ne_10m_admin_0_countries.shp\"))\n",
    "    bbox = ne_countries.loc[ne_countries['ISO_A3']==country_code].geometry.buffer(1).values[0].bounds\n",
    "    # ne_countries = gpd.read_file('C:/Users/mye500/OneDrive - Vrije Universiteit Amsterdam/01_Research-Projects/01_risk_assessment/base_map/base_map_adm_0.gpkg')\n",
    "    # bbox = ne_countries.loc[ne_countries['GID_0']==country_code].geometry.buffer(1).values[0].bounds\n",
    "\n",
    "    df_ds = {}\n",
    "    for climate_model in climate_models:\n",
    "        concat_prep = []\n",
    "\n",
    "        #combine STORM data from different basins\n",
    "        if \"WP\" in country_basin[country_code]:\n",
    "            WP = load_storm_data(climate_model,'WP',bbox)\n",
    "            concat_prep.append(WP)\n",
    "        if \"SP\" in country_basin[country_code]:\n",
    "            SP = load_storm_data(climate_model,'SP',bbox)\n",
    "            concat_prep.append(SP)\n",
    "        if \"NI\" in country_basin[country_code]:            \n",
    "            NI = load_storm_data(climate_model,'NI',bbox)\n",
    "            concat_prep.append(NI)            \n",
    "        if \"SI\" in country_basin[country_code]:       \n",
    "            SI = load_storm_data(climate_model,'SI',bbox)\n",
    "            concat_prep.append(SI)            \n",
    "                   \n",
    "        df_ds_cl = pd.concat(concat_prep, keys=country_basin[country_code])\n",
    "        df_ds_cl = df_ds_cl.reset_index(drop=True)\n",
    "        df_ds[climate_model] = df_ds_cl\n",
    "\n",
    "    return df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a2c41cd1-23bd-45ab-84d7-ef3b005b19e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twn_wind = open_storm_data('TWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "67f24e70-2570-4b51-b5a2-d238b74abba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "brn_wind = open_storm_data('BRN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "82fa52fa-65fc-45d7-b4fe-c988a1d32855",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_1000</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.881390</td>\n",
       "      <td>POLYGON ((12579102.46 568480.588, 12579102.46 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.803687</td>\n",
       "      <td>POLYGON ((12590234.409 568480.588, 12590234.40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.622256</td>\n",
       "      <td>POLYGON ((12601366.358 568480.588, 12601366.35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.560145</td>\n",
       "      <td>POLYGON ((12612498.307 568480.588, 12612498.30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.383634</td>\n",
       "      <td>POLYGON ((12623630.256 568480.588, 12623630.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>27.470805</td>\n",
       "      <td>POLYGON ((12913060.932 680335.356, 12913060.93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>27.363381</td>\n",
       "      <td>POLYGON ((12924192.881 680335.356, 12924192.88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>27.361039</td>\n",
       "      <td>POLYGON ((12935324.83 680335.356, 12935324.83 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>27.350224</td>\n",
       "      <td>POLYGON ((12946456.779 680335.356, 12946456.77...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>27.534547</td>\n",
       "      <td>POLYGON ((12957588.728 680335.356, 12957588.72...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>385 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1_1000                                           geometry\n",
       "0    25.881390  POLYGON ((12579102.46 568480.588, 12579102.46 ...\n",
       "1    25.803687  POLYGON ((12590234.409 568480.588, 12590234.40...\n",
       "2    25.622256  POLYGON ((12601366.358 568480.588, 12601366.35...\n",
       "3    25.560145  POLYGON ((12612498.307 568480.588, 12612498.30...\n",
       "4    25.383634  POLYGON ((12623630.256 568480.588, 12623630.25...\n",
       "..         ...                                                ...\n",
       "380  27.470805  POLYGON ((12913060.932 680335.356, 12913060.93...\n",
       "381  27.363381  POLYGON ((12924192.881 680335.356, 12924192.88...\n",
       "382  27.361039  POLYGON ((12935324.83 680335.356, 12935324.83 ...\n",
       "383  27.350224  POLYGON ((12946456.779 680335.356, 12946456.77...\n",
       "384  27.534547  POLYGON ((12957588.728 680335.356, 12957588.72...\n",
       "\n",
       "[385 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brn_wind[''][['1_1000','geometry']] #climate_model, return_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e9b1fa7-e368-4f50-a046-0ee32690bad2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.714411149336897"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ne\n",
    "brn_wind['_CMCC-CM2-VHR4']['1_1_CMCC-CM2-VHR4'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6b43b71-49ee-4aee-aca7-db18ecbd8b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.77332750074388"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gdam\n",
    "twn_wind('TWN')['_CMCC-CM2-VHR4']#['1_1_CMCC-CM2-VHR4'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9c7ff6dd-a3f2-4e2a-becd-e5cffa38edde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clip_flood_data(country_code):\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "\n",
    "    # load country geometry file and create geometry to clip\n",
    "    ne_countries = gpd.read_file(ne_path)\n",
    "    geometry = ne_countries.loc[ne_countries['ISO_A3']==country_code].geometry.values[0]\n",
    "    geoms = [mapping(geometry)]\n",
    "    \n",
    "    #climate_model: historical, rcp4p5, rcp8p5; time_period: hist, 2030, 2050, 2080\n",
    "    rps = ['0001','0002','0005','0010','0025','0050','0100','0250','0500','1000']\n",
    "    climate_models = ['historical','rcp8p5']\n",
    "    \n",
    "    for rp in rps:\n",
    "        #global input_file\n",
    "        for climate_model in climate_models:\n",
    "            if climate_model=='historical':\n",
    "                input_file = os.path.join(fl_path,'global',\n",
    "                                          'inuncoast_{}_nosub_hist_rp{}_0.tif'.format(climate_model,rp)) \n",
    " \n",
    "            elif climate_model=='rcp8p5':\n",
    "                input_file = os.path.join(fl_path,'global',\n",
    "                                          'inuncoast_{}_nosub_2030_rp{}_0.tif'.format(climate_model,rp))\n",
    "\n",
    "            # load raster file and save clipped version\n",
    "            with rasterio.open(input_file) as src:\n",
    "                out_image, out_transform = mask(src, geoms, crop=True)\n",
    "                out_meta = src.meta\n",
    "\n",
    "                out_meta.update({\"driver\": \"GTiff\",\n",
    "                         \"height\": out_image.shape[1],\n",
    "                         \"width\": out_image.shape[2],\n",
    "                         \"transform\": out_transform})\n",
    "\n",
    "                if 'scistor' in fl_path:\n",
    "                    file_path = os.path.join(fl_path,'country','_'.join([country_code]+input_file.split('_')[6:]))\n",
    "                else:\n",
    "                    file_path = os.path.join(fl_path,'country','_'.join([country_code]+input_file.split('_')[3:]))\n",
    "\n",
    "                with rasterio.open(file_path, \"w\", **out_meta) as dest:\n",
    "                    dest.write(out_image)\n",
    "\n",
    "def load_flood_data(country_code,climate_model):\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "     \n",
    "    rps = ['0001','0002','0005','0010','0025','0050','0100','0250','0500','1000']\n",
    "    collect_df_ds = []\n",
    "    \n",
    "    if climate_model=='historical':\n",
    "        print('Loading historical coastal flood data ...')\n",
    "        for rp in rps:\n",
    "            #for file in files:\n",
    "            file_path = os.path.join(fl_path,'country','{}_{}_nosub_hist_rp{}_0.tif'.format(country_code,climate_model,rp))\n",
    "            with xr.open_dataset(file_path) as ds: #, engine=\"rasterio\"\n",
    "                df_ds = ds.to_dataframe().reset_index()\n",
    "                df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "                df_ds = df_ds.rename(columns={'band_data': 'rp'+rp}) #rename to return period\n",
    "                \n",
    "                # move from meters to centimeters\n",
    "                df_ds['rp'+rp] = (df_ds['rp'+rp]*100)         \n",
    "                df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "                df_ds = df_ds.dropna()\n",
    "                df_ds = df_ds.reset_index(drop=True)\n",
    "                df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=0.0089932/2,cap_style='square').values  # the original value here is 0.00833???\n",
    "                df_ds['geometry'] = reproject(df_ds)\n",
    "                collect_df_ds.append(df_ds)\n",
    "\n",
    "        df_all = collect_df_ds[0].merge(collect_df_ds[1]).merge(collect_df_ds[2]).merge(collect_df_ds[3]).merge(collect_df_ds[4])\\\n",
    "                 .merge(collect_df_ds[5]).merge(collect_df_ds[6]).merge(collect_df_ds[7]).merge(collect_df_ds[8]).merge(collect_df_ds[9])\n",
    "        df_all = df_all.loc[df_all['rp1000']>0].reset_index(drop=True)\n",
    "\n",
    "    elif climate_model=='rcp8p5':\n",
    "        print('Loading future coastal flood data ...')\n",
    "        for rp in rps:\n",
    "            #for file in files:\n",
    "            file_path = os.path.join(fl_path,'country','{}_{}_nosub_2030_rp{}_0.tif'.format(country_code,climate_model,rp))\n",
    "            with xr.open_dataset(file_path) as ds: #, engine=\"rasterio\"\n",
    "                df_ds = ds.to_dataframe().reset_index()\n",
    "                df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "                df_ds = df_ds.rename(columns={'band_data': 'rp'+rp}) #rename to return period\n",
    "                df_ds['rp'+rp] = (df_ds['rp'+rp]*100)\n",
    "                df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "                df_ds = df_ds.dropna()\n",
    "                df_ds = df_ds.reset_index(drop=True)\n",
    "                df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=0.00833/2,cap_style='square').values\n",
    "                df_ds['geometry'] = reproject(df_ds)\n",
    "                collect_df_ds.append(df_ds)\n",
    "\n",
    "        df_all = collect_df_ds[0].merge(collect_df_ds[1]).merge(collect_df_ds[2]).merge(collect_df_ds[3]).merge(collect_df_ds[4])\\\n",
    "                 .merge(collect_df_ds[5]).merge(collect_df_ds[6]).merge(collect_df_ds[7]).merge(collect_df_ds[8]).merge(collect_df_ds[9])\n",
    "\n",
    "        df_all = df_all.loc[df_all['rp1000']>0].reset_index(drop=True)\n",
    "    return df_all\n",
    "\n",
    "def open_flood_data(country_code):\n",
    "    climate_models = ['historical','rcp8p5']\n",
    "    df_ds = {}\n",
    "    for climate_model in climate_models:\n",
    "        df_ds_sc = load_flood_data(country_code,climate_model)\n",
    "        df_ds[climate_model] = df_ds_sc\n",
    "    \n",
    "    return df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2160cb1f-75ac-48f0-898e-6fdcb8bb3b59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clip_flood_data('KOR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e5ac9f48-e434-4893-8c04-07e663921d94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n",
      "CPU times: total: 2min 9s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "khm_flood = open_flood_data('KHM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c26e2932-90c7-45e5-ad13-e7d43c4ea94d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rp0001</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.138884</td>\n",
       "      <td>POLYGON ((11460378.305 1301203.722, 11460378.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34.355808</td>\n",
       "      <td>POLYGON ((11461305.968 1298362.747, 11461305.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99.879242</td>\n",
       "      <td>POLYGON ((11462233.63 1312570.176, 11462233.63...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>162.722992</td>\n",
       "      <td>POLYGON ((11462233.63 1311622.815, 11462233.63...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>171.230804</td>\n",
       "      <td>POLYGON ((11462233.63 1310675.482, 11462233.63...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>22.372198</td>\n",
       "      <td>POLYGON ((11601382.994 1183982.151, 11601382.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>4.255009</td>\n",
       "      <td>POLYGON ((11602310.656 1183982.151, 11602310.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>7.622194</td>\n",
       "      <td>POLYGON ((11603238.318 1183982.151, 11603238.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>20.360147</td>\n",
       "      <td>POLYGON ((11604165.981 1183982.151, 11604165.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>22.591734</td>\n",
       "      <td>POLYGON ((11605093.643 1183982.151, 11605093.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rp0001                                           geometry\n",
       "1     20.138884  POLYGON ((11460378.305 1301203.722, 11460378.3...\n",
       "6     34.355808  POLYGON ((11461305.968 1298362.747, 11461305.9...\n",
       "7     99.879242  POLYGON ((11462233.63 1312570.176, 11462233.63...\n",
       "8    162.722992  POLYGON ((11462233.63 1311622.815, 11462233.63...\n",
       "9    171.230804  POLYGON ((11462233.63 1310675.482, 11462233.63...\n",
       "..          ...                                                ...\n",
       "321   22.372198  POLYGON ((11601382.994 1183982.151, 11601382.9...\n",
       "327    4.255009  POLYGON ((11602310.656 1183982.151, 11602310.6...\n",
       "331    7.622194  POLYGON ((11603238.318 1183982.151, 11603238.3...\n",
       "334   20.360147  POLYGON ((11604165.981 1183982.151, 11604165.9...\n",
       "336   22.591734  POLYGON ((11605093.643 1183982.151, 11605093.6...\n",
       "\n",
       "[155 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = khm_flood['historical'][['rp0001','geometry']] #climate_model, return_period\n",
    "df1 = df1[~df1.eq(0).any(axis=1)]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8379514b-d544-4d13-bf2a-b1b8761094a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rp0100</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.124001</td>\n",
       "      <td>POLYGON ((11460378.305 1301203.722, 11460378.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.177502</td>\n",
       "      <td>POLYGON ((11461305.968 1312570.176, 11461305.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.686016</td>\n",
       "      <td>POLYGON ((11461305.968 1300256.702, 11461305.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.513527</td>\n",
       "      <td>POLYGON ((11461305.968 1299309.71, 11461305.96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80.326653</td>\n",
       "      <td>POLYGON ((11461305.968 1298362.747, 11461305.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>81.774506</td>\n",
       "      <td>POLYGON ((11620863.904 1172659.691, 11620863.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>46.028496</td>\n",
       "      <td>POLYGON ((11621791.567 1172659.691, 11621791.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>36.697803</td>\n",
       "      <td>POLYGON ((11622719.229 1171716.318, 11622719.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>20.580435</td>\n",
       "      <td>POLYGON ((11622719.229 1170772.971, 11622719.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>36.754047</td>\n",
       "      <td>POLYGON ((11623646.892 1170772.971, 11623646.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rp0100                                           geometry\n",
       "1    63.124001  POLYGON ((11460378.305 1301203.722, 11460378.3...\n",
       "2    26.177502  POLYGON ((11461305.968 1312570.176, 11461305.9...\n",
       "4    36.686016  POLYGON ((11461305.968 1300256.702, 11461305.9...\n",
       "5    27.513527  POLYGON ((11461305.968 1299309.71, 11461305.96...\n",
       "6    80.326653  POLYGON ((11461305.968 1298362.747, 11461305.9...\n",
       "..         ...                                                ...\n",
       "342  81.774506  POLYGON ((11620863.904 1172659.691, 11620863.9...\n",
       "344  46.028496  POLYGON ((11621791.567 1172659.691, 11621791.5...\n",
       "346  36.697803  POLYGON ((11622719.229 1171716.318, 11622719.2...\n",
       "347  20.580435  POLYGON ((11622719.229 1170772.971, 11622719.2...\n",
       "350  36.754047  POLYGON ((11623646.892 1170772.971, 11623646.8...\n",
       "\n",
       "[282 rows x 2 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = khm_flood['historical'][['rp0100','geometry']] #climate_model, return_period\n",
    "df2 = df2[~df2.eq(0).any(axis=1)]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "44a7afcc-11b5-47da-8ffc-bdb9a28134eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    }
   ],
   "source": [
    "twn_flood = open_flood_data('TWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6421d39c-a12a-488b-8c89-e62484c90543",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twn_flood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3de688-606c-4dd2-abe3-f37015c7442e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OSM data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "934161b6-5f01-4315-87b3-9e4a7bd70876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_osm_infrastructure(country_code,osm_data_path):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        country_code (_type_): _description_\n",
    "        osm_data_path (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "    \n",
    "    # lines\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    osm_lines = power_polyline(osm_path)\n",
    "    osm_lines['geometry'] = reproject(osm_lines)\n",
    "    osm_lines = buffer_assets(osm_lines.loc[osm_lines.asset.isin(\n",
    "        ['cable','minor_cable','line','minor_line'])],buffer_size=100).reset_index(drop=True)\n",
    "    \n",
    "    # polygons\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    osm_polygons = electricity(osm_path)\n",
    "    osm_polygons['geometry'] = reproject(osm_polygons)\n",
    "    \n",
    "    # points\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    osm_points = power_point(osm_path)\n",
    "    osm_points['geometry'] = reproject(osm_points)\n",
    "    osm_points = buffer_assets(osm_points.loc[osm_points.asset.isin(\n",
    "        ['power_tower','power_pole'])],buffer_size=100).reset_index(drop=True)\n",
    "    \n",
    "    return osm_lines,osm_polygons,osm_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b16fbb7a-d740-4b39-bfdd-127321fb4cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:00<00:00, 491.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:00<00:00, 74.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plant' 'substation']\n",
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8774/8774 [00:00<00:00, 9235.45it/s]\n"
     ]
    }
   ],
   "source": [
    "osm_power_infra = extract_osm_infrastructure('BRN',osm_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de54851e-4aaa-4e38-88fc-a27efb33c918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#NEW VERSION!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "def assess_damage_osm(country_code,osm_power_infra,hazard_type): #NEW VERSION\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "\n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(country_code,vul_curve_path,hazard_type)\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    osm_lines,osm_poly,osm_points = osm_power_infra\n",
    "    \n",
    "    #calculate damaged lines/polygons/points in loop by climate_model\n",
    "    damaged_lines = {}\n",
    "    damaged_poly = {}\n",
    "    damaged_points = {}\n",
    "\n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "        df_ds = open_storm_data(country_code)\n",
    "\n",
    "        # remove assets that will not have any damage\n",
    "        osm_lines = osm_lines.loc[osm_lines.asset != 'cable'].reset_index(drop=True)\n",
    "        osm_lines['asset'] = osm_lines['asset'].replace(['minor_line'], 'line')\n",
    "        osm_poly = osm_poly.loc[osm_poly.asset != 'plant'].reset_index(drop=True)            \n",
    "    \n",
    "    elif hazard_type=='fl':\n",
    "        # read flood data\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "        df_ds = open_flood_data(country_code)\n",
    "    \n",
    "        \n",
    "    for climate_model in climate_models:\n",
    "        if hazard_type=='tc':\n",
    "            return_periods = ['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),'1_10{}'.format(climate_model),\n",
    "                              '1_25{}'.format(climate_model),'1_50{}'.format(climate_model),'1_100{}'.format(climate_model),\n",
    "                              '1_250{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "        elif hazard_type == 'fl':\n",
    "            return_periods = ['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000']     \n",
    "    \n",
    "        # assess damage for lines\n",
    "        #print(df_ds[climate_model])\n",
    "        #print(overlay_hazard_assets(df_ds[climate_model],osm_lines).T)\n",
    "        overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_lines).T,\n",
    "                                     columns=['asset','hazard_point','geometry'])\n",
    "        \n",
    "        overlay_lines_new = overlay_lines\n",
    "        overlay_lines_new['geometry'] = None\n",
    "        for index, row in overlay_lines_new.iterrows():\n",
    "            hazard_point = row['hazard_point']\n",
    "            geometry = df_ds[climate_model].loc[hazard_point, 'geometry']\n",
    "            overlay_lines_new.at[index, 'geometry'] = geometry\n",
    "            \n",
    "        overlay_lines_new.to_excel(os.path.join(output_path,f'{country_code}_overlay_lines_{climate_model}.xlsx'))\n",
    "\n",
    "\n",
    "        if len(overlay_lines) == 0:\n",
    "            damaged_lines[climate_model] = pd.DataFrame()\n",
    "\n",
    "        else:\n",
    "            collect_line_damages = []\n",
    "            for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                              desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_line_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                            df_ds[climate_model],\n",
    "                                                                            osm_lines,\n",
    "                                                                            curves,\n",
    "                                                                            maxdam,\n",
    "                                                                            return_period,\n",
    "                                                                            country_code))\n",
    "\n",
    "            get_asset_type_line = dict(zip(osm_lines.index,osm_lines.asset))\n",
    "            \n",
    "            if hazard_type == 'tc':\n",
    "                results = pd.DataFrame([item for sublist in collect_line_damages\n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "                damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "            elif hazard_type == 'fl':\n",
    "                #results = pd.DataFrame(collect_line_damages,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                results = pd.DataFrame(np.array(list(flatten(collect_line_damages))).reshape(\n",
    "                    int(len(list(flatten(collect_line_damages)))/6), 6),\n",
    "                                       columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                results['asset'] = results['asset'].astype(int)\n",
    "                results[['meandam','lowerdam','upperdam']] = results[['meandam','lowerdam','upperdam']].astype(float)\n",
    "                \n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "                #sum damage of line, cable, and minor_line\n",
    "                results['curve'] = results['curve'].replace(['cable', 'minor_line'], 'line')\n",
    "                results['asset_type'] = results['asset_type'].replace(['cable', 'minor_line'], 'line')\n",
    "\n",
    "                damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "                \n",
    "        # assess damage for polygons\n",
    "        if len(osm_poly) > 0:\n",
    "            overlay_poly = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_poly).T,\n",
    "                                    columns=['asset','hazard_point'])\n",
    "        else:\n",
    "            overlay_poly = pd.DataFrame()\n",
    "            \n",
    "            overlay_poly.to_excel(os.path.join(output_path,f'{country_code}_overlay_poly_{climate_model}.xlsx'))\n",
    "\n",
    "        if len(overlay_poly) == 0:\n",
    "            damaged_poly[climate_model] = pd.DataFrame()\n",
    "\n",
    "        else:\n",
    "            collect_poly_damages = []\n",
    "            for asset in tqdm(overlay_poly.groupby('asset'),total=len(overlay_poly.asset.unique()),\n",
    "                              desc='polygon damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_poly_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                            df_ds[climate_model],\n",
    "                                                                            osm_poly,\n",
    "                                                                            curves,\n",
    "                                                                            maxdam,\n",
    "                                                                            return_period,\n",
    "                                                                            country_code))\n",
    "\n",
    "            get_asset_type_poly = dict(zip(osm_poly.index,osm_poly.asset))\n",
    "            \n",
    "            results = pd.DataFrame([item for sublist in collect_poly_damages \n",
    "                                    for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "            results['asset_type'] = results.asset.apply(lambda x : get_asset_type_poly[x])    \n",
    "\n",
    "            damaged_poly[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "            \n",
    "        #assess damage for points\n",
    "        overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_points).T,\n",
    "                                      columns=['asset','hazard_point'])\n",
    "        overlay_points.to_excel(os.path.join(output_path,f'{country_code}_overlay_points_{climate_model}.xlsx'))\n",
    "\n",
    "        if len(overlay_points) == 0:\n",
    "            damaged_points[climate_model] = pd.DataFrame()\n",
    "\n",
    "        else:\n",
    "            collect_point_damages = []\n",
    "            for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                              desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_point_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                            df_ds[climate_model],\n",
    "                                                                            osm_points,\n",
    "                                                                            curves,\n",
    "                                                                            maxdam,\n",
    "                                                                            return_period,\n",
    "                                                                            country_code))\n",
    "\n",
    "            get_asset_type_point = dict(zip(osm_points.index,osm_points.asset))\n",
    "            \n",
    "            if hazard_type == 'tc':\n",
    "                results = pd.DataFrame([item for sublist in collect_point_damages\n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_point[x])    \n",
    "                \n",
    "                damaged_points[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "            \n",
    "            elif hazard_type == 'fl':\n",
    "                results = pd.DataFrame(np.array(list(flatten(collect_point_damages))).reshape(\n",
    "                    int(len(list(flatten(collect_point_damages)))/6), 6),\n",
    "                                       columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                results['asset'] = results['asset'].astype(int)\n",
    "                results[['meandam','lowerdam','upperdam']] = results[['meandam','lowerdam','upperdam']].astype(float)\n",
    "                \n",
    "                #return collect_point_damages,get_asset_type_point\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_point[x])    \n",
    "\n",
    "                damaged_points[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "    return damaged_lines,damaged_poly,damaged_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fb0f2583-08fd-49aa-8ad9-c63d7d49c7ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2470/2470 [00:07<00:00, 350.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 368/368 [00:16<00:00, 22.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['substation' 'plant']\n",
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1608621/1608621 [02:36<00:00, 10265.36it/s]\n"
     ]
    }
   ],
   "source": [
    "osm_power_infra = extract_osm_infrastructure('TWN',osm_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1e4e26ec-09a3-4bae-9cb8-58a03f1cedab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_exposure(country_code,osm_power_infra,hazard_type): #NEW VERSION\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    osm_lines,osm_poly,osm_points = osm_power_infra\n",
    "\n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = [''] #,'_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM'\n",
    "        df_ds = twn_wind #open_storm_data(country_code)!!!!!!!!!!!!!!!!!!!\n",
    "        \n",
    "        # remove assets that will not have any damage\n",
    "        osm_lines = osm_lines.loc[osm_lines.asset != 'cable'].reset_index(drop=True)\n",
    "        osm_lines['asset'] = osm_lines['asset'].replace(['minor_line'], 'line')\n",
    "        osm_poly = osm_poly.loc[osm_poly.asset != 'plant'].reset_index(drop=True)\n",
    "            \n",
    "    elif hazard_type=='fl':\n",
    "        # read flood data\n",
    "        climate_models = ['historical'] #,'rcp8p5'\n",
    "        df_ds = twn_flood #open_flood_data(country_code)!!!!!!!!!!!!!!!!!!!\n",
    "                \n",
    "    for climate_model in climate_models:\n",
    "        if hazard_type=='tc':\n",
    "            return_periods = ['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),\n",
    "                              '1_10{}'.format(climate_model),'1_25{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                              '1_100{}'.format(climate_model),'1_250{}'.format(climate_model),'1_500{}'.format(climate_model),\n",
    "                              '1_1000{}'.format(climate_model)]\n",
    "            \n",
    "        elif hazard_type == 'fl':\n",
    "            return_periods = ['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000'] \n",
    "            \n",
    "        for return_period in return_periods:\n",
    "            # assess damage for lines\n",
    "            #print(df_ds[climate_model][[return_period,'geometry']])\n",
    "\n",
    "            df_hazard = df_ds[climate_model][[return_period,'geometry']]\n",
    "            df_hazard = df_hazard[~df_hazard.eq(0).any(axis=1)]\n",
    "            print(df_hazard)\n",
    "            overlay_lines = pd.DataFrame(overlay_hazard_assets(df_hazard,osm_lines).T,\n",
    "                                         columns=['asset','hazard_point'])\n",
    "\n",
    "            overlay_lines['geometry'] = None\n",
    "\n",
    "            for index, row in overlay_lines.iterrows():\n",
    "                hazard_point = row['hazard_point']\n",
    "                if hazard_point not in df_hazard.index:\n",
    "                    overlay_lines = overlay_lines.drop(index)\n",
    "                else:\n",
    "                    geometry = df_hazard.loc[hazard_point, 'geometry']\n",
    "                    overlay_lines.at[index, 'geometry'] = geometry\n",
    "\n",
    "            #overlay_lines.to_excel(os.path.join(output_path,f'{country_code}_overlay_lines_{climate_model}.xlsx'))\n",
    "\n",
    "            # assess damage for polygons\n",
    "            if len(osm_poly) > 0:\n",
    "                overlay_poly = pd.DataFrame(overlay_hazard_assets(df_hazard,osm_poly).T,\n",
    "                                        columns=['asset','hazard_point'])\n",
    "            else:\n",
    "                overlay_poly = pd.DataFrame()\n",
    "\n",
    "            overlay_poly['geometry'] = None\n",
    "\n",
    "            for index, row in overlay_poly.iterrows():\n",
    "                hazard_point = row['hazard_point']\n",
    "                if hazard_point not in df_hazard.index:\n",
    "                    overlay_poly = overlay_poly.drop(index)\n",
    "                else:\n",
    "                    geometry = df_hazard.loc[hazard_point, 'geometry']\n",
    "                    overlay_poly.at[index, 'geometry'] = geometry\n",
    "                    \n",
    "            #assess damage for points\n",
    "            overlay_points = pd.DataFrame(overlay_hazard_assets(df_hazard,osm_points).T,\n",
    "                                          columns=['asset','hazard_point'])\n",
    "\n",
    "            overlay_points['geometry'] = None\n",
    "\n",
    "            for index, row in overlay_points.iterrows():\n",
    "                hazard_point = row['hazard_point']\n",
    "                if hazard_point not in df_hazard.index:\n",
    "                    overlay_points = overlay_points.drop(index)\n",
    "                else:\n",
    "                    geometry = df_hazard.loc[hazard_point, 'geometry']\n",
    "                    overlay_points.at[index, 'geometry'] = geometry\n",
    "        \n",
    "            df = pd.concat([overlay_lines,overlay_poly,overlay_points])\n",
    "\n",
    "            # æ ¹æ®hazard_pointè®¡ç®—æ¯ä¸ªhazard_pointå¯¹åº”çš„assetä¸ªæ•°\n",
    "            hazard_counts = df.groupby('hazard_point')['asset'].nunique().reset_index()\n",
    "            hazard_counts.columns = ['hazard_point', 'asset_count']\n",
    "\n",
    "            # ä»ŽåŽŸå§‹DataFrameä¸­èŽ·å–æ¯ä¸ªhazard_pointå¯¹åº”çš„geometry\n",
    "            hazard_geometry = df[['hazard_point', 'geometry']].drop_duplicates()\n",
    "\n",
    "            osm_exposure = pd.merge(hazard_counts, hazard_geometry, on='hazard_point')\n",
    "\n",
    "            osm_exposure.to_excel(os.path.join(output_path,exposure,f'{country_code}_osm_exposure_{hazard_type}_{return_period}.xlsx'))\n",
    "\n",
    "    return osm_exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9d355b5f-1ad4-4d91-b4a3-1506667bb7b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            1_1                                           geometry\n",
      "0     35.695326  POLYGON ((13057776.27 2391878.588, 13057776.27...\n",
      "1     35.847856  POLYGON ((13068908.219 2391878.588, 13068908.2...\n",
      "2     35.827720  POLYGON ((13080040.168 2391878.588, 13080040.1...\n",
      "3     35.713667  POLYGON ((13091172.117 2391878.588, 13091172.1...\n",
      "4     35.605688  POLYGON ((13102304.066 2391878.588, 13102304.0...\n",
      "...         ...                                                ...\n",
      "3181  39.264171  POLYGON ((13658901.52 3036284.923, 13658901.52...\n",
      "3182  39.642033  POLYGON ((13670033.469 3036284.923, 13670033.4...\n",
      "3183  39.615541  POLYGON ((13681165.418 3036284.923, 13681165.4...\n",
      "3184  39.849922  POLYGON ((13692297.368 3036284.923, 13692297.3...\n",
      "3185  39.730572  POLYGON ((13703429.317 3036284.923, 13703429.3...\n",
      "\n",
      "[3186 rows x 2 columns]\n",
      "            1_2                                           geometry\n",
      "0     36.153372  POLYGON ((13057776.27 2391878.588, 13057776.27...\n",
      "1     36.301064  POLYGON ((13068908.219 2391878.588, 13068908.2...\n",
      "2     36.284508  POLYGON ((13080040.168 2391878.588, 13080040.1...\n",
      "3     36.185645  POLYGON ((13091172.117 2391878.588, 13091172.1...\n",
      "4     36.091312  POLYGON ((13102304.066 2391878.588, 13102304.0...\n",
      "...         ...                                                ...\n",
      "3181  39.829193  POLYGON ((13658901.52 3036284.923, 13658901.52...\n",
      "3182  40.183976  POLYGON ((13670033.469 3036284.923, 13670033.4...\n",
      "3183  40.161925  POLYGON ((13681165.418 3036284.923, 13681165.4...\n",
      "3184  40.382903  POLYGON ((13692297.368 3036284.923, 13692297.3...\n",
      "3185  40.273021  POLYGON ((13703429.317 3036284.923, 13703429.3...\n",
      "\n",
      "[3186 rows x 2 columns]\n",
      "            1_5                                           geometry\n",
      "0     37.524455  POLYGON ((13057776.27 2391878.588, 13057776.27...\n",
      "1     37.654552  POLYGON ((13068908.219 2391878.588, 13068908.2...\n",
      "2     37.645442  POLYGON ((13080040.168 2391878.588, 13080040.1...\n",
      "3     37.613610  POLYGON ((13091172.117 2391878.588, 13091172.1...\n",
      "4     37.585709  POLYGON ((13102304.066 2391878.588, 13102304.0...\n",
      "...         ...                                                ...\n",
      "3181  41.523839  POLYGON ((13658901.52 3036284.923, 13658901.52...\n",
      "3182  41.794737  POLYGON ((13670033.469 3036284.923, 13670033.4...\n",
      "3183  41.806377  POLYGON ((13681165.418 3036284.923, 13681165.4...\n",
      "3184  41.981001  POLYGON ((13692297.368 3036284.923, 13692297.3...\n",
      "3185  41.914944  POLYGON ((13703429.317 3036284.923, 13703429.3...\n",
      "\n",
      "[3186 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "osm_exposure = save_exposure('TWN',osm_power_infra,'tc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5a627448-d7df-42af-84bd-fdb9d57fc315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hazard_point</th>\n",
       "      <th>asset_count</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>840.0</td>\n",
       "      <td>17</td>\n",
       "      <td>POLYGON ((11577227.043 1186775.975, 11577227.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>841.0</td>\n",
       "      <td>34</td>\n",
       "      <td>POLYGON ((11588358.992 1186775.975, 11588358.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>842.0</td>\n",
       "      <td>19</td>\n",
       "      <td>POLYGON ((11599490.941 1186775.975, 11599490.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910.0</td>\n",
       "      <td>22</td>\n",
       "      <td>POLYGON ((11532699.246 1198103.041, 11532699.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>913.0</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((11566095.093 1198103.041, 11566095.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>3376.0</td>\n",
       "      <td>10</td>\n",
       "      <td>POLYGON ((11799866.024 1574216.548, 11799866.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>3377.0</td>\n",
       "      <td>7</td>\n",
       "      <td>POLYGON ((11810997.973 1574216.548, 11810997.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>3391.0</td>\n",
       "      <td>16</td>\n",
       "      <td>POLYGON ((11966845.26 1574216.548, 11966845.26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>3449.0</td>\n",
       "      <td>12</td>\n",
       "      <td>POLYGON ((11788734.075 1585691.789, 11788734.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>3450.0</td>\n",
       "      <td>11</td>\n",
       "      <td>POLYGON ((11799866.024 1585691.789, 11799866.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hazard_point  asset_count  \\\n",
       "0           840.0           17   \n",
       "1           841.0           34   \n",
       "2           842.0           19   \n",
       "3           910.0           22   \n",
       "4           913.0            3   \n",
       "..            ...          ...   \n",
       "211        3376.0           10   \n",
       "212        3377.0            7   \n",
       "213        3391.0           16   \n",
       "214        3449.0           12   \n",
       "215        3450.0           11   \n",
       "\n",
       "                                              geometry  \n",
       "0    POLYGON ((11577227.043 1186775.975, 11577227.0...  \n",
       "1    POLYGON ((11588358.992 1186775.975, 11588358.9...  \n",
       "2    POLYGON ((11599490.941 1186775.975, 11599490.9...  \n",
       "3    POLYGON ((11532699.246 1198103.041, 11532699.2...  \n",
       "4    POLYGON ((11566095.093 1198103.041, 11566095.0...  \n",
       "..                                                 ...  \n",
       "211  POLYGON ((11799866.024 1574216.548, 11799866.0...  \n",
       "212  POLYGON ((11810997.973 1574216.548, 11810997.9...  \n",
       "213  POLYGON ((11966845.26 1574216.548, 11966845.26...  \n",
       "214  POLYGON ((11788734.075 1585691.789, 11788734.0...  \n",
       "215  POLYGON ((11799866.024 1585691.789, 11799866.0...  \n",
       "\n",
       "[216 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a613424-df63-482a-bf27-7e90be040d54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hazard_point</th>\n",
       "      <th>asset_count</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>840.0</td>\n",
       "      <td>17</td>\n",
       "      <td>POLYGON ((11577227.043 1186775.975, 11577227.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>841.0</td>\n",
       "      <td>34</td>\n",
       "      <td>POLYGON ((11588358.992 1186775.975, 11588358.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>842.0</td>\n",
       "      <td>19</td>\n",
       "      <td>POLYGON ((11599490.941 1186775.975, 11599490.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910.0</td>\n",
       "      <td>22</td>\n",
       "      <td>POLYGON ((11532699.246 1198103.041, 11532699.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>913.0</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((11566095.093 1198103.041, 11566095.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>3376.0</td>\n",
       "      <td>10</td>\n",
       "      <td>POLYGON ((11799866.024 1574216.548, 11799866.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>3377.0</td>\n",
       "      <td>7</td>\n",
       "      <td>POLYGON ((11810997.973 1574216.548, 11810997.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>3391.0</td>\n",
       "      <td>16</td>\n",
       "      <td>POLYGON ((11966845.26 1574216.548, 11966845.26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>3449.0</td>\n",
       "      <td>12</td>\n",
       "      <td>POLYGON ((11788734.075 1585691.789, 11788734.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>3450.0</td>\n",
       "      <td>11</td>\n",
       "      <td>POLYGON ((11799866.024 1585691.789, 11799866.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hazard_point  asset_count  \\\n",
       "0           840.0           17   \n",
       "1           841.0           34   \n",
       "2           842.0           19   \n",
       "3           910.0           22   \n",
       "4           913.0            3   \n",
       "..            ...          ...   \n",
       "211        3376.0           10   \n",
       "212        3377.0            7   \n",
       "213        3391.0           16   \n",
       "214        3449.0           12   \n",
       "215        3450.0           11   \n",
       "\n",
       "                                              geometry  \n",
       "0    POLYGON ((11577227.043 1186775.975, 11577227.0...  \n",
       "1    POLYGON ((11588358.992 1186775.975, 11588358.9...  \n",
       "2    POLYGON ((11599490.941 1186775.975, 11599490.9...  \n",
       "3    POLYGON ((11532699.246 1198103.041, 11532699.2...  \n",
       "4    POLYGON ((11566095.093 1198103.041, 11566095.0...  \n",
       "..                                                 ...  \n",
       "211  POLYGON ((11799866.024 1574216.548, 11799866.0...  \n",
       "212  POLYGON ((11810997.973 1574216.548, 11810997.9...  \n",
       "213  POLYGON ((11966845.26 1574216.548, 11966845.26...  \n",
       "214  POLYGON ((11788734.075 1585691.789, 11788734.0...  \n",
       "215  POLYGON ((11799866.024 1585691.789, 11799866.0...  \n",
       "\n",
       "[216 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "603f66b5-7ca7-42dd-a6bd-b3eaf0a15778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asset</th>\n",
       "      <th>hazard_point</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3391.0</td>\n",
       "      <td>POLYGON ((11966845.26 1574216.548, 11966845.26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>POLYGON ((11677414.584 1300219.208, 11677414.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>POLYGON ((11610622.89 1198103.041, 11610622.89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>POLYGON ((11599490.941 1198103.041, 11599490.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>POLYGON ((11610622.89 1198103.041, 11610622.89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>4257.0</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>POLYGON ((11755338.228 1379869.508, 11755338.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>4258.0</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>POLYGON ((11755338.228 1379869.508, 11755338.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>4259.0</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>POLYGON ((11755338.228 1379869.508, 11755338.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>4260.0</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>POLYGON ((11755338.228 1379869.508, 11755338.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>4261.0</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>POLYGON ((11644018.737 1288857.18, 11644018.73...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4752 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       asset  hazard_point                                           geometry\n",
       "0        0.0        3391.0  POLYGON ((11966845.26 1574216.548, 11966845.26...\n",
       "1        1.0        1589.0  POLYGON ((11677414.584 1300219.208, 11677414.5...\n",
       "2        2.0         917.0  POLYGON ((11610622.89 1198103.041, 11610622.89...\n",
       "3        3.0         916.0  POLYGON ((11599490.941 1198103.041, 11599490.9...\n",
       "4        3.0         917.0  POLYGON ((11610622.89 1198103.041, 11610622.89...\n",
       "...      ...           ...                                                ...\n",
       "4396  4257.0        2114.0  POLYGON ((11755338.228 1379869.508, 11755338.2...\n",
       "4397  4258.0        2114.0  POLYGON ((11755338.228 1379869.508, 11755338.2...\n",
       "4398  4259.0        2114.0  POLYGON ((11755338.228 1379869.508, 11755338.2...\n",
       "4399  4260.0        2114.0  POLYGON ((11755338.228 1379869.508, 11755338.2...\n",
       "4400  4261.0        1512.0  POLYGON ((11644018.737 1288857.18, 11644018.73...\n",
       "\n",
       "[4752 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "012910ed-abf3-41cb-b032-1f95fe59547d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "One of the arguments is of incorrect type. Please provide only Geometry objects.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m new_df \u001b[38;5;241m=\u001b[39m osm_exposure\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# å°†geometryåˆ—ä¸­çš„pygeos.lib.Geometryå¯¹è±¡è½¬æ¢ä¸ºWKTå­—ç¬¦ä¸²\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnew_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgeom\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mwkt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeom\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# å°†geometryåˆ—è½¬æ¢ä¸ºGeopandasçš„å‡ ä½•å¯¹è±¡\u001b[39;00m\n\u001b[0;32m      8\u001b[0m new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoSeries\u001b[38;5;241m.\u001b[39mfrom_wkt(new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\py310\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\py310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[66], line 5\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(geom)\u001b[0m\n\u001b[0;32m      2\u001b[0m new_df \u001b[38;5;241m=\u001b[39m osm_exposure\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# å°†geometryåˆ—ä¸­çš„pygeos.lib.Geometryå¯¹è±¡è½¬æ¢ä¸ºWKTå­—ç¬¦ä¸²\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m geom: \u001b[43mwkt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeom\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# å°†geometryåˆ—è½¬æ¢ä¸ºGeopandasçš„å‡ ä½•å¯¹è±¡\u001b[39;00m\n\u001b[0;32m      8\u001b[0m new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoSeries\u001b[38;5;241m.\u001b[39mfrom_wkt(new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\py310\\lib\\site-packages\\shapely\\wkt.py:62\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(ob, trim, rounding_precision, **kw)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdumps\u001b[39m(ob, trim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, rounding_precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m     43\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    Dump a WKT representation of a geometry to a string.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    input geometry as WKT string\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m shapely\u001b[38;5;241m.\u001b[39mto_wkt(ob, trim\u001b[38;5;241m=\u001b[39mtrim, rounding_precision\u001b[38;5;241m=\u001b[39mrounding_precision, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\py310\\lib\\site-packages\\shapely\\io.py:106\u001b[0m, in \u001b[0;36mto_wkt\u001b[1;34m(geometry, rounding_precision, trim, output_dimension, old_3d, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(old_3d):\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mold_3d only accepts scalar values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mto_wkt(\n\u001b[0;32m    107\u001b[0m     geometry,\n\u001b[0;32m    108\u001b[0m     np\u001b[38;5;241m.\u001b[39mintc(rounding_precision),\n\u001b[0;32m    109\u001b[0m     np\u001b[38;5;241m.\u001b[39mbool_(trim),\n\u001b[0;32m    110\u001b[0m     np\u001b[38;5;241m.\u001b[39mintc(output_dimension),\n\u001b[0;32m    111\u001b[0m     np\u001b[38;5;241m.\u001b[39mbool_(old_3d),\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    113\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: One of the arguments is of incorrect type. Please provide only Geometry objects."
     ]
    }
   ],
   "source": [
    "from shapely import wkt\n",
    "new_df = osm_exposure.copy()\n",
    "\n",
    "# å°†geometryåˆ—ä¸­çš„pygeos.lib.Geometryå¯¹è±¡è½¬æ¢ä¸ºWKTå­—ç¬¦ä¸²\n",
    "new_df['geometry'] = new_df['geometry'].apply(lambda geom: wkt.dumps(geom))\n",
    "\n",
    "# å°†geometryåˆ—è½¬æ¢ä¸ºGeopandasçš„å‡ ä½•å¯¹è±¡\n",
    "new_df['geometry'] = gpd.GeoSeries.from_wkt(new_df['geometry'])\n",
    "\n",
    "# åˆ›å»ºGeopandasçš„GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(new_df)\n",
    "\n",
    "# ç»˜åˆ¶åœ°å›¾\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "gdf.plot(ax=ax, column='asset_count', cmap='YlOrRd', edgecolor='black', linewidth=0.5, legend=True)\n",
    "\n",
    "# è®¾ç½®å›¾æ ‡é¢˜å’Œåæ ‡è½´æ ‡ç­¾\n",
    "ax.set_title('Asset Count Map')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "# æ˜¾ç¤ºå›¾å½¢\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "313d91ab-0996-4aa6-8de6-49b0cb2bf424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rp</th>\n",
       "      <th>curve</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>meandam</th>\n",
       "      <th>lowerdam</th>\n",
       "      <th>upperdam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_1000_CMCC-CM2-VHR4</td>\n",
       "      <td>W2_1_1</td>\n",
       "      <td>substation</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_1000_CMCC-CM2-VHR4</td>\n",
       "      <td>W2_1_2</td>\n",
       "      <td>substation</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_1000_CMCC-CM2-VHR4</td>\n",
       "      <td>W2_1_3</td>\n",
       "      <td>substation</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_1000_CMCC-CM2-VHR4</td>\n",
       "      <td>W2_1_4</td>\n",
       "      <td>substation</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_1000_CMCC-CM2-VHR4</td>\n",
       "      <td>W2_1_5</td>\n",
       "      <td>substation</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1_5_CMCC-CM2-VHR4</td>\n",
       "      <td>W2_7_2</td>\n",
       "      <td>substation</td>\n",
       "      <td>897.686595</td>\n",
       "      <td>673.264946</td>\n",
       "      <td>1122.108244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1_5_CMCC-CM2-VHR4</td>\n",
       "      <td>W2_7_3</td>\n",
       "      <td>substation</td>\n",
       "      <td>484.363271</td>\n",
       "      <td>363.272453</td>\n",
       "      <td>605.454088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1_5_CMCC-CM2-VHR4</td>\n",
       "      <td>W2_7_4</td>\n",
       "      <td>substation</td>\n",
       "      <td>305.148861</td>\n",
       "      <td>228.861645</td>\n",
       "      <td>381.436076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>1_5_CMCC-CM2-VHR4</td>\n",
       "      <td>W2_7_5</td>\n",
       "      <td>substation</td>\n",
       "      <td>256.712533</td>\n",
       "      <td>192.534400</td>\n",
       "      <td>320.890667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1_5_CMCC-CM2-VHR4</td>\n",
       "      <td>W2_7_6</td>\n",
       "      <td>substation</td>\n",
       "      <td>172.756233</td>\n",
       "      <td>129.567175</td>\n",
       "      <td>215.945292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       rp   curve  asset_type     meandam    lowerdam   \n",
       "0    1_1000_CMCC-CM2-VHR4  W2_1_1  substation    0.000069    0.000051  \\\n",
       "1    1_1000_CMCC-CM2-VHR4  W2_1_2  substation    0.000042    0.000032   \n",
       "2    1_1000_CMCC-CM2-VHR4  W2_1_3  substation    0.000023    0.000017   \n",
       "3    1_1000_CMCC-CM2-VHR4  W2_1_4  substation    0.000014    0.000011   \n",
       "4    1_1000_CMCC-CM2-VHR4  W2_1_5  substation    0.000012    0.000009   \n",
       "..                    ...     ...         ...         ...         ...   \n",
       "415     1_5_CMCC-CM2-VHR4  W2_7_2  substation  897.686595  673.264946   \n",
       "416     1_5_CMCC-CM2-VHR4  W2_7_3  substation  484.363271  363.272453   \n",
       "417     1_5_CMCC-CM2-VHR4  W2_7_4  substation  305.148861  228.861645   \n",
       "418     1_5_CMCC-CM2-VHR4  W2_7_5  substation  256.712533  192.534400   \n",
       "419     1_5_CMCC-CM2-VHR4  W2_7_6  substation  172.756233  129.567175   \n",
       "\n",
       "        upperdam  \n",
       "0       0.000086  \n",
       "1       0.000053  \n",
       "2       0.000029  \n",
       "3       0.000018  \n",
       "4       0.000015  \n",
       "..           ...  \n",
       "415  1122.108244  \n",
       "416   605.454088  \n",
       "417   381.436076  \n",
       "418   320.890667  \n",
       "419   215.945292  \n",
       "\n",
       "[420 rows x 6 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract nested dict by key\n",
    "osm_damage_infra[1]['_CMCC-CM2-VHR4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e56c1d61-40b5-4892-ac70-c20c522eb661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def country_analysis_osm(country_code,hazard_type):\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "    \n",
    "    # extract infrastructure data from OSM\n",
    "    osm_power_infra = extract_osm_infrastructure(country_code,osm_data_path)\n",
    "    \n",
    "    # assess damage to hazard_type\n",
    "    osm_damage_infra = assess_damage_osm(country_code,osm_power_infra,hazard_type)\n",
    "    \n",
    "    line_risk = {}\n",
    "    plant_risk = {}\n",
    "    substation_risk = {}\n",
    "    tower_risk = {}\n",
    "    pole_risk = {}\n",
    "\n",
    "    if hazard_type=='tc':\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "\n",
    "        for i in range(len(osm_damage_infra)):\n",
    "            for climate_model in climate_models:\n",
    "                df = osm_damage_infra[i][climate_model]\n",
    "\n",
    "                if len(df) == 0:\n",
    "                    print(\"No {}_{} risk of infra_type {} in {}\".format(hazard_type,climate_model,i,country_code))\n",
    "\n",
    "                else:\n",
    "                    with pd.ExcelWriter(os.path.join(output_path,'damage','{}_osm_{}{}_damage_{}'.format(country_code,hazard_type,climate_model,i)+'.xlsx')) as writer:\n",
    "                        df.to_excel(writer)\n",
    "\n",
    "                    df['rp'] = df['rp'].replace(['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),\n",
    "                                                '1_10{}'.format(climate_model),'1_25{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                                                '1_100{}'.format(climate_model),'1_250{}'.format(climate_model),'1_500{}'.format(climate_model),\n",
    "                                                '1_1000{}'.format(climate_model)],\n",
    "                                                [1,0.5,0.2,0.1,0.04,0.02,0.01,0.004,0.002,0.001])\n",
    "\n",
    "                    curve_code_substation = ['W2_1_1','W2_1_2','W2_1_3','W2_1_4','W2_1_5','W2_1_6','W2_2_1','W2_2_2','W2_2_3','W2_2_4','W2_2_5','W2_2_6',\n",
    "                                             'W2_3_1','W2_3_2','W2_3_3','W2_3_4','W2_3_5','W2_3_6','W2_4_1','W2_4_2','W2_4_3','W2_4_4','W2_4_5','W2_4_6',\n",
    "                                             'W2_5_1','W2_5_2','W2_5_3','W2_5_4','W2_5_5','W2_5_6','W2_6_1','W2_6_2','W2_6_3','W2_6_4','W2_6_5','W2_6_6',\n",
    "                                             'W2_7_1','W2_7_2','W2_7_3','W2_7_4','W2_7_5','W2_7_6']\n",
    "\n",
    "\n",
    "                    curve_code_tower = ['W3_1','W3_2','W3_3','W3_4','W3_5','W3_6','W3_7','W3_8','W3_9','W3_10','W3_11','W3_12','W3_13','W3_14','W3_15',\n",
    "                                        'W3_16','W3_17','W3_18','W3_19','W3_20','W3_21','W3_22','W3_23','W3_24','W3_25','W3_26','W3_27','W3_28']\n",
    "\n",
    "                    curve_code_pole = ['W4_1','W4_2','W4_3','W4_4','W4_5','W4_6','W4_7','W4_8','W4_9','W4_10','W4_11','W4_12',\n",
    "                                       'W4_13','W4_14','W4_15','W4_16','W4_17','W4_18','W4_19','W4_20','W4_21','W4_22','W4_23',\n",
    "                                       'W4_24','W4_25','W4_26','W4_27','W4_28','W4_29','W4_30','W4_31','W4_32','W4_33','W4_34',\n",
    "                                       'W4_35','W4_36','W4_37','W4_38','W4_39','W4_40','W4_41','W4_42','W4_43','W4_44','W4_45',\n",
    "                                       'W4_46','W4_47','W4_48','W4_49','W4_50','W4_51','W4_52','W4_53','W4_54','W4_55','W4_56']\n",
    "\n",
    "                    curve_code_line = ['W5_1_1','W5_1_2','W5_1_3','W5_1_4','W5_1_5','W5_1_6','W5_1_7','W5_1_8','W5_1_9','W5_1_10','W5_1_11','W5_1_12',\n",
    "                                       'W5_2_1','W5_2_2','W5_2_3','W5_2_4','W5_2_5','W5_2_6','W5_2_7','W5_2_8','W5_2_9','W5_2_10','W5_2_11','W5_2_12',\n",
    "                                       'W5_3_1','W5_3_2','W5_3_3','W5_3_4','W5_3_5','W5_3_6','W5_3_7','W5_3_8','W5_3_9','W5_3_10','W5_3_11','W5_3_12',\n",
    "                                       'W5_4_1','W5_4_2','W5_4_3','W5_4_4','W5_4_5','W5_4_6','W5_4_7','W5_4_8','W5_4_9','W5_4_10','W5_4_11','W5_4_12',\n",
    "                                       'W5_5_1','W5_5_2','W5_5_3','W5_5_4','W5_5_5','W5_5_6','W5_5_7','W5_5_8','W5_5_9','W5_5_10','W5_5_11','W5_5_12',\n",
    "                                       'W5_6_1','W5_6_2','W5_6_3','W5_6_4','W5_6_5','W5_6_6','W5_6_7','W5_6_8','W5_6_9','W5_6_10','W5_6_11','W5_6_12',\n",
    "                                       'W5_7_1','W5_7_2','W5_7_3','W5_7_4','W5_7_5','W5_7_6','W5_7_7','W5_7_8','W5_7_9','W5_7_10','W5_7_11','W5_7_12']\n",
    "\n",
    "                    #assess risk for power lines\n",
    "                    if i == 0:\n",
    "                        for curve_code in curve_code_line:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            loss_list = loss_list.sort_values(by='rp',ascending=False)\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of power lines ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                line_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "\n",
    "                    #assess risk for power substations                \n",
    "                    elif i == 1:                        \n",
    "                        for curve_code in curve_code_substation:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            loss_list = loss_list.sort_values(by='rp',ascending=False)\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of substations ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                substation_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "\n",
    "                    #assess risk for power towers and power poles\n",
    "                    elif i == 2:\n",
    "                        for curve_code in curve_code_tower:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            loss_list = loss_list.sort_values(by='rp',ascending=False)\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of power towers ...\")\n",
    "\n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                tower_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "\n",
    "                            for curve_code in curve_code_pole:\n",
    "                                loss_list = df.loc[df['curve'] == curve_code]\n",
    "                                loss_list = loss_list.sort_values(by='rp',ascending=False)\n",
    "                                if len(loss_list) == 0:\n",
    "                                    print(\"No risk of power poles ...\")\n",
    "\n",
    "                                else:                    \n",
    "                                    loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                    loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                    loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                    RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                    RPS = RPS.rp.values.tolist()\n",
    "                                    pole_risk[climate_model,curve_code] = {\n",
    "                                        'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                        'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                        'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                    }\n",
    "\n",
    "    elif hazard_type=='fl':\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "    \n",
    "        for i in range(len(osm_damage_infra)):\n",
    "            for climate_model in climate_models:\n",
    "                df = osm_damage_infra[i][climate_model]\n",
    "                    \n",
    "                if len(df) == 0:\n",
    "                    print(\"No {}_{} risk of infra_type {} in {}\".format(hazard_type,climate_model,i,country_code))\n",
    "\n",
    "                else:\n",
    "                    with pd.ExcelWriter(os.path.join(output_path,'damage','{}_osm_{}_{}_damage_{}'.format(country_code,hazard_type,climate_model,i)+'.xlsx')) as writer:\n",
    "                        df.to_excel(writer)\n",
    "\n",
    "                    df['rp'] = df['rp'].replace(['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000'],\n",
    "                                                [1,0.5,0.2,0.1,0.04,0.02,0.01,0.004,0.002,0.001])\n",
    "                    \n",
    "                    curve_code_plant = ['F1_1_1','F1_1_2','F1_1_3']\n",
    "                    curve_code_substation = ['F2_1_1','F2_1_2','F2_1_3']\n",
    "                    curve_code_tower = ['F3_1_1','F3_1_2']\n",
    "                    curve_code_pole = ['F4_1_1','F4_1_2','F4_1_3','F4_1_4']\n",
    "                    curve_code_line = ['F5_1_1','F5_1_2','F5_1_3','F5_1_4','F5_1_5','F5_1_6','F5_1_7','F5_1_8',\n",
    "                                      'F5_1_9','F5_1_10','F5_1_11','F5_1_12']\n",
    "                    curve_code_minor_line = ['F5_2']\n",
    "                    curve_code_cable = ['F5_3_1','F5_3_2']\n",
    "\n",
    "                    #assess risk for power lines\n",
    "                    if i == 0:\n",
    "                        for curve_code in curve_code_line:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of power lines ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                line_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "\n",
    "                    #assess risk for power plants and substations                \n",
    "                    elif i == 1:\n",
    "                        for curve_code in curve_code_plant:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of plants ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                plant_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "\n",
    "                        for curve_code in curve_code_substation:    \n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of substations ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                substation_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                    }\n",
    "\n",
    "                    #assess risk for power towers and power poles\n",
    "                    elif i == 2:\n",
    "                        for curve_code in curve_code_tower:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of power towers ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                tower_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "                            \n",
    "                        for curve_code in curve_code_pole:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of power poles ...\")\n",
    "                            \n",
    "                            else:                    \n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                pole_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "                                \n",
    "    return pd.DataFrame(line_risk),pd.DataFrame(plant_risk),pd.DataFrame(substation_risk),pd.DataFrame(tower_risk),pd.DataFrame(pole_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ba717-0015-4527-bf1a-a9556f87a541",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Government data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef53a27c-f539-43db-9870-1ee933ddf7c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_pg_infrastructure(country_code):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        country_code (_type_): _description_\n",
    "        pg_type (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "\n",
    "    files = [x for x in os.listdir(pg_data_path)  if country_code in x ]\n",
    "    pg_types = ['line','point']\n",
    "    \n",
    "    for pg_type in pg_types:\n",
    "        if os.path.isfile(os.path.join(pg_data_path,'{}_{}.gpkg'.format(country_code,pg_type))):\n",
    "            if pg_type=='line':\n",
    "                for file in files: \n",
    "                    file_path = os.path.join(pg_data_path,'{}_{}.gpkg'.format(country_code,pg_type))\n",
    "\n",
    "                    pg_data_country = gpd.read_file(file_path)\n",
    "                    pg_data_country = pd.DataFrame(pg_data_country.copy())\n",
    "                    pg_data_country.geometry = pygeos.from_shapely(pg_data_country.geometry)\n",
    "                    pg_data_country['geometry'] = reproject(pg_data_country)\n",
    "\n",
    "                pg_lines = buffer_assets(pg_data_country.loc[pg_data_country.asset.isin(['line'])],buffer_size=100).reset_index(drop=True)\n",
    "\n",
    "            elif pg_type=='point':\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(pg_data_path,'{}_{}.gpkg'.format(country_code,pg_type))\n",
    "\n",
    "                    pg_data_country = gpd.read_file(file_path)\n",
    "                    pg_data_country = pd.DataFrame(pg_data_country.copy())\n",
    "                    pg_data_country.geometry = pygeos.from_shapely(pg_data_country.geometry)\n",
    "                    pg_data_country['geometry'] = reproject(pg_data_country)\n",
    "\n",
    "                pg_points = buffer_assets(pg_data_country.loc[pg_data_country.asset.isin(['plant','substation','power_tower','power_pole'])],buffer_size=100).reset_index(drop=True)\n",
    "\n",
    "    return pg_lines,pg_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6a7cdb0-f9a6-4d0c-9dd9-c9d88d7e98e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "pg_infra = extract_pg_infrastructure('BRN')\n",
    "print(type(pg_infra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c78d9c1-f773-42ea-ad91-0acb4aad54bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>voltage_kv</th>\n",
       "      <th>asset</th>\n",
       "      <th>geometry</th>\n",
       "      <th>buffered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (12709972.524 509284.354, 12718390....</td>\n",
       "      <td>POLYGON ((12718400.226 508569.237, 12718401.50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (12723006.954 513810.198, 12733597....</td>\n",
       "      <td>POLYGON ((12733571.047 516803.195, 12733590.37...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (12770799.864 531913.573, 12777498....</td>\n",
       "      <td>POLYGON ((12777414.455 542196.764, 12777417.71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (12788903.239 556534.163, 12793248....</td>\n",
       "      <td>POLYGON ((12793283.162 554998.492, 12793287.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (12718119.043 508560.219, 12724274....</td>\n",
       "      <td>POLYGON ((12724292.117 505675.616, 12733601.32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>275</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (12743101.701 508288.668, 12750343....</td>\n",
       "      <td>POLYGON ((12750290.949 509198.09, 12759941.625...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>132</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (12788541.172 550288.498, 12792161....</td>\n",
       "      <td>POLYGON ((12792135.938 548602.919, 12802404.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>66</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (12735679.317 517385.614, 12736675....</td>\n",
       "      <td>POLYGON ((12736580.434 520314.662, 12736588.59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>66</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (12735543.542 517204.581, 12741155....</td>\n",
       "      <td>POLYGON ((12741121.474 519335.212, 12741140.46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>66</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (12735905.609 516933.03, 12751202.9...</td>\n",
       "      <td>POLYGON ((12751172.269 521961.373, 12751193.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>66</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (12781978.699 549926.431, 12783110....</td>\n",
       "      <td>POLYGON ((12783012.782 554791.836, 12783019.34...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    voltage_kv asset                                           geometry  \\\n",
       "0           66  line  LINESTRING (12709972.524 509284.354, 12718390....   \n",
       "1           66  line  LINESTRING (12723006.954 513810.198, 12733597....   \n",
       "2           66  line  LINESTRING (12770799.864 531913.573, 12777498....   \n",
       "3           66  line  LINESTRING (12788903.239 556534.163, 12793248....   \n",
       "4          132  line  LINESTRING (12718119.043 508560.219, 12724274....   \n",
       "5          275  line  LINESTRING (12743101.701 508288.668, 12750343....   \n",
       "6          132  line  LINESTRING (12788541.172 550288.498, 12792161....   \n",
       "7           66  line  LINESTRING (12735679.317 517385.614, 12736675....   \n",
       "8           66  line  LINESTRING (12735543.542 517204.581, 12741155....   \n",
       "9           66  line  LINESTRING (12735905.609 516933.03, 12751202.9...   \n",
       "10          66  line  LINESTRING (12781978.699 549926.431, 12783110....   \n",
       "\n",
       "                                             buffered  \n",
       "0   POLYGON ((12718400.226 508569.237, 12718401.50...  \n",
       "1   POLYGON ((12733571.047 516803.195, 12733590.37...  \n",
       "2   POLYGON ((12777414.455 542196.764, 12777417.71...  \n",
       "3   POLYGON ((12793283.162 554998.492, 12793287.25...  \n",
       "4   POLYGON ((12724292.117 505675.616, 12733601.32...  \n",
       "5   POLYGON ((12750290.949 509198.09, 12759941.625...  \n",
       "6   POLYGON ((12792135.938 548602.919, 12802404.13...  \n",
       "7   POLYGON ((12736580.434 520314.662, 12736588.59...  \n",
       "8   POLYGON ((12741121.474 519335.212, 12741140.46...  \n",
       "9   POLYGON ((12751172.269 521961.373, 12751193.13...  \n",
       "10  POLYGON ((12783012.782 554791.836, 12783019.34...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_infra[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0797c42-fd24-45f7-a0c0-51783767aa2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assess_damage_pg(country_code,pg_infra,hazard_type):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        country_code (_type_): _description_\n",
    "        pg_data_country (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "\n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(country_code,vul_curve_path,hazard_type)\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    pg_lines,pg_points = pg_infra\n",
    "    \n",
    "    #calculate damaged lines/polygons/points in loop by climate_model\n",
    "    damaged_lines = {}\n",
    "    damaged_points = {}\n",
    "\n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "        df_ds = open_storm_data(country_code)\n",
    "        \n",
    "        # remove assets that will not have any damage\n",
    "        pg_points = pg_points.loc[pg_points.asset != 'plant'].reset_index(drop=True)\n",
    "    \n",
    "    elif hazard_type == 'fl':\n",
    "        # read flood data\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "        df_ds = open_flood_data(country_code)\n",
    "        \n",
    "    for climate_model in climate_models:\n",
    "        if hazard_type=='tc':\n",
    "            return_periods = ['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),'1_10{}'.format(climate_model),\n",
    "                              '1_25{}'.format(climate_model),'1_50{}'.format(climate_model),'1_100{}'.format(climate_model),\n",
    "                              '1_250{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "        elif hazard_type == 'fl':\n",
    "            return_periods = ['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000'] \n",
    "            \n",
    "        # assess damage for lines\n",
    "        overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],pg_lines).T,\n",
    "                                     columns=['asset','hazard_point'])\n",
    "\n",
    "        if len(overlay_lines) == 0:\n",
    "            damaged_lines[climate_model] = pd.DataFrame()\n",
    "\n",
    "        else:\n",
    "            collect_line_damages = []\n",
    "            for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                              desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_line_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                            df_ds[climate_model],\n",
    "                                                                            pg_lines,\n",
    "                                                                            curves,\n",
    "                                                                            maxdam,\n",
    "                                                                            return_period,\n",
    "                                                                            country_code))\n",
    "\n",
    "            get_asset_type_line = dict(zip(pg_lines.index,pg_lines.asset))\n",
    "            \n",
    "            if hazard_type=='tc':\n",
    "                results = pd.DataFrame([item for sublist in collect_line_damages\n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "                damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "                \n",
    "            elif hazard_type == 'fl':\n",
    "                results = pd.DataFrame(collect_line_damages,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "                results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "                #sum damage of line, cable, and minor_line\n",
    "                results['curve'] = results['curve'].replace(['cable', 'minor_line'], 'line')\n",
    "                results['asset_type'] = results['asset_type'].replace(['cable', 'minor_line'], 'line')\n",
    "\n",
    "                damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index() \n",
    "\n",
    "        # assess damage for points\n",
    "        overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],pg_points).T,\n",
    "                                      columns=['asset','hazard_point'])\n",
    "\n",
    "        if len(overlay_points) == 0:\n",
    "            damaged_points[climate_model] = pd.DataFrame()\n",
    "\n",
    "        else:\n",
    "            collect_point_damages = []\n",
    "            for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                              desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_point_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                            df_ds[climate_model],\n",
    "                                                                            pg_points,\n",
    "                                                                            curves,\n",
    "                                                                            maxdam,\n",
    "                                                                            return_period,\n",
    "                                                                            country_code))\n",
    "\n",
    "            get_asset_type_point = dict(zip(pg_points.index,pg_points.asset))\n",
    "            \n",
    "            if hazard_type == 'tc':\n",
    "                results = pd.DataFrame([item for sublist in collect_point_damages\n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "            elif hazard_type == 'fl':\n",
    "                results = pd.DataFrame(collect_point_damages ,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "            results['asset_type'] = results.asset.apply(lambda x : get_asset_type_point[x])    \n",
    "\n",
    "            damaged_points[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "                \n",
    "    return damaged_lines,damaged_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5680499-fc0f-454f-ab9b-4452a2c120ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infrastructure type  plant               substation                  \\\n",
      "Code                F1_1_1 F1_1_2 F1_1_3     F2_1_1  F2_1_2  F2_1_3   \n",
      "Depth (cm)                                                            \n",
      "265.0                0.217  0.217  0.217     0.1340  0.1340  0.1340   \n",
      "270.0                0.243  0.243  0.243     0.1370  0.1370  0.1370   \n",
      "274.0                0.247  0.247  0.247     0.1385  0.1385  0.1385   \n",
      "275.0                0.251  0.251  0.251     0.1400  0.1400  0.1400   \n",
      "280.0                0.259  0.259  0.259     0.1440  0.1440  0.1440   \n",
      "285.0                0.268  0.268  0.268     0.1470  0.1470  0.1470   \n",
      "290.0                0.276  0.276  0.276     0.1500  0.1500  0.1500   \n",
      "295.0                0.284  0.284  0.284     0.1540  0.1540  0.1540   \n",
      "300.0                0.292  0.292  0.292     0.1570  0.1570  0.1570   \n",
      "305.0                0.300  0.300  0.300     0.1500  0.1500  0.1500   \n",
      "\n",
      "Infrastructure type power_tower        power_pole         ...   line         \\\n",
      "Code                     F3_1_1 F3_1_2     F4_1_1 F4_1_2  ... F5_1_6 F5_1_7   \n",
      "Depth (cm)                                                ...                 \n",
      "265.0                      0.02   0.02       0.02   0.02  ...   0.02   0.02   \n",
      "270.0                      0.02   0.02       0.02   0.02  ...   0.02   0.02   \n",
      "274.0                      0.02   0.02       0.02   0.02  ...   0.02   0.02   \n",
      "275.0                      0.02   0.02       0.02   0.02  ...   0.02   0.02   \n",
      "280.0                      0.02   0.02       0.02   0.02  ...   0.02   0.02   \n",
      "285.0                      0.02   0.02       0.02   0.02  ...   0.02   0.02   \n",
      "290.0                      0.02   0.02       0.02   0.02  ...   0.02   0.02   \n",
      "295.0                      0.02   0.02       0.02   0.02  ...   0.02   0.02   \n",
      "300.0                      0.02   0.02       0.02   0.02  ...   0.02   0.02   \n",
      "305.0                      0.02   0.02       0.02   0.02  ...   0.02   0.02   \n",
      "\n",
      "Infrastructure type                                       minor_line  cable  \\\n",
      "Code                F5_1_8 F5_1_9 F5_1_10 F5_1_11 F5_1_12       F5_2 F5_3_1   \n",
      "Depth (cm)                                                                    \n",
      "265.0                 0.02   0.02    0.02    0.02    0.02       0.02   0.02   \n",
      "270.0                 0.02   0.02    0.02    0.02    0.02       0.02   0.02   \n",
      "274.0                 0.02   0.02    0.02    0.02    0.02       0.02   0.02   \n",
      "275.0                 0.02   0.02    0.02    0.02    0.02       0.02   0.02   \n",
      "280.0                 0.02   0.02    0.02    0.02    0.02       0.02   0.02   \n",
      "285.0                 0.02   0.02    0.02    0.02    0.02       0.02   0.02   \n",
      "290.0                 0.02   0.02    0.02    0.02    0.02       0.02   0.02   \n",
      "295.0                 0.02   0.02    0.02    0.02    0.02       0.02   0.02   \n",
      "300.0                 0.02   0.02    0.02    0.02    0.02       0.02   0.02   \n",
      "305.0                 0.02   0.02    0.02    0.02    0.02       0.02   0.02   \n",
      "\n",
      "Infrastructure type         \n",
      "Code                F5_3_2  \n",
      "Depth (cm)                  \n",
      "265.0                 0.02  \n",
      "270.0                 0.02  \n",
      "274.0                 0.02  \n",
      "275.0                 0.02  \n",
      "280.0                 0.02  \n",
      "285.0                 0.02  \n",
      "290.0                 0.02  \n",
      "295.0                 0.02  \n",
      "300.0                 0.02  \n",
      "305.0                 0.02  \n",
      "\n",
      "[10 rows x 27 columns]\n",
      "The ratio_usa for BRN is 0.5201\n",
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for BRN fl (rcp8p5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.09 s\n",
      "Wall time: 5.25 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pg_damage_infra = assess_damage_pg('BRN',pg_infra,'fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64cfcf4a-3381-4a83-9f58-6b254ce75336",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_damage_infra[1]['rcp8p5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f7d5fb3-c1c9-4e1e-a73c-fea26042357f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for JPN fl (historical): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 25.00it/s]\n",
      "point damage calculation for JPN fl (historical): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 45.45it/s]\n",
      "polyline damage calculation for JPN fl (rcp8p5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 24.04it/s]\n",
      "point damage calculation for JPN fl (rcp8p5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 50.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8min 7s\n",
      "Wall time: 8min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pg_damage_infra_fl = assess_damage_pg('JPN',pg_infra,'fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc6d1154-a26e-4dfe-9ee0-86f6bb80c10d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'historical':        rp       curve  asset_type        meandam       lowerdam       upperdam\n",
       "  0  rp0001  substation  substation  490588.160384  367941.120288  613235.200480\n",
       "  1  rp0002  substation  substation  517498.328609  388123.746457  646872.910762\n",
       "  2  rp0005  substation  substation  559647.208366  419735.406274  699559.010457\n",
       "  3  rp0010  substation  substation  579966.806294  434975.104721  724958.507868\n",
       "  4  rp0025  substation  substation  608736.040167  456552.030125  760920.050208\n",
       "  5  rp0050  substation  substation  632107.357808  474080.518356  790134.197260\n",
       "  6  rp0100  substation  substation  652340.431603  489255.323702  815425.539504\n",
       "  7  rp0250  substation  substation  682990.145845  512242.609384  853737.682306\n",
       "  8  rp0500  substation  substation  699857.025260  524892.768945  874821.281575\n",
       "  9  rp1000  substation  substation  721527.021566  541145.266174  901908.776957,\n",
       "  'rcp8p5':        rp       curve  asset_type        meandam       lowerdam       upperdam\n",
       "  0  rp0001  substation  substation  563081.188997  422310.891747  703851.486246\n",
       "  1  rp0002  substation  substation  576128.595727  432096.446795  720160.744658\n",
       "  2  rp0005  substation  substation  610238.220801  457678.665601  762797.776001\n",
       "  3  rp0010  substation  substation  636848.474749  477636.356061  796060.593436\n",
       "  4  rp0025  substation  substation  663008.857279  497256.642959  828761.071599\n",
       "  5  rp0050  substation  substation  688989.026262  516741.769697  861236.282828\n",
       "  6  rp0100  substation  substation  707410.163024  530557.622268  884262.703781\n",
       "  7  rp0250  substation  substation  731011.743016  548258.807262  913764.678770\n",
       "  8  rp0500  substation  substation  756650.033516  567487.525137  945812.541895\n",
       "  9  rp1000  substation  substation  773409.866355  580057.399766  966762.332944},\n",
       " {})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_damage_infra_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98d174ad-3c24-44ea-88cb-0b88ee406e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def country_analysis_pg(country_code,hazard_type):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        country_code (_type_): _description_\n",
    "        hazard_type (str, optional): _description_. Defaults to 'OSM'.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "    \n",
    "    # extract infrastructure data from gov data\n",
    "    pg_power_infra = extract_pg_infrastructure(country_code)\n",
    "    \n",
    "    # assess damage to hazard_type\n",
    "    pg_damage_infra = assess_damage_pg(country_code,pg_power_infra,hazard_type)\n",
    "    \n",
    "    line_risk = {}\n",
    "    plant_risk = {}\n",
    "    substation_risk = {}\n",
    "\n",
    "    if hazard_type=='tc':\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "\n",
    "        for i in range(len(pg_damage_infra)):\n",
    "            for climate_model in climate_models:\n",
    "                df = pg_damage_infra[i][climate_model]\n",
    "                    \n",
    "                if len(df) == 0:\n",
    "                    print(\"No {}_{} risk of infra_type {} in {}\".format(hazard_type,climate_model,i,country_code))\n",
    "\n",
    "                else:\n",
    "                    with pd.ExcelWriter(os.path.join(output_path,'damage','{}_pg_{}{}_damage_{}'.format(country_code,hazard_type,climate_model,i)+'.xlsx')) as writer:\n",
    "                        df.to_excel(writer)\n",
    "\n",
    "                    df['rp'] = df['rp'].replace(['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),\n",
    "                                                '1_10{}'.format(climate_model),'1_25{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                                                '1_100{}'.format(climate_model),'1_250{}'.format(climate_model),'1_500{}'.format(climate_model),\n",
    "                                                '1_1000{}'.format(climate_model)],\n",
    "                                                [1,0.5,0.2,0.1,0.04,0.02,0.01,0.004,0.002,0.001])\n",
    "                    \n",
    "                    curve_code_substation = ['W2_1_1','W2_1_2','W2_1_3','W2_2_1','W2_2_2','W2_2_3','W2_3_1','W2_3_2','W2_3_3',\n",
    "                                            'W2_4_1','W2_4_2','W2_4_3','W2_5_1','W2_5_2','W2_5_3','W2_6_1','W2_6_2','W2_6_3',\n",
    "                                            'W2_7_1','W2_7_2','W2_7_3']\n",
    "                    \n",
    "                    curve_code_line = ['W5_1','W5_2','W5_3']\n",
    "\n",
    "                    #assess risk for power lines\n",
    "                    if i == 0:\n",
    "                        for curve_code in curve_code_line:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            loss_list = loss_list.sort_values(by='rp',ascending=False)\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of power lines ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "\n",
    "                                line_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "                            #print(line_risk_curve)\n",
    "                    \n",
    "                    #assess risk for power substations                \n",
    "                    elif i == 1:                        \n",
    "                        for curve_code in curve_code_substation:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            loss_list = loss_list.sort_values(by='rp',ascending=False)\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of substations ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "\n",
    "                                substation_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "\n",
    "\n",
    "    elif hazard_type=='fl':\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "    \n",
    "        for i in range(len(pg_damage_infra)):\n",
    "            for climate_model in climate_models:\n",
    "                df = pg_damage_infra[i][climate_model]\n",
    "                    \n",
    "                if len(df) == 0:\n",
    "                    print(\"No {}_{} risk of infra_type {} in {}\".format(hazard_type,climate_model,i,country_code))\n",
    "\n",
    "                else:\n",
    "                    with pd.ExcelWriter(os.path.join(output_path,'damage','{}_pg_{}_{}_damage_{}'.format(country_code,hazard_type,climate_model,i)+'.xlsx')) as writer:\n",
    "                        df.to_excel(writer)\n",
    "\n",
    "                    df['rp'] = df['rp'].replace(['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000'],\n",
    "                                                [1,0.5,0.2,0.1,0.04,0.02,0.01,0.004,0.002,0.001])\n",
    "                    \n",
    "                    curve_code_plant = ['F1_1_1','F1_1_2','F1_1_3']\n",
    "                    curve_code_substation = ['F2_1_1','F2_1_2','F2_1_3']\n",
    "                    curve_code_line = ['F5_1']\n",
    "\n",
    "                    #assess risk for power lines\n",
    "                    if i == 0:\n",
    "                        for curve_code in curve_code_line:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of power lines ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                line_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "\n",
    "                    #assess risk for power plants and substations                \n",
    "                    elif i == 1:\n",
    "                        for curve_code in curve_code_plant:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of plants ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                plant_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                }\n",
    "                            \n",
    "                        for curve_code in curve_code_substation:\n",
    "                            loss_list = df.loc[df['curve'] == curve_code]\n",
    "                            if len(loss_list) == 0:\n",
    "                                print(\"No risk of substations ...\")\n",
    "                            \n",
    "                            else:\n",
    "                                loss_list_mean = loss_list.meandam.values.tolist()\n",
    "                                loss_list_lower = loss_list.lowerdam.values.tolist()\n",
    "                                loss_list_upper = loss_list.upperdam.values.tolist()\n",
    "                                RPS = loss_list.loc[loss_list['curve'] == curve_code]\n",
    "                                RPS = RPS.rp.values.tolist()\n",
    "                                substation_risk[climate_model,curve_code] = {\n",
    "                                    'mean_risk': integrate.simps(y=loss_list_mean[::-1], x=RPS[::-1]),\n",
    "                                    'lower_risk': integrate.simps(y=loss_list_lower[::-1], x=RPS[::-1]),\n",
    "                                    'upper_risk': integrate.simps(y=loss_list_upper[::-1], x=RPS[::-1])\n",
    "                                    }\n",
    "                            \n",
    "    return pd.DataFrame(line_risk),pd.DataFrame(plant_risk),pd.DataFrame(substation_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0b2f45-0e6a-4452-b85a-1cf009ec3d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pg_risk_tc = country_analysis_pg('JPN','tc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c6222f6c-3c12-4b7a-84ba-544e31de677f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_CMCC-CM2-VHR4</th>\n",
       "      <th>_CNRM-CM6-1-HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W2_7_3\n",
       "mean_risk   1.434933e...</td>\n",
       "      <td>W2_7_3\n",
       "mean_risk   1.544563e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      _CMCC-CM2-VHR4  \\\n",
       "0                    W2_7_3\n",
       "mean_risk   1.434933e...   \n",
       "\n",
       "                                      _CNRM-CM6-1-HR  \n",
       "0                    W2_7_3\n",
       "mean_risk   1.544563e...  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pg_risk_tc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5755396e-ef87-4815-ba01-1f91eb685bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for JPN fl (historical): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 24.88it/s]\n",
      "point damage calculation for JPN fl (historical): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 41.67it/s]\n",
      "polyline damage calculation for JPN fl (rcp8p5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 23.80it/s]\n",
      "point damage calculation for JPN fl (rcp8p5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 49.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No risk of plants ...\n",
      "No risk of plants ...\n"
     ]
    }
   ],
   "source": [
    "pg_risk_fl = country_analysis_pg('JPN','fl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f076a1e2-6f11-47d7-b19b-595720d8de7b",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dda764da-ee7e-49ea-9572-e263c80ddecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def risk_output(country_code,hazard_type,infra_type):\n",
    "    # set paths\n",
    "    #data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path,ne_path = set_paths()\n",
    "    \n",
    "    if hazard_type == 'tc':\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "        \n",
    "    elif hazard_type == 'fl':\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "  \n",
    "    if infra_type == 'osm':\n",
    "        line_risk,plant_risk,substation_risk,tower_risk,pole_risk = country_analysis_osm(country_code,hazard_type)\n",
    "    \n",
    "    elif infra_type == 'gov':\n",
    "        line_risk,plant_risk,substation_risk = country_analysis_pg(country_code,hazard_type)\n",
    "            \n",
    "    for climate_model in climate_models:\n",
    "        if climate_model == '':\n",
    "            writer = pd.ExcelWriter(os.path.join(output_path,'risk','{}_{}_{}_{}_risk'.format(country_code,infra_type,hazard_type,'present')+'.xlsx'),\n",
    "                                    engine='openpyxl')\n",
    "        else:\n",
    "            writer = pd.ExcelWriter(os.path.join(output_path,'risk','{}_{}_{}_{}_risk'.format(country_code,infra_type,hazard_type,climate_model)+'.xlsx'),\n",
    "                                    engine='openpyxl')\n",
    "\n",
    "        # write each dataframe to a different sheet\n",
    "        if len(line_risk) != 0:\n",
    "            line_risk[climate_model].to_excel(writer, sheet_name='line_risk')\n",
    "        if len(plant_risk) != 0:\n",
    "            plant_risk[climate_model].to_excel(writer, sheet_name='plant_risk')\n",
    "        if len(substation_risk) != 0:\n",
    "            substation_risk[climate_model].to_excel(writer, sheet_name='substation_risk')\n",
    "        if len(tower_risk) != 0:\n",
    "            tower_risk[climate_model].to_excel(writer, sheet_name='tower_risk')\n",
    "        if len(pole_risk) != 0:\n",
    "            pole_risk[climate_model].to_excel(writer, sheet_name='pole_risk')\n",
    "\n",
    "        # save the Excel file\n",
    "        if writer.sheets:\n",
    "            writer.save()\n",
    "\n",
    "        else:\n",
    "            df = pd.DataFrame()\n",
    "            df.loc[1:3, 0] = ['mean_risk', 'lower_risk', 'upper_risk']\n",
    "\n",
    "            writer = pd.ExcelWriter(os.path.join(output_path,'risk','{}_{}_{}_{}_risk'.format(country_code,infra_type,hazard_type,climate_model)+'.xlsx'))\n",
    "            df.to_excel(writer,sheet_name='line_risk', index=False)\n",
    "            writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d978c878-bbbf-47c5-abc2-2df27355e8c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:00<00:00, 435.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:00<00:00, 83.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plant' 'substation']\n",
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8774/8774 [00:00<00:00, 10222.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio_usa for BRN is 0.5201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polygon damage calculation for BRN tc (): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.63s/it]\n",
      "polygon damage calculation for BRN tc (_CMCC-CM2-VHR4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.61s/it]\n",
      "polygon damage calculation for BRN tc (_CNRM-CM6-1-HR): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.64s/it]\n",
      "polygon damage calculation for BRN tc (_EC-Earth3P-HR): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.61s/it]\n",
      "polygon damage calculation for BRN tc (_HadGEM3-GC31-HM): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tc_ risk of infra_type 0 in BRN\n",
      "No tc__CMCC-CM2-VHR4 risk of infra_type 0 in BRN\n",
      "No tc__CNRM-CM6-1-HR risk of infra_type 0 in BRN\n",
      "No tc__EC-Earth3P-HR risk of infra_type 0 in BRN\n",
      "No tc__HadGEM3-GC31-HM risk of infra_type 0 in BRN\n",
      "No tc_ risk of infra_type 2 in BRN\n",
      "No tc__CMCC-CM2-VHR4 risk of infra_type 2 in BRN\n",
      "No tc__CNRM-CM6-1-HR risk of infra_type 2 in BRN\n",
      "No tc__EC-Earth3P-HR risk of infra_type 2 in BRN\n",
      "No tc__HadGEM3-GC31-HM risk of infra_type 2 in BRN\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OpenpyxlWriter' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m<timed eval>:1\u001b[0m\n",
      "Cell \u001b[1;32mIn[17], line 39\u001b[0m, in \u001b[0;36mrisk_output\u001b[1;34m(country_code, hazard_type, infra_type)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# save the Excel file\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m writer\u001b[38;5;241m.\u001b[39msheets:\n\u001b[1;32m---> 39\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OpenpyxlWriter' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "risk_output('BRN','tc','osm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "f25448e6-5b5d-434d-8332-8471a4a7e2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rp</th>\n",
       "      <th>curve</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>meandam</th>\n",
       "      <th>lowerdam</th>\n",
       "      <th>upperdam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>1.658665e+09</td>\n",
       "      <td>4.523633e+08</td>\n",
       "      <td>2.261816e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>1.730781e+09</td>\n",
       "      <td>4.720311e+08</td>\n",
       "      <td>2.360156e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.388258e+09</td>\n",
       "      <td>6.513430e+08</td>\n",
       "      <td>3.256715e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.100</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.552940e+09</td>\n",
       "      <td>6.962564e+08</td>\n",
       "      <td>3.481282e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.040</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.767454e+09</td>\n",
       "      <td>7.547601e+08</td>\n",
       "      <td>3.773801e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.020</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.921201e+09</td>\n",
       "      <td>7.966912e+08</td>\n",
       "      <td>3.983456e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.010</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.080762e+09</td>\n",
       "      <td>8.402079e+08</td>\n",
       "      <td>4.201039e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.004</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.356950e+09</td>\n",
       "      <td>9.155320e+08</td>\n",
       "      <td>4.577660e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.528684e+09</td>\n",
       "      <td>9.623684e+08</td>\n",
       "      <td>4.811842e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.698459e+09</td>\n",
       "      <td>1.008671e+09</td>\n",
       "      <td>5.043354e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rp  curve asset_type       meandam      lowerdam      upperdam\n",
       "0   1.000  plant      plant  1.658665e+09  4.523633e+08  2.261816e+09\n",
       "2   0.500  plant      plant  1.730781e+09  4.720311e+08  2.360156e+09\n",
       "4   0.200  plant      plant  2.388258e+09  6.513430e+08  3.256715e+09\n",
       "6   0.100  plant      plant  2.552940e+09  6.962564e+08  3.481282e+09\n",
       "8   0.040  plant      plant  2.767454e+09  7.547601e+08  3.773801e+09\n",
       "10  0.020  plant      plant  2.921201e+09  7.966912e+08  3.983456e+09\n",
       "12  0.010  plant      plant  3.080762e+09  8.402079e+08  4.201039e+09\n",
       "14  0.004  plant      plant  3.356950e+09  9.155320e+08  4.577660e+09\n",
       "16  0.002  plant      plant  3.528684e+09  9.623684e+08  4.811842e+09\n",
       "18  0.001  plant      plant  3.698459e+09  1.008671e+09  5.043354e+09"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_damage_infra[1]['historical'].loc[osm_damage_infra[1]['historical']['asset_type'] == 'plant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "b3065e13-2e48-4dd3-b027-5d7815a9f94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.000\n",
       "1     1.000\n",
       "2     1.000\n",
       "3     0.500\n",
       "4     0.500\n",
       "5     0.500\n",
       "6     0.200\n",
       "7     0.200\n",
       "8     0.200\n",
       "9     0.100\n",
       "10    0.100\n",
       "11    0.100\n",
       "12    0.040\n",
       "13    0.040\n",
       "14    0.040\n",
       "15    0.020\n",
       "16    0.020\n",
       "17    0.020\n",
       "18    0.010\n",
       "19    0.010\n",
       "20    0.010\n",
       "21    0.004\n",
       "22    0.004\n",
       "23    0.004\n",
       "24    0.002\n",
       "25    0.002\n",
       "26    0.002\n",
       "27    0.001\n",
       "28    0.001\n",
       "29    0.001\n",
       "Name: rp, dtype: float64"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_damage_infra[0]['historical'].loc[:,\"rp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769479e-4a85-4931-af47-fb1ff09b73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def clip_gridfinder(country_code):\n",
    "    base_map_path = os.path.join(data_path,'base_map')\n",
    "\n",
    "    cty_boundary_path = os.path.join(base_map_path,'gadm41_{}.gpkg'.format(country_code))\n",
    "    cty_boundary = gpd.read_file(cty_boundary_path)\n",
    "    #mask = pd.DataFrame(mask.copy())\n",
    "    #mask.geometry = pygeos.from_shapely(mask.geometry)\n",
    "    #mask['geometry'] = reproject(mask)\n",
    "\n",
    "    gridfinder_path = r'C:\\Users\\mye500\\OneDrive - Vrije Universiteit Amsterdam\\01_Research-Projects\\01_risk_assessment\\PG_data\\gridfinder\\grid.gpkg'\n",
    "    gridfinder = gpd.read_file(gridfinder_path)\n",
    "    #gridfinder = pd.DataFrame(gridfinder.copy())\n",
    "    #gridfinder.geometry = pygeos.from_shapely(gridfinder.geometry)\n",
    "    #gridfinder['geometry'] = reproject(gridfinder)\n",
    "\n",
    "    clipped = gpd.clip(gridfinder,cty_boundary)\n",
    "\n",
    "    return clipped\n",
    "\n",
    "clip_gridfinder('TWN')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
