{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5263e9-087d-4863-a4e5-839dc33017bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mye500\\AppData\\Local\\Temp\\ipykernel_2448\\167061698.py:1: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osgeo import ogr,gdal\n",
    "import os\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pyproj\n",
    "from pygeos import from_wkb,from_wkt\n",
    "import pygeos\n",
    "from tqdm import tqdm\n",
    "from shapely.wkb import loads\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from shapely.geometry import mapping\n",
    "pd.options.mode.chained_assignment = None\n",
    "from rasterio.mask import mask\n",
    "import rioxarray\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11a902-f512-4fd3-b035-af38041ee083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdal.SetConfigOption(\"OSM_CONFIG_FILE\", os.path.join('..',\"osmconf.ini\"))\n",
    "\n",
    "# change paths to make it work on your own machine\n",
    "data_path = os.path.join('C:\\\\','Data','pg_risk_analysis')\n",
    "tc_path = os.path.join(data_path,'tc_netcdf')\n",
    "fl_path = os.path.join(data_path,'GLOFRIS')\n",
    "osm_data_path = os.path.join('C:\\\\','Data','country_osm')\n",
    "pg_data_path = os.path.join(data_path,'pg_data')\n",
    "vul_curve_path = os.path.join(data_path,'vulnerability_curves','input_vulnerability_data.xlsx')\n",
    "output_path = os.path.join('C:\\\\','projects','pg_risk_analysis','output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc83d355-8c98-4ae6-97b1-3203a29a4fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_b(geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    This function builds an SQL query from the values passed to the retrieve() function.\n",
    "    Arguments:\n",
    "         *geoType* : Type of geometry (osm layer) to search for.\n",
    "         *keyCol* : A list of keys/columns that should be selected from the layer.\n",
    "         ***valConstraint* : A dictionary of constraints for the values. e.g. WHERE 'value'>20 or 'value'='constraint'\n",
    "    Returns:\n",
    "        *string: : a SQL query string.\n",
    "    \"\"\"\n",
    "    query = \"SELECT \" + \"osm_id\"\n",
    "    for a in keyCol: query+= \",\"+ a  \n",
    "    query += \" FROM \" + geoType + \" WHERE \"\n",
    "    # If there are values in the dictionary, add constraint clauses\n",
    "    if valConstraint: \n",
    "        for a in [*valConstraint]:\n",
    "            # For each value of the key, add the constraint\n",
    "            for b in valConstraint[a]: query += a + b\n",
    "        query+= \" AND \"\n",
    "    # Always ensures the first key/col provided is not Null.\n",
    "    query+= \"\"+str(keyCol[0]) +\" IS NOT NULL\" \n",
    "    return query \n",
    "\n",
    "\n",
    "def retrieve(osm_path,geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    Function to extract specified geometry and keys/values from OpenStreetMap\n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.     \n",
    "        *geoType* : Type of Geometry to retrieve. e.g. lines, multipolygons, etc.\n",
    "        *keyCol* : These keys will be returned as columns in the dataframe.\n",
    "        ***valConstraint: A dictionary specifiying the value constraints.  \n",
    "        A key can have multiple values (as a list) for more than one constraint for key/value.  \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all columns, geometries, and constraints specified.    \n",
    "    \"\"\"\n",
    "    driver=ogr.GetDriverByName('OSM')\n",
    "    data = driver.Open(osm_path)\n",
    "    query = query_b(geoType,keyCol,**valConstraint)\n",
    "    sql_lyr = data.ExecuteSQL(query)\n",
    "    features =[]\n",
    "    # cl = columns \n",
    "    cl = ['osm_id'] \n",
    "    for a in keyCol: cl.append(a)\n",
    "    if data is not None:\n",
    "        print('query is finished, lets start the loop')\n",
    "        for feature in tqdm(sql_lyr,desc='extract'):\n",
    "            #try:\n",
    "            if feature.GetField(keyCol[0]) is not None:\n",
    "                geom1 = (feature.geometry().ExportToWkt())\n",
    "                #print(geom1)\n",
    "                geom = from_wkt(feature.geometry().ExportToWkt()) \n",
    "                if geom is None:\n",
    "                    continue\n",
    "                # field will become a row in the dataframe.\n",
    "                field = []\n",
    "                for i in cl: field.append(feature.GetField(i))\n",
    "                field.append(geom)   \n",
    "                features.append(field)\n",
    "            #except:\n",
    "            #    print(\"WARNING: skipped OSM feature\")   \n",
    "    else:\n",
    "        print(\"ERROR: Nonetype error when requesting SQL. Check required.\")    \n",
    "    cl.append('geometry')                   \n",
    "    if len(features) > 0:\n",
    "        return pd.DataFrame(features,columns=cl)\n",
    "    else:\n",
    "        print(\"WARNING: No features or No Memory. returning empty GeoDataFrame\") \n",
    "        return pd.DataFrame(columns=['osm_id','geometry'])\n",
    "\n",
    "def power_polyline(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract all energy linestrings from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'lines',['power','voltage'])\n",
    "    \n",
    "    df = df.reset_index(drop=True).rename(columns={'power': 'asset'})\n",
    "    \n",
    "    #print(df) #check infra keys\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def power_polygon(osm_path): # check with joel, something was wrong here with extracting substations\n",
    "    \"\"\"\n",
    "    Function to extract energy polygons from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['other_tags']) \n",
    "    \n",
    "    df = df.loc[(df.other_tags.str.contains('power'))]   #keep rows containing power data         \n",
    "    df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})     \n",
    "    \n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"substation\"', case=False)]  = 'substation' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"plant\"', case=False)] = 'plant' #specify row\n",
    "    \n",
    "    df = df.loc[(df.asset == 'substation') | (df.asset == 'plant')]\n",
    "            \n",
    "    return df.reset_index(drop=True) \n",
    "\n",
    "def electricity(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract building polygons from OpenStreetMap    \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all unique building polygons.    \n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['power'])\n",
    "    \n",
    "    df = df.reset_index(drop=True).rename(columns={'power': 'asset'})\n",
    "    \n",
    "    #df = df[df.asset!='generator']\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"substation\"', case=False)]  = 'substation' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"plant\"', case=False)] = 'plant' #specify row\n",
    "    \n",
    "    #print(df)  #check infra keys\n",
    "    \n",
    "    df = df.loc[(df.asset == 'substation') | (df.asset == 'plant')]\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def retrieve_poly_subs(osm_path, w_list, b_list):\n",
    "    \"\"\"\n",
    "    Function to extract electricity substation polygons from OpenStreetMap\n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region\n",
    "        for which we want to do the analysis.\n",
    "        *w_list* :  white list of keywords to search in the other_tags columns\n",
    "        *b_list* :  black list of keywords of rows that should not be selected\n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique substation.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['other_tags'])\n",
    "    df = df[df.other_tags.str.contains('substation', case=False, na=False)]\n",
    "    #df = df.loc[(df.other_tags.str.contains('substation'))]\n",
    "    df = df[~df.other_tags.str.contains('|'.join(b_list))]\n",
    "    #df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})\n",
    "    df['asset']  = 'substation' #specify row\n",
    "    #df = df.loc[(df.asset == 'substation')] #specify row\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def power_point(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract energy points from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"   \n",
    "    df = retrieve(osm_path,'points',['other_tags']) \n",
    "    df = df.loc[(df.other_tags.str.contains('power'))]  #keep rows containing power data       \n",
    "    df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})     \n",
    "        \n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"tower\"', case=False)]  = 'power_tower' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"pole\"', case=False)] = 'power_pole' #specify row\n",
    "    #df['asset'].loc[df['asset'].str.contains('\"utility\"=>\"power\"', case=False)] = 'power_tower' #specify row\n",
    "    \n",
    "    df = df.loc[(df.asset == 'power_tower') | (df.asset == 'power_pole')]\n",
    "            \n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36fe9f2e-0be0-47fd-83ca-67f3a272279d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reproject(df_ds, current_crs=\"epsg:4326\", approximate_crs=\"epsg:3857\"):\n",
    "    # Extract the input geometries as a numpy array of coordinates\n",
    "    geometries = df_ds['geometry']\n",
    "    coords = pygeos.get_coordinates(geometries)\n",
    "\n",
    "    # Transform the coordinates using pyproj\n",
    "    transformer = pyproj.Transformer.from_crs(current_crs, approximate_crs, always_xy=True)\n",
    "    new_coords = transformer.transform(coords[:, 0], coords[:, 1])\n",
    "\n",
    "    # Create a new GeoSeries with the reprojected coordinates\n",
    "    return pygeos.set_coordinates(geometries.copy(), np.array(new_coords).T)\n",
    "\n",
    "def buffer_assets(assets, buffer_size=100):\n",
    "    \"\"\"\n",
    "    Create a buffer of a specified size around the geometries in a GeoDataFrame.\n",
    "    \n",
    "    Args:\n",
    "        assets (GeoDataFrame): A GeoDataFrame containing geometries to be buffered.\n",
    "        buffer_size (int, optional): The distance in the units of the GeoDataFrame's CRS to buffer the geometries.\n",
    "            Defaults to 100.\n",
    "    \n",
    "    Returns:\n",
    "        GeoDataFrame: A new GeoDataFrame with an additional column named 'buffered' containing the buffered\n",
    "            geometries.\n",
    "    \"\"\"\n",
    "    # Create a buffer of the specified size around the geometries\n",
    "    assets['buffered'] = pygeos.buffer(assets.geometry.values, buffer_size)\n",
    "    \n",
    "    return assets\n",
    "\n",
    "def load_curves_maxdam(vul_curve_path,hazard_type):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        data_path ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "\n",
    "    if hazard_type == 'tc':\n",
    "        sheet_name = 'wind_curves'\n",
    "    \n",
    "    elif hazard_type == 'fl':\n",
    "        sheet_name = 'flooding_curves'\n",
    "    \n",
    "    # load curves and maximum damages as separate inputs\n",
    "    curves = pd.read_excel(vul_curve_path,sheet_name=sheet_name,skiprows=11,index_col=[0])\n",
    "    \n",
    "    if hazard_type == 'fl':\n",
    "        maxdam = pd.read_excel(vul_curve_path,sheet_name=sheet_name,index_col=[0]).iloc[:8]\n",
    "    elif hazard_type == 'tc':\n",
    "        maxdam = pd.read_excel(vul_curve_path,sheet_name=sheet_name,index_col=[0],header=[0,1]).iloc[:8]\n",
    "        maxdam = maxdam.rename({'substation_point':'substation'},level=0,axis=1)\n",
    "            \n",
    "    curves.columns = maxdam.columns\n",
    "        \n",
    "    #transpose maxdam so its easier work with the dataframe\n",
    "    maxdam = maxdam.T\n",
    "\n",
    "    #interpolate the curves to fill missing values\n",
    "    curves = curves.interpolate()\n",
    "    \n",
    "    #print(curves)\n",
    "   \n",
    "    return curves,maxdam\n",
    "\n",
    "\n",
    "def overlay_hazard_assets(df_ds, assets):\n",
    "    \"\"\"\n",
    "    Overlay a set of assets with a hazard dataset and return the subset of assets that intersect with\n",
    "    one or more hazard polygons or lines.\n",
    "    \n",
    "    Args:\n",
    "        df_ds (GeoDataFrame): A GeoDataFrame containing the hazard dataset.\n",
    "        assets (GeoDataFrame): A GeoDataFrame containing the assets to be overlaid with the hazard dataset.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: A numpy array of integers representing the indices of the hazard geometries that intersect with\n",
    "            the assets. If the assets have a 'buffered' column, the buffered geometries are used for the overlay.\n",
    "    \"\"\"\n",
    "    hazard_tree = pygeos.STRtree(df_ds.geometry.values)\n",
    "    if (pygeos.get_type_id(assets.iloc[0].geometry) == 3) | (pygeos.get_type_id(assets.iloc[0].geometry) == 6):\n",
    "        return  hazard_tree.query_bulk(assets.geometry,predicate='intersects')    \n",
    "    else:\n",
    "        return  hazard_tree.query_bulk(assets.buffered,predicate='intersects')\n",
    "    \n",
    "def get_damage_per_asset_per_rp(asset,df_ds,assets,curves,maxdam,return_period,country):\n",
    "    \"\"\"\n",
    "    Calculates the damage per asset per return period based on asset type, hazard curves and maximum damage\n",
    "\n",
    "    Args:\n",
    "        asset (tuple): Tuple with two dictionaries, containing the asset index and the hazard point index of the asset\n",
    "        df_ds (pandas.DataFrame): A pandas DataFrame containing hazard points with a 'geometry' column\n",
    "        assets (geopandas.GeoDataFrame): A GeoDataFrame containing asset geometries and asset type information\n",
    "        curves (dict): A dictionary with the asset types as keys and their corresponding hazard curves as values\n",
    "        maxdam (pandas.DataFrame): A pandas DataFrame containing the maximum damage for each asset type\n",
    "        return_period (str): The return period for which the damage should be calculated\n",
    "        country (str): The country for which the damage should be calculated\n",
    "\n",
    "    Returns:\n",
    "        list or tuple: Depending on the input, the function either returns a list of tuples with the asset index, the curve name and the calculated damage, or a tuple with None, None, None if no hazard points are found\n",
    "    \"\"\"\n",
    "    \n",
    "    # find the exact hazard overlays:\n",
    "    get_hazard_points = df_ds.iloc[asset[1]['hazard_point'].values].reset_index()\n",
    "    get_hazard_points = get_hazard_points.loc[pygeos.intersects(get_hazard_points.geometry.values,assets.iloc[asset[0]].geometry)]\n",
    "\n",
    "    \n",
    "    asset_type = assets.iloc[asset[0]].asset\n",
    "    asset_geom = assets.iloc[asset[0]].geometry\n",
    "\n",
    "    if asset_type in ['plant','substation','generator']:\n",
    "        maxdam_asset = maxdam.loc[asset_type].MaxDam/pygeos.area(asset_geom)\n",
    "        lowerdam_asset = maxdam.loc[asset_type].LowerDam/pygeos.area(asset_geom)\n",
    "        upperdam_asset = maxdam.loc[asset_type].UpperDam/pygeos.area(asset_geom)\n",
    "    else:\n",
    "        maxdam_asset = maxdam.loc[asset_type].MaxDam\n",
    "        lowerdam_asset = maxdam.loc[asset_type].LowerDam\n",
    "        upperdam_asset = maxdam.loc[asset_type].UpperDam\n",
    "\n",
    "\n",
    "    hazard_intensity = curves[asset_type].index.values\n",
    "    \n",
    "    if isinstance(curves[asset_type],pd.core.series.Series):\n",
    "        fragility_values = curves[asset_type].values.flatten()\n",
    "        only_one = True\n",
    "        curve_name = curves[asset_type].name\n",
    "    elif len(curves[asset_type].columns) == 1:\n",
    "        fragility_values = curves[asset_type].values.flatten()      \n",
    "        only_one = True   \n",
    "        curve_name = curves[asset_type].columns[0]\n",
    "    else:\n",
    "        fragility_values = curves[asset_type].values#.T[0]\n",
    "        maxdam_asset = maxdam_asset.values#[0]\n",
    "        only_one = False\n",
    "\n",
    "    if len(get_hazard_points) == 0:\n",
    "        return [return_period,asset[0],None,None]\n",
    "    else:\n",
    "        if only_one:    \n",
    "            # run the calculation as normal when the asset just has a single curve\n",
    "            if pygeos.get_type_id(asset_geom) == 1:            \n",
    "                get_hazard_points['overlay_meters'] = pygeos.length(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "                return [return_period,asset[0],curve_name,np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*maxdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*lowerdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*upperdam_asset)]\n",
    "\n",
    "            elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                get_hazard_points['overlay_m2'] = pygeos.area(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "                return [return_period,asset[0],curve_name,get_hazard_points.apply(lambda x: np.interp(x[return_period],hazard_intensity, \n",
    "                                                                  fragility_values)*maxdam_asset*x.overlay_m2,axis=1).sum(),\n",
    "                                                          get_hazard_points.apply(lambda x: np.interp(x[return_period],hazard_intensity, \n",
    "                                                                  fragility_values)*lowerdam_asset*x.overlay_m2,axis=1).sum(),\n",
    "                                                          get_hazard_points.apply(lambda x: np.interp(x[return_period],hazard_intensity, \n",
    "                                                                  fragility_values)*upperdam_asset*x.overlay_m2,axis=1).sum()]  \n",
    "\n",
    "            else:\n",
    "                return [return_period,asset[0],curve_name,np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*maxdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*lowerdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*upperdam_asset)]\n",
    "        else:\n",
    "            # run the calculation when the asset has multiple curves\n",
    "            if pygeos.get_type_id(asset_geom) == 1:            \n",
    "                get_hazard_points['overlay_meters'] = pygeos.length(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                get_hazard_points['overlay_m2'] = pygeos.area(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            \n",
    "            collect_all = []\n",
    "            for iter_,curve_ids in enumerate(curves[asset_type].columns):\n",
    "                if pygeos.get_type_id(asset_geom) == 1:\n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*get_hazard_points.overlay_meters*maxdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*get_hazard_points.overlay_meters*lowerdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*get_hazard_points.overlay_meters*upperdam_asset[iter_])])\n",
    "                                   \n",
    "                elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                        get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity,\n",
    "                                                                                    fragility_values.T[iter_])*maxdam_asset[iter_]*x.overlay_m2,axis=1).sum(),\n",
    "                                        get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity,\n",
    "                                                                                    fragility_values.T[iter_])*lowerdam_asset[iter_]*x.overlay_m2,axis=1).sum(),\n",
    "                                        get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity,\n",
    "                                                                                    fragility_values.T[iter_])*upperdam_asset[iter_]*x.overlay_m2,axis=1).sum()])\n",
    "\n",
    "                else:\n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*maxdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*lowerdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*upperdam_asset[iter_])])\n",
    "            return collect_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bf0e992-b4d1-46b0-a952-488ac8c5b2b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Infrastructure type</th>\n",
       "      <th>Code</th>\n",
       "      <th>Type vulnerability data</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Specific occupancy</th>\n",
       "      <th>Reference</th>\n",
       "      <th>MaxDam</th>\n",
       "      <th>LowerDam</th>\n",
       "      <th>UpperDam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>plant</th>\n",
       "      <td>F1_1_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>Small power plants</td>\n",
       "      <td>FEMA, 2021</td>\n",
       "      <td>154165240.329434</td>\n",
       "      <td>115623930.247075</td>\n",
       "      <td>192706550.411792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plant.1</th>\n",
       "      <td>F1_1_2</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>Medium power plants</td>\n",
       "      <td>FEMA, 2021</td>\n",
       "      <td>775256237.288818</td>\n",
       "      <td>581442177.966614</td>\n",
       "      <td>969070296.611023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plant.2</th>\n",
       "      <td>F1_1_3</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>Large power plants</td>\n",
       "      <td>FEMA, 2021</td>\n",
       "      <td>775256237.288818</td>\n",
       "      <td>581442177.966614</td>\n",
       "      <td>969070296.611023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>substation</th>\n",
       "      <td>F2_1_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>low votage</td>\n",
       "      <td>FEMA, 2021</td>\n",
       "      <td>8860071.283301</td>\n",
       "      <td>6645053.462476</td>\n",
       "      <td>11075089.104126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>substation.1</th>\n",
       "      <td>F2_1_2</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>medium votage</td>\n",
       "      <td>FEMA, 2021</td>\n",
       "      <td>17720142.566602</td>\n",
       "      <td>13290106.924951</td>\n",
       "      <td>22150178.208252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>substation.2</th>\n",
       "      <td>F2_1_3</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>high votage</td>\n",
       "      <td>FEMA, 2021</td>\n",
       "      <td>44300356.416504</td>\n",
       "      <td>33225267.312378</td>\n",
       "      <td>55375445.52063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_tower</th>\n",
       "      <td>F3_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>117360.574259</td>\n",
       "      <td>88020.430694</td>\n",
       "      <td>146700.717823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_pole</th>\n",
       "      <td>F4_1_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>wood</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>56195.614965</td>\n",
       "      <td>42146.711224</td>\n",
       "      <td>70244.518706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_pole.1</th>\n",
       "      <td>F4_1_2</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>concrete</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>57458.437773</td>\n",
       "      <td>43093.82833</td>\n",
       "      <td>71823.047217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_pole.2</th>\n",
       "      <td>F4_1_3</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>steel monopole</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>90291.830787</td>\n",
       "      <td>67718.87309</td>\n",
       "      <td>112864.788483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>F5_1_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>wood</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>70.621354</td>\n",
       "      <td>52.966016</td>\n",
       "      <td>88.276693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line.1</th>\n",
       "      <td>F5_1_2</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>concrete</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>98.085214</td>\n",
       "      <td>73.563911</td>\n",
       "      <td>122.606518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line.2</th>\n",
       "      <td>F5_1_3</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>steel monopole</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>94.161806</td>\n",
       "      <td>70.621354</td>\n",
       "      <td>117.702257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line.3</th>\n",
       "      <td>F5_1_4</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>steel lattice tower</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>147.127821</td>\n",
       "      <td>110.345866</td>\n",
       "      <td>183.909777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Infrastructure type    Code Type vulnerability data           Unit  \\\n",
       "plant                F1_1_1                   curve  euro/facility   \n",
       "plant.1              F1_1_2                   curve  euro/facility   \n",
       "plant.2              F1_1_3                   curve  euro/facility   \n",
       "substation           F2_1_1                   curve  euro/facility   \n",
       "substation.1         F2_1_2                   curve  euro/facility   \n",
       "substation.2         F2_1_3                   curve  euro/facility   \n",
       "power_tower            F3_1                   curve  euro/facility   \n",
       "power_pole           F4_1_1                   curve  euro/facility   \n",
       "power_pole.1         F4_1_2                   curve  euro/facility   \n",
       "power_pole.2         F4_1_3                   curve  euro/facility   \n",
       "line                 F5_1_1                   curve         euro/m   \n",
       "line.1               F5_1_2                   curve         euro/m   \n",
       "line.2               F5_1_3                   curve         euro/m   \n",
       "line.3               F5_1_4                   curve         euro/m   \n",
       "\n",
       "Infrastructure type   Specific occupancy   Reference            MaxDam  \\\n",
       "plant                 Small power plants  FEMA, 2021  154165240.329434   \n",
       "plant.1              Medium power plants  FEMA, 2021  775256237.288818   \n",
       "plant.2               Large power plants  FEMA, 2021  775256237.288818   \n",
       "substation                    low votage  FEMA, 2021    8860071.283301   \n",
       "substation.1               medium votage  FEMA, 2021   17720142.566602   \n",
       "substation.2                 high votage  FEMA, 2021   44300356.416504   \n",
       "power_tower                          NaN  FEMA, 2013     117360.574259   \n",
       "power_pole                          wood  FEMA, 2013      56195.614965   \n",
       "power_pole.1                    concrete  FEMA, 2013      57458.437773   \n",
       "power_pole.2              steel monopole  FEMA, 2013      90291.830787   \n",
       "line                                wood  FEMA, 2013         70.621354   \n",
       "line.1                          concrete  FEMA, 2013         98.085214   \n",
       "line.2                    steel monopole  FEMA, 2013         94.161806   \n",
       "line.3               steel lattice tower  FEMA, 2013        147.127821   \n",
       "\n",
       "Infrastructure type          LowerDam          UpperDam  \n",
       "plant                115623930.247075  192706550.411792  \n",
       "plant.1              581442177.966614  969070296.611023  \n",
       "plant.2              581442177.966614  969070296.611023  \n",
       "substation             6645053.462476   11075089.104126  \n",
       "substation.1          13290106.924951   22150178.208252  \n",
       "substation.2          33225267.312378    55375445.52063  \n",
       "power_tower              88020.430694     146700.717823  \n",
       "power_pole               42146.711224      70244.518706  \n",
       "power_pole.1              43093.82833      71823.047217  \n",
       "power_pole.2              67718.87309     112864.788483  \n",
       "line                        52.966016         88.276693  \n",
       "line.1                      73.563911        122.606518  \n",
       "line.2                      70.621354        117.702257  \n",
       "line.3                     110.345866        183.909777  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_curves_maxdam(vul_curve_path,'fl')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9896d9f-4592-4552-8876-c1340f3e09f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def open_storm_data(country_code):\n",
    "    # list of available climate models\n",
    "    climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "\n",
    "    # dictionary of basins for each country\n",
    "    country_basin = {\n",
    "        \"BRN\": [\"WP\"],\n",
    "        \"KHM\": [\"WP\"],\n",
    "        \"CHN\": [\"WP\", \"NI\"],\n",
    "        \"IDN\": [\"SI\", \"SP\", \"NI\", \"WP\"],\n",
    "        \"JPN\": [\"WP\"],\n",
    "        \"LAO\": [\"WP\"],\n",
    "        \"MYS\": [\"WP\", \"NI\"],\n",
    "        \"MNG\": [\"WP\", \"NI\"],\n",
    "        \"MMR\": [\"NI\", \"WP\"],\n",
    "        \"PRK\": [\"WP\"],\n",
    "        \"PHL\": [\"WP\"],\n",
    "        \"SGP\": [\"WP\"],\n",
    "        \"KOR\": [\"WP\"],\n",
    "        \"TWN\": [\"WP\"],\n",
    "        \"THA\": [\"WP\", \"NI\"],\n",
    "        \"VNM\": [\"WP\"]\n",
    "    }\n",
    "\n",
    "    # load country geometry file and create geometry to clip\n",
    "    ne_countries = gpd.read_file(os.path.join(data_path,'..',\"natural_earth\",\"ne_10m_admin_0_countries.shp\"))\n",
    "    bbox = ne_countries.loc[ne_countries['ISO_A3']==country_code].geometry.buffer(1).values[0].bounds\n",
    "\n",
    "    df_ds = {}\n",
    "    for climate_model in climate_models:\n",
    "        concat_prep = []\n",
    "\n",
    "        #combine STORM data from different basins\n",
    "        if \"WP\" in country_basin[country_code]:\n",
    "            WP = load_storm_data(climate_model,'WP',bbox)\n",
    "            concat_prep.append(WP)\n",
    "        if \"SP\" in country_basin[country_code]:\n",
    "            SP = load_storm_data(climate_model,'SP',bbox)\n",
    "            concat_prep.append(SP)\n",
    "        if \"NI\" in country_basin[country_code]:            \n",
    "            NI = load_storm_data(climate_model,'NI',bbox)\n",
    "            concat_prep.append(NI)            \n",
    "        if \"SI\" in country_basin[country_code]:       \n",
    "            SI = load_storm_data(climate_model,'SI',bbox)\n",
    "            concat_prep.append(SI)            \n",
    "                   \n",
    "        df_ds_cl = pd.concat(concat_prep, keys=country_basin[country_code])\n",
    "        df_ds_cl = df_ds_cl.reset_index(drop=True)\n",
    "        df_ds[climate_model] = df_ds_cl\n",
    "\n",
    "    return df_ds\n",
    "\n",
    "def load_storm_data(climate_model,basin,bbox):\n",
    "\n",
    "    filename = os.path.join(tc_path, f'STORM_FIXED_RETURN_PERIODS{climate_model}_{basin}.nc')\n",
    "    \n",
    "    # load data from NetCDF file\n",
    "    with xr.open_dataset(filename) as ds:\n",
    "        \n",
    "        # convert data to WGS84 CRS\n",
    "        ds.rio.write_crs(4326, inplace=True)\n",
    "        ds = ds.rio.clip_box(minx=bbox[0], miny=bbox[1], maxx=bbox[2], maxy=bbox[3])\n",
    "        \n",
    "        # get the mean values\n",
    "        df_ds = ds['mean'].to_dataframe().unstack(level=2).reset_index()\n",
    "\n",
    "        # create geometry values and drop lat lon columns\n",
    "        df_ds['geometry'] = [pygeos.points(x) for x in list(zip(df_ds['lon'], df_ds['lat']))]\n",
    "        df_ds = df_ds.drop(['lat', 'lon'], axis=1, level=0)\n",
    "        \n",
    "        # interpolate wind speeds of 1, 2, and 5-yr return period\n",
    "        ## rename columns to return periods (must be integer for interpolating)\n",
    "        df_ds_geometry = pd.DataFrame()\n",
    "        df_ds_geometry['geometry'] = df_ds['geometry']\n",
    "        df_ds = df_ds.drop(['geometry'], axis=1, level=0)\n",
    "        df_ds = df_ds['mean']\n",
    "        df_ds.columns = [int(x) for x in ds['mean']['rp']]\n",
    "        df_ds[1] = np.nan\n",
    "        df_ds[2] = np.nan\n",
    "        df_ds[5] = np.nan\n",
    "        df_ds[25] = np.nan\n",
    "        df_ds[250] = np.nan\n",
    "        df_ds = df_ds.reindex(sorted(df_ds.columns), axis=1)\n",
    "        df_ds = df_ds.interpolate(method='linear', axis=1, limit_direction='both')\n",
    "        df_ds['geometry'] = df_ds_geometry['geometry']\n",
    "        df_ds = df_ds[[1, 2, 5, 10, 25, 50, 100, 250, 500, 1000, 'geometry']]\n",
    "        \n",
    "        # rename columns to return periods\n",
    "        df_ds.columns = ['1_{}{}'.format(int(x), climate_model) for x in [1, 2, 5, 10, 25, 50, 100, 250, 500, 1000]] +['geometry']     \n",
    "        df_ds['geometry'] = pygeos.buffer(df_ds.geometry, radius=0.1/2, cap_style='square').values\n",
    "        \n",
    "        # reproject the geometry column to the specified CRS\n",
    "        df_ds['geometry'] = reproject(df_ds)\n",
    "            \n",
    "        # drop all non values to reduce size\n",
    "        #df_ds = df_ds.loc[~df_ds['1_10000{}'.format(climate_model)].isna()].reset_index(drop=True)\n",
    "        df_ds = df_ds.fillna(0)\n",
    "\n",
    "    return df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b43b71-49ee-4aee-aca7-db18ecbd8b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "twn_wind=open_storm_data('TWN')\n",
    "print(type(twn_wind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7059f5f8-fff4-4827-a187-bebcf957230d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.89 s\n",
      "Wall time: 2.88 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_2</th>\n",
       "      <th>1_5</th>\n",
       "      <th>1_10</th>\n",
       "      <th>1_25</th>\n",
       "      <th>1_50</th>\n",
       "      <th>1_100</th>\n",
       "      <th>1_250</th>\n",
       "      <th>1_500</th>\n",
       "      <th>1_1000</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.484970</td>\n",
       "      <td>31.484970</td>\n",
       "      <td>31.484970</td>\n",
       "      <td>31.484970</td>\n",
       "      <td>34.882271</td>\n",
       "      <td>37.150791</td>\n",
       "      <td>38.786932</td>\n",
       "      <td>41.029938</td>\n",
       "      <td>42.933264</td>\n",
       "      <td>43.897242</td>\n",
       "      <td>POLYGON ((13057776.27 2391878.588, 13057776.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.561684</td>\n",
       "      <td>31.561684</td>\n",
       "      <td>31.561684</td>\n",
       "      <td>31.561684</td>\n",
       "      <td>34.941517</td>\n",
       "      <td>37.417290</td>\n",
       "      <td>38.952814</td>\n",
       "      <td>40.987155</td>\n",
       "      <td>42.433489</td>\n",
       "      <td>43.846372</td>\n",
       "      <td>POLYGON ((13068908.219 2391878.588, 13068908.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.559660</td>\n",
       "      <td>31.559660</td>\n",
       "      <td>31.559660</td>\n",
       "      <td>31.559660</td>\n",
       "      <td>34.989208</td>\n",
       "      <td>37.441990</td>\n",
       "      <td>39.295692</td>\n",
       "      <td>41.087890</td>\n",
       "      <td>42.636647</td>\n",
       "      <td>43.937314</td>\n",
       "      <td>POLYGON ((13080040.168 2391878.588, 13080040.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.649051</td>\n",
       "      <td>31.649051</td>\n",
       "      <td>31.649051</td>\n",
       "      <td>31.649051</td>\n",
       "      <td>35.093386</td>\n",
       "      <td>37.464786</td>\n",
       "      <td>39.427878</td>\n",
       "      <td>41.296611</td>\n",
       "      <td>42.939086</td>\n",
       "      <td>44.289626</td>\n",
       "      <td>POLYGON ((13091172.117 2391878.588, 13091172.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.749391</td>\n",
       "      <td>31.749391</td>\n",
       "      <td>31.749391</td>\n",
       "      <td>31.749391</td>\n",
       "      <td>35.266336</td>\n",
       "      <td>37.634156</td>\n",
       "      <td>39.579647</td>\n",
       "      <td>41.514516</td>\n",
       "      <td>42.741313</td>\n",
       "      <td>44.298240</td>\n",
       "      <td>POLYGON ((13102304.066 2391878.588, 13102304.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>35.069860</td>\n",
       "      <td>35.069860</td>\n",
       "      <td>35.069860</td>\n",
       "      <td>35.069860</td>\n",
       "      <td>39.243768</td>\n",
       "      <td>42.045388</td>\n",
       "      <td>44.128518</td>\n",
       "      <td>46.371252</td>\n",
       "      <td>48.097373</td>\n",
       "      <td>49.527067</td>\n",
       "      <td>POLYGON ((13658901.52 3036284.923, 13658901.52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>35.159120</td>\n",
       "      <td>35.159120</td>\n",
       "      <td>35.159120</td>\n",
       "      <td>35.159120</td>\n",
       "      <td>39.261418</td>\n",
       "      <td>41.821312</td>\n",
       "      <td>44.056902</td>\n",
       "      <td>46.617187</td>\n",
       "      <td>48.180678</td>\n",
       "      <td>49.415934</td>\n",
       "      <td>POLYGON ((13670033.469 3036284.923, 13670033.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>35.238116</td>\n",
       "      <td>35.238116</td>\n",
       "      <td>35.238116</td>\n",
       "      <td>35.238116</td>\n",
       "      <td>39.250911</td>\n",
       "      <td>41.894078</td>\n",
       "      <td>44.101615</td>\n",
       "      <td>46.562302</td>\n",
       "      <td>47.930412</td>\n",
       "      <td>48.967779</td>\n",
       "      <td>POLYGON ((13681165.418 3036284.923, 13681165.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>35.309186</td>\n",
       "      <td>35.309186</td>\n",
       "      <td>35.309186</td>\n",
       "      <td>35.309186</td>\n",
       "      <td>39.248515</td>\n",
       "      <td>41.935010</td>\n",
       "      <td>44.177309</td>\n",
       "      <td>46.750433</td>\n",
       "      <td>47.926717</td>\n",
       "      <td>48.968906</td>\n",
       "      <td>POLYGON ((13692297.368 3036284.923, 13692297.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>35.334279</td>\n",
       "      <td>35.334279</td>\n",
       "      <td>35.334279</td>\n",
       "      <td>35.334279</td>\n",
       "      <td>39.291144</td>\n",
       "      <td>41.815739</td>\n",
       "      <td>44.186469</td>\n",
       "      <td>46.671538</td>\n",
       "      <td>47.922262</td>\n",
       "      <td>49.403801</td>\n",
       "      <td>POLYGON ((13703429.317 3036284.923, 13703429.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3186 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1_1        1_2        1_5       1_10       1_25       1_50  \\\n",
       "0     31.484970  31.484970  31.484970  31.484970  34.882271  37.150791   \n",
       "1     31.561684  31.561684  31.561684  31.561684  34.941517  37.417290   \n",
       "2     31.559660  31.559660  31.559660  31.559660  34.989208  37.441990   \n",
       "3     31.649051  31.649051  31.649051  31.649051  35.093386  37.464786   \n",
       "4     31.749391  31.749391  31.749391  31.749391  35.266336  37.634156   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "3181  35.069860  35.069860  35.069860  35.069860  39.243768  42.045388   \n",
       "3182  35.159120  35.159120  35.159120  35.159120  39.261418  41.821312   \n",
       "3183  35.238116  35.238116  35.238116  35.238116  39.250911  41.894078   \n",
       "3184  35.309186  35.309186  35.309186  35.309186  39.248515  41.935010   \n",
       "3185  35.334279  35.334279  35.334279  35.334279  39.291144  41.815739   \n",
       "\n",
       "          1_100      1_250      1_500     1_1000  \\\n",
       "0     38.786932  41.029938  42.933264  43.897242   \n",
       "1     38.952814  40.987155  42.433489  43.846372   \n",
       "2     39.295692  41.087890  42.636647  43.937314   \n",
       "3     39.427878  41.296611  42.939086  44.289626   \n",
       "4     39.579647  41.514516  42.741313  44.298240   \n",
       "...         ...        ...        ...        ...   \n",
       "3181  44.128518  46.371252  48.097373  49.527067   \n",
       "3182  44.056902  46.617187  48.180678  49.415934   \n",
       "3183  44.101615  46.562302  47.930412  48.967779   \n",
       "3184  44.177309  46.750433  47.926717  48.968906   \n",
       "3185  44.186469  46.671538  47.922262  49.403801   \n",
       "\n",
       "                                               geometry  \n",
       "0     POLYGON ((13057776.27 2391878.588, 13057776.27...  \n",
       "1     POLYGON ((13068908.219 2391878.588, 13068908.2...  \n",
       "2     POLYGON ((13080040.168 2391878.588, 13080040.1...  \n",
       "3     POLYGON ((13091172.117 2391878.588, 13091172.1...  \n",
       "4     POLYGON ((13102304.066 2391878.588, 13102304.0...  \n",
       "...                                                 ...  \n",
       "3181  POLYGON ((13658901.52 3036284.923, 13658901.52...  \n",
       "3182  POLYGON ((13670033.469 3036284.923, 13670033.4...  \n",
       "3183  POLYGON ((13681165.418 3036284.923, 13681165.4...  \n",
       "3184  POLYGON ((13692297.368 3036284.923, 13692297.3...  \n",
       "3185  POLYGON ((13703429.317 3036284.923, 13703429.3...  \n",
       "\n",
       "[3186 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "open_storm_data('TWN')['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c7ff6dd-a3f2-4e2a-becd-e5cffa38edde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clip_flood_data(country_code):\n",
    "    \n",
    "    # load country geometry file and create geometry to clip\n",
    "    ne_countries = gpd.read_file(os.path.join(data_path,'..',\"natural_earth\",\"ne_10m_admin_0_countries.shp\"))\n",
    "    geometry = ne_countries.loc[ne_countries['ISO_A3']==country_code].geometry.values[0]\n",
    "    geoms = [mapping(geometry)]\n",
    "    \n",
    "    #climate_model: historical, rcp4p5, rcp8p5; time_period: hist, 2030, 2050, 2080\n",
    "    rps = ['0001','0002','0005','0010','0025','0050','0100','0250','0500','1000']\n",
    "    climate_models = ['historical','rcp8p5']\n",
    "    \n",
    "    #\"/scistor/ivm/data_catalogue/open_street_map/pg_risk_analysis/GLOFRIS/global/inuncoast_historical_nosub_hist_rp0001_0.tif\"\n",
    "\n",
    "    for rp in rps:\n",
    "        #global input_file\n",
    "        for climate_model in climate_models:\n",
    "            if climate_model=='historical':\n",
    "                #f rps=='0001':\n",
    "                    input_file = os.path.join(fl_path,'global',\n",
    "                                              'inuncoast_{}_nosub_hist_rp{}_0.tif'.format(climate_model,rp)) \n",
    "                #elif rps==['0002','0005','0010','0025','0050','0100','0250','0500','1000']:\n",
    "                #    input_file = os.path.join(fl_path,'global',\n",
    "                #                              'inuncoast_{}_nosub_hist_rp{}_0.tif'.format(climate_model,rp)) \n",
    "            elif climate_model=='rcp8p5':\n",
    "                #f rps=='0001':\n",
    "                    input_file = os.path.join(fl_path,'global',\n",
    "                                              'inuncoast_{}_nosub_2030_rp{}_0.tif'.format(climate_model,rp))\n",
    "                #elif rps==['0002','0005','0010','0025','0050','0100','0250','0500','1000']:\n",
    "                #    input_file = os.path.join(fl_path,'global',\n",
    "                #                              'inuncoast_{}_nosub_2030_rp{}_0.tif'.format(climate_model,rp))\n",
    "            \n",
    "            # load raster file and save clipped version\n",
    "            with rasterio.open(input_file) as src:\n",
    "                out_image, out_transform = mask(src, geoms, crop=True)\n",
    "                out_meta = src.meta\n",
    "\n",
    "                out_meta.update({\"driver\": \"GTiff\",\n",
    "                         \"height\": out_image.shape[1],\n",
    "                         \"width\": out_image.shape[2],\n",
    "                         \"transform\": out_transform})\n",
    "\n",
    "                if 'scistor' in fl_path:\n",
    "                    file_path = os.path.join(fl_path,'country','_'.join([country_code]+input_file.split('_')[6:]))\n",
    "                else:\n",
    "                    file_path = os.path.join(fl_path,'country','_'.join([country_code]+input_file.split('_')[3:]))\n",
    "\n",
    "                with rasterio.open(file_path, \"w\", **out_meta) as dest:\n",
    "                    dest.write(out_image)\n",
    "\n",
    "def load_flood_data(country_code,climate_model):\n",
    "     \n",
    "    rps = ['0001','0002','0005','0010','0025','0050','0100','0250','0500','1000']\n",
    "    collect_df_ds = []\n",
    "    \n",
    "    if climate_model=='historical':\n",
    "        print('Loading historical coastal flood data ...')\n",
    "        for rp in rps:\n",
    "            #for file in files:\n",
    "            file_path = os.path.join(fl_path,'country','{}_{}_nosub_hist_rp{}_0.tif'.format(country_code,climate_model,rp))\n",
    "            with xr.open_dataset(file_path) as ds: #, engine=\"rasterio\"\n",
    "                df_ds = ds.to_dataframe().reset_index()\n",
    "                df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "                df_ds = df_ds.rename(columns={'band_data': 'rp'+rp}) #rename to return period\n",
    "                \n",
    "                # move from meters to centimeters\n",
    "                df_ds['rp'+rp] = (df_ds['rp'+rp]*100)         \n",
    "                df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "                df_ds = df_ds.dropna()\n",
    "                df_ds = df_ds.reset_index(drop=True)\n",
    "                df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=0.00833/2,cap_style='square').values  #?????????????????????????\n",
    "                df_ds['geometry'] = reproject(df_ds)\n",
    "                collect_df_ds.append(df_ds)\n",
    "\n",
    "        df_all = collect_df_ds[0].merge(collect_df_ds[1]).merge(collect_df_ds[2]).merge(collect_df_ds[3]).merge(collect_df_ds[4])\\\n",
    "                 .merge(collect_df_ds[5]).merge(collect_df_ds[6]).merge(collect_df_ds[7]).merge(collect_df_ds[8]).merge(collect_df_ds[9])\n",
    "        df_all = df_all.loc[df_all['rp1000']>0].reset_index(drop=True)\n",
    "\n",
    "    elif climate_model=='rcp8p5':\n",
    "        print('Loading future coastal flood data ...')\n",
    "        for rp in rps:\n",
    "            #for file in files:\n",
    "            file_path = os.path.join(fl_path,'country','{}_{}_nosub_2030_rp{}_0.tif'.format(country_code,climate_model,rp))\n",
    "            with xr.open_dataset(file_path) as ds: #, engine=\"rasterio\"\n",
    "                df_ds = ds.to_dataframe().reset_index()\n",
    "                df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "                df_ds = df_ds.rename(columns={'band_data': 'rp'+rp}) #rename to return period\n",
    "                df_ds['rp'+rp] = (df_ds['rp'+rp]*100)\n",
    "                df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "                df_ds = df_ds.dropna()\n",
    "                df_ds = df_ds.reset_index(drop=True)\n",
    "                df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=0.00833/2,cap_style='square').values\n",
    "                df_ds['geometry'] = reproject(df_ds)\n",
    "                collect_df_ds.append(df_ds)\n",
    "\n",
    "        df_all = collect_df_ds[0].merge(collect_df_ds[1]).merge(collect_df_ds[2]).merge(collect_df_ds[3]).merge(collect_df_ds[4])\\\n",
    "                 .merge(collect_df_ds[5]).merge(collect_df_ds[6]).merge(collect_df_ds[7]).merge(collect_df_ds[8]).merge(collect_df_ds[9])\n",
    "\n",
    "        df_all = df_all.loc[df_all['rp1000']>0].reset_index(drop=True)\n",
    "    return df_all\n",
    "\n",
    "def open_flood_data(country_code):\n",
    "    climate_models = ['historical','rcp8p5']\n",
    "    df_ds = {}\n",
    "    for climate_model in climate_models:\n",
    "        df_ds_sc = load_flood_data(country_code,climate_model)\n",
    "\n",
    "        df_ds[climate_model] = df_ds_sc\n",
    "    \n",
    "    return df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ebbb408-29e0-4128-ad1b-2a7eae99b0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clip_flood_data('BRN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ac9f48-e434-4893-8c04-07e663921d94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "twn_flood = open_flood_data('CHN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4cb2960-1dbe-4c3e-b9c9-4a65773bddd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(twn_flood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "e6e24a4d-35cc-4bdd-8d69-4d2c504fe1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'historical':           rp0001                                           geometry  \\\n",
       " 0     176.420731  POLYGON ((13168167.913 2811396.474, 13168167.9...   \n",
       " 1     190.201111  POLYGON ((13169095.575 2810377.258, 13169095.5...   \n",
       " 2       0.000000  POLYGON ((13170023.238 2811396.474, 13170023.2...   \n",
       " 3       0.000000  POLYGON ((13170023.238 2810377.258, 13170023.2...   \n",
       " 4       0.000000  POLYGON ((13170950.9 2811396.474, 13170950.9 2...   \n",
       " ...          ...                                                ...   \n",
       " 998   127.308418  POLYGON ((13525317.946 2521533.141, 13525317.9...   \n",
       " 999     9.339666  POLYGON ((13526245.608 2519531.048, 13526245.6...   \n",
       " 1000    0.000000  POLYGON ((13559641.456 2840983.226, 13559641.4...   \n",
       " 1001    0.000000  POLYGON ((13560569.118 2840983.226, 13560569.1...   \n",
       " 1002    0.000000  POLYGON ((13560569.118 2839962.04, 13560569.11...   \n",
       " \n",
       "           rp0002      rp0005      rp0010      rp0025      rp0050      rp0100  \\\n",
       " 0     190.869278  226.426697  249.968765  279.714294  301.781189  323.685181   \n",
       " 1     204.649658  240.207077  263.749146  293.494690  315.561554  337.465546   \n",
       " 2      10.197401   45.754814   69.296883   99.042419  121.109299  143.013290   \n",
       " 3       0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       " 4      98.447418  134.004837  157.546906  187.292435  209.359314  231.263306   \n",
       " ...          ...         ...         ...         ...         ...         ...   \n",
       " 998   129.873520  136.186218  140.365738  145.646622  149.564270  153.452972   \n",
       " 999    11.904764   18.217468   22.396994   27.677870   31.595516   35.484219   \n",
       " 1000    0.000000    0.000000    0.000000    6.591582   11.742449   16.855263   \n",
       " 1001   17.736244   26.036049   31.531216   38.474392   43.625259   48.738075   \n",
       " 1002    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       " \n",
       "           rp0250      rp0500      rp1000  \n",
       " 0     352.525330  374.301910  396.062744  \n",
       " 1     366.305695  388.082275  409.843170  \n",
       " 2     171.853455  193.630035  215.390869  \n",
       " 3       0.000000    0.000000   11.110926  \n",
       " 4     260.103455  281.880035  303.640900  \n",
       " ...          ...         ...         ...  \n",
       " 998   158.573105  162.439209  166.302521  \n",
       " 999    40.604355   44.470451   48.333763  \n",
       " 1000   23.587109   28.670193   33.749603  \n",
       " 1001   55.469917   60.553001   65.632416  \n",
       " 1002    3.818989    8.902073   13.981485  \n",
       " \n",
       " [1003 rows x 11 columns],\n",
       " 'rcp8p5':           rp0001                                           geometry  \\\n",
       " 0     196.380707  POLYGON ((13168167.913 2811396.474, 13168167.9...   \n",
       " 1       0.000000  POLYGON ((13169095.575 2811396.474, 13169095.5...   \n",
       " 2     210.161087  POLYGON ((13169095.575 2810377.258, 13169095.5...   \n",
       " 3      15.708828  POLYGON ((13170023.238 2811396.474, 13170023.2...   \n",
       " 4       0.000000  POLYGON ((13170023.238 2810377.258, 13170023.2...   \n",
       " ...          ...                                                ...   \n",
       " 1059  146.558426  POLYGON ((13525317.946 2521533.141, 13525317.9...   \n",
       " 1060   28.589678  POLYGON ((13526245.608 2519531.048, 13526245.6...   \n",
       " 1061    2.300882  POLYGON ((13559641.456 2840983.226, 13559641.4...   \n",
       " 1062   34.183693  POLYGON ((13560569.118 2840983.226, 13560569.1...   \n",
       " 1063    0.000000  POLYGON ((13560569.118 2839962.04, 13560569.11...   \n",
       " \n",
       "           rp0002      rp0005      rp0010      rp0025      rp0050      rp0100  \\\n",
       " 0     210.829254  246.386719  269.928741  299.674316  321.741211  343.645203   \n",
       " 1       0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       " 2     224.609634  260.167084  283.709106  313.454712  335.521576  357.425568   \n",
       " 3      30.157375   65.714836   89.256859  119.002441  141.069321  162.973312   \n",
       " 4       0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       " ...          ...         ...         ...         ...         ...         ...   \n",
       " 1059  149.123520  155.436234  159.615753  164.896637  168.814270  172.702972   \n",
       " 1060   31.154776   37.467480   41.647003   46.927879   50.845528   54.734230   \n",
       " 1061    5.673432   13.973236   19.468403   26.411581   31.562447   36.675262   \n",
       " 1062   37.556244   45.856049   51.351212   58.294392   63.445259   68.558075   \n",
       " 1063    0.000000    0.000000    0.000000    6.643462   11.794329   16.907143   \n",
       " \n",
       "           rp0250      rp0500      rp1000  \n",
       " 0     372.485352  394.261932  416.022766  \n",
       " 1       0.000000    0.000000    8.243799  \n",
       " 2     386.265717  408.042328  429.803192  \n",
       " 3     191.813477  213.590057  235.350891  \n",
       " 4       0.000000    9.310102   31.070948  \n",
       " ...          ...         ...         ...  \n",
       " 1059  177.823120  181.689209  185.552505  \n",
       " 1060   59.854362   63.720467   67.583755  \n",
       " 1061   43.407104   48.490189   53.569603  \n",
       " 1062   75.289917   80.373001   85.452415  \n",
       " 1063   23.638988   28.722073   33.801483  \n",
       " \n",
       " [1064 rows x 11 columns]}"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twn_flood#['historical']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3de688-606c-4dd2-abe3-f37015c7442e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OSM data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "934161b6-5f01-4315-87b3-9e4a7bd70876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_osm_infrastructure(country_code,osm_data_path):\n",
    "\n",
    "    # lines\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    power_lines_country = power_polyline(osm_path)\n",
    "    power_lines_country['geometry'] = reproject(power_lines_country)\n",
    "    power_lines_country = buffer_assets(power_lines_country.loc[power_lines_country.asset.isin(\n",
    "        ['cable','minor_cable','line','minor_line'])],buffer_size=100).reset_index(drop=True)\n",
    "    \n",
    "    # polygons\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    power_poly_country = electricity(osm_path)\n",
    "    power_poly_country['geometry'] = reproject(power_poly_country)\n",
    "    \n",
    "    # points\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    power_points_country = power_point(osm_path)\n",
    "    power_points_country['geometry'] = reproject(power_points_country)\n",
    "    power_points_country = buffer_assets(power_points_country.loc[power_points_country.asset.isin(\n",
    "        ['power_tower','power_pole'])],buffer_size=100).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    return power_lines_country,power_poly_country,power_points_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b16fbb7a-d740-4b39-bfdd-127321fb4cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:00<00:00, 442.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:00<00:00, 81.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8774/8774 [00:00<00:00, 10040.31it/s]\n"
     ]
    }
   ],
   "source": [
    "osm_power_infra = extract_osm_infrastructure('BRN',osm_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9dc748e9-7357-4296-ab28-711503d43cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(osm_power_infra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abb7a943-1950-445c-8328-f6db95b7f163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assess_damage_osm(country_code,osm_power_infra,hazard_type):\n",
    "    \n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(vul_curve_path,hazard_type)\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    power_lines,power_poly,power_points = osm_power_infra\n",
    "\n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']#,'_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "        df_ds = open_storm_data(country_code)\n",
    "        \n",
    "        # remove assets that will not have any damage\n",
    "        power_lines = power_lines.loc[power_lines.asset != 'cable'].reset_index(drop=True)\n",
    "        power_poly = power_poly.loc[power_poly.asset != 'plant'].reset_index(drop=True)\n",
    "\n",
    "    elif hazard_type=='fl':\n",
    "        # read flood data\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "        df_ds = open_flood_data(country_code) \n",
    "        \n",
    "    #calculate damaged lines in loop by climate_model\n",
    "    damaged_lines = {}\n",
    "    damaged_poly = {}\n",
    "    damaged_points = {}\n",
    "    \n",
    "    for climate_model in climate_models:\n",
    "        \n",
    "        if hazard_type == 'tc':\n",
    "            return_periods = ['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),'1_10{}'.format(climate_model),\n",
    "                              '1_25{}'.format(climate_model),'1_50{}'.format(climate_model),'1_100{}'.format(climate_model),\n",
    "                              '1_250{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "        elif hazard_type == 'fl':\n",
    "            return_periods = ['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000']  \n",
    "\n",
    "        # assess damage for lines\n",
    "        overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],power_lines).T,\n",
    "                                     columns=['asset','hazard_point'])\n",
    "        \n",
    "        if len(overlay_lines) == 0:\n",
    "            damaged_lines[climate_model] = pd.DataFrame()\n",
    "            \n",
    "        else:            \n",
    "            collect_line_damages = []\n",
    "            for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                              desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_line_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                            df_ds[climate_model],\n",
    "                                                                            power_lines,\n",
    "                                                                            curves,\n",
    "                                                                            maxdam,\n",
    "                                                                            return_period,\n",
    "                                                                            country_code))\n",
    "\n",
    "            get_asset_type_line = dict(zip(power_lines.index,power_lines.asset))\n",
    "\n",
    "            if hazard_type == 'fl':\n",
    "                results = pd.DataFrame(collect_line_damages,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "            elif hazard_type == 'tc':\n",
    "                results = pd.DataFrame([item for sublist in collect_line_damages \n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "            results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "            damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "            \n",
    "        # assess damage for polygons\n",
    "        if len(power_poly) > 0:\n",
    "            overlay_poly = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],power_poly).T,\n",
    "                                        columns=['asset','hazard_point'])\n",
    "        else:\n",
    "            overlay_poly = pd.DataFrame()\n",
    "            \n",
    "        if len(overlay_poly) == 0:\n",
    "            damaged_poly[climate_model] = pd.DataFrame()\n",
    "        \n",
    "        else:\n",
    "            collect_poly_damages = []\n",
    "            for asset in tqdm(overlay_poly.groupby('asset'),total=len(overlay_poly.asset.unique()),\n",
    "                              desc='polygon damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_poly_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                            df_ds[climate_model],\n",
    "                                                                            power_poly,\n",
    "                                                                            curves,\n",
    "                                                                            maxdam,\n",
    "                                                                            return_period,\n",
    "                                                                            country_code))\n",
    "\n",
    "            get_asset_type_poly = dict(zip(power_poly.index,power_poly.asset))\n",
    "\n",
    "            if hazard_type == 'fl':\n",
    "                results = pd.DataFrame(collect_poly_damages ,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "            elif hazard_type == 'tc':\n",
    "                results = pd.DataFrame([item for sublist in collect_poly_damages \n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "                \n",
    "            results['asset_type'] = results.asset.apply(lambda x : get_asset_type_poly[x])\n",
    "\n",
    "            damaged_poly[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "        # assess damage for points\n",
    "        overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],power_points).T,\n",
    "                                      columns=['asset','hazard_point'])\n",
    "        \n",
    "        if len(overlay_points) == 0:\n",
    "            damaged_points[climate_model] = pd.DataFrame()\n",
    "            \n",
    "        else:\n",
    "            collect_point_damages = []\n",
    "            for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                              desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_point_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                             df_ds[climate_model],\n",
    "                                                                             power_points,\n",
    "                                                                             curves,\n",
    "                                                                             maxdam,\n",
    "                                                                             return_period,\n",
    "                                                                             country_code))\n",
    "\n",
    "            get_asset_type_point = dict(zip(power_points.index,power_points.asset))\n",
    "\n",
    "            if hazard_type == 'fl':\n",
    "                results = pd.DataFrame(collect_point_damages ,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "            elif hazard_type == 'tc':\n",
    "                results = pd.DataFrame([item for sublist in collect_point_damages \n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "            results['asset_type'] = results.asset.apply(lambda x : get_asset_type_point[x])    \n",
    "\n",
    "            damaged_points[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "    return damaged_lines,damaged_poly,damaged_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac71f06a-d796-456c-a7b5-4564ba01f806",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    }
   ],
   "source": [
    "osm_damage_infra = assess_damage_osm('BRN',osm_power_infra,'fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04e67d4b-351b-4238-8eae-2500b934bb3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_damage_infra[2]['historical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "313d91ab-0996-4aa6-8de6-49b0cb2bf424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract nested dict by key\n",
    "osm_damage_infra[0]#['historical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d5e4b99-fb9d-4e25-a456-757930e52242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(osm_damage_infra[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "457c186a-018f-4a87-b4e0-c0a7e2927aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def country_analysis_osm(country_code,hazard_type): #\n",
    "\n",
    "    # extract infrastructure data from OSM\n",
    "    osm_power_infra = extract_osm_infrastructure(country_code,osm_data_path)\n",
    "    \n",
    "    # assess damage to hazard_type\n",
    "    osm_damage_infra = assess_damage_osm(country_code,osm_power_infra,hazard_type)\n",
    "    \n",
    "    if hazard_type=='tc':\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "    \n",
    "    elif hazard_type=='fl':\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "\n",
    "    line_risk = {}\n",
    "    plant_risk = {}\n",
    "    substation_risk = {}\n",
    "    tower_risk = {}\n",
    "    pole_risk = {}\n",
    "    \n",
    "    for i in range(len(osm_damage_infra)):\n",
    "        for climate_model in climate_models:\n",
    "            df = osm_damage_infra[i][climate_model]\n",
    "                \n",
    "            if len(df) == 0:\n",
    "                print(\"No {}_{} risk of infra_type {} in {}\".format(hazard_type,climate_model,i,country_code))\n",
    "\n",
    "            else:\n",
    "                with pd.ExcelWriter(os.path.join(output_path,'damage','{}_osm_{}_{}_damage_{}'.format(country_code,hazard_type,climate_model,i)+'.xlsx')) as writer:\n",
    "                    df.to_excel(writer)\n",
    "\n",
    "                if hazard_type == 'tc':\n",
    "                    df['rp'] = df['rp'].replace(['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),\n",
    "                                                 '1_10{}'.format(climate_model),'1_25{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                                                 '1_100{}'.format(climate_model),'1_250{}'.format(climate_model),'1_500{}'.format(climate_model),\n",
    "                                                 '1_1000{}'.format(climate_model)],\n",
    "                                                [1,0.5,0.2,0.1,0.04,0.02,0.01,0.004,0.002,0.001])\n",
    "\n",
    "                elif hazard_type == 'fl':\n",
    "                    df['rp'] = df['rp'].replace(['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000'],\n",
    "                                                [1,0.5,0.2,0.1,0.04,0.02,0.01,0.004,0.002,0.001])\n",
    "\n",
    "                #assess risk for power lines\n",
    "                if i == 0:\n",
    "                    loss_list = df.meandam.values.tolist()\n",
    "                    RPS = df.rp.values.tolist()\n",
    "                    line_risk[climate_model] = integrate.simps(y=loss_list[::-1], x=RPS[::-1])\n",
    "\n",
    "                #assess risk for power plants and substations\n",
    "                elif i == 1:\n",
    "                    loss_list = df.loc[df['asset_type'] == 'plant']\n",
    "                    loss_list = loss_list.meandam.values.tolist()\n",
    "                    RPS = df.loc[df['asset_type'] == 'plant']\n",
    "                    RPS = RPS.rp.values.tolist()\n",
    "                    plant_risk[climate_model] = integrate.simps(y=loss_list[::-1], x=RPS[::-1])\n",
    "\n",
    "                    loss_list = df.loc[df['asset_type'] == 'substation']\n",
    "                    loss_list = loss_list.meandam.values.tolist()\n",
    "                    RPS = df.loc[df['asset_type'] == 'substation']\n",
    "                    RPS = RPS.rp.values.tolist()\n",
    "                    substation_risk[climate_model] = integrate.simps(y=loss_list[::-1], x=RPS[::-1])\n",
    "\n",
    "                #assess risk for power towers and power poles\n",
    "                elif i == 2:\n",
    "                    loss_list = df.loc[df['asset_type'] == 'power_tower']\n",
    "                    loss_list = loss_list.meandam.values.tolist()\n",
    "                    RPS = df.loc[df['asset_type'] == 'power_tower']\n",
    "                    RPS = RPS.rp.values.tolist()\n",
    "                    tower_risk[climate_model] = integrate.simps(y=loss_list[::-1], x=RPS[::-1])\n",
    "\n",
    "                    loss_list = df.loc[df['asset_type'] == 'power_pole']\n",
    "                    loss_list = loss_list.meandam.values.tolist()\n",
    "                    RPS = df.loc[df['asset_type'] == 'power_pole']\n",
    "                    RPS = RPS.rp.values.tolist()\n",
    "                    pole_risk[climate_model] = integrate.simps(y=loss_list[::-1], x=RPS[::-1])\n",
    "                \n",
    "    return line_risk,plant_risk,substation_risk,tower_risk,pole_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b08ddf81-6571-4e42-bbdd-b6b6e948186a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:00<00:00, 483.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:00<00:00, 72.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8774/8774 [00:00<00:00, 9890.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n",
      "No fl_historical risk of infra_type 0 in BRN\n",
      "No fl_rcp8p5 risk of infra_type 0 in BRN\n",
      "No fl_historical risk of infra_type 1 in BRN\n",
      "No fl_rcp8p5 risk of infra_type 1 in BRN\n",
      "No fl_historical risk of infra_type 2 in BRN\n",
      "No fl_rcp8p5 risk of infra_type 2 in BRN\n",
      "CPU times: total: 13.1 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "osm_risk = country_analysis_osm('BRN','fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "c1660d82-8cda-4017-9662-f45bde7c35d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'historical': 105424.89081186829, 'rcp8p5': 136900.6743702326},\n",
       " {'historical': 1956667104.920839, 'rcp8p5': 2598842791.7569385},\n",
       " {'historical': 5313279.909809661, 'rcp8p5': 6924928.7416341975},\n",
       " {'historical': 145221.70252471452, 'rcp8p5': 197047.65002692994},\n",
       " {'historical': 0.0, 'rcp8p5': 0.19539434541201794})"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ba717-0015-4527-bf1a-a9556f87a541",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Government data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "ef53a27c-f539-43db-9870-1ee933ddf7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load collected power grid data\n",
    "def extract_pg_data(country_code,pg_type):\n",
    "    \n",
    "    files = [x for x in os.listdir(pg_data_path)  if country_code in x ]\n",
    "    \n",
    "    if pg_type=='line':\n",
    "        for file in files: \n",
    "            file_path = os.path.join(pg_data_path,'{}_{}.gpkg'.format(country_code,pg_type))\n",
    "\n",
    "            pg_data_country = gpd.read_file(file_path)\n",
    "            pg_data_country = pd.DataFrame(pg_data_country.copy())\n",
    "            #print(pg_data_country.head())\n",
    "            pg_data_country.geometry = pygeos.from_shapely(pg_data_country.geometry)\n",
    "            pg_data_country['geometry'] = reproject(pg_data_country)\n",
    "\n",
    "        pg_data_country = buffer_assets(pg_data_country.loc[pg_data_country.asset.isin(['line'])],\n",
    "                                        buffer_size=100).reset_index(drop=True)\n",
    "\n",
    "    elif pg_type=='point':\n",
    "        for file in files:\n",
    "            file_path = os.path.join(pg_data_path,'{}_{}.gpkg'.format(country_code,pg_type))\n",
    "                \n",
    "            pg_data_country = gpd.read_file(file_path)\n",
    "            pg_data_country = pd.DataFrame(pg_data_country.copy())\n",
    "            pg_data_country.geometry = pygeos.from_shapely(pg_data_country.geometry)\n",
    "            pg_data_country['geometry'] = reproject(pg_data_country)\n",
    "            #print(pg_data_country)\n",
    "\n",
    "        pg_data_country = buffer_assets(pg_data_country.loc[pg_data_country.asset.isin(['plant_point','substation_point','power_tower','power_pole'])],\n",
    "                                        buffer_size=100).reset_index(drop=True)\n",
    "\n",
    "    return pg_data_country\n",
    "\n",
    "def open_pg_data(country_code):\n",
    "    pg_lines = extract_pg_data(country_code,'line')\n",
    "    pg_points = extract_pg_data(country_code,'point')\n",
    "\n",
    "    return pg_lines,pg_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "e6a7cdb0-f9a6-4d0c-9dd9-c9d88d7e98e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>capacity_kV</th>\n",
       "      <th>value</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>country</th>\n",
       "      <th>operator</th>\n",
       "      <th>undergrnd</th>\n",
       "      <th>phases</th>\n",
       "      <th>cables</th>\n",
       "      <th>year</th>\n",
       "      <th>asset</th>\n",
       "      <th>geometry</th>\n",
       "      <th>buffered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Existing</td>\n",
       "      <td>230</td>\n",
       "      <td>transmission_line</td>\n",
       "      <td>0.0</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>Laos</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11642041.532 2064458.971, 11641491...</td>\n",
       "      <td>POLYGON ((11641591.898 2002921.519, 11651201.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Existing</td>\n",
       "      <td>230</td>\n",
       "      <td>transmission_line</td>\n",
       "      <td>1.0</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>Laos</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11642041.532 2064458.971, 11637642...</td>\n",
       "      <td>POLYGON ((11637741.737 2064075.819, 11637193.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Existing</td>\n",
       "      <td>230</td>\n",
       "      <td>transmission_line</td>\n",
       "      <td>2.0</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>Laos</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11895120.2 1689115.931, 11894570.3...</td>\n",
       "      <td>POLYGON ((11894481.255 1691616.252, 11852218.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Existing</td>\n",
       "      <td>115</td>\n",
       "      <td>transmission_line</td>\n",
       "      <td>3.0</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>Laos</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11417899.886 2043628.146, 11431921...</td>\n",
       "      <td>POLYGON ((11431917.506 2044306.41, 11431935.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Existing</td>\n",
       "      <td>115</td>\n",
       "      <td>transmission_line</td>\n",
       "      <td>4.0</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>Laos</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11417899.886 2043628.146, 11432471...</td>\n",
       "      <td>POLYGON ((11432490.024 2040979.482, 11432509.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Existing</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11532976.034 2090761.016, 11536981...</td>\n",
       "      <td>POLYGON ((11537052.726 2086775.9, 11537065.71 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Existing</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11538373.443 2088607.412, 11537840...</td>\n",
       "      <td>POLYGON ((11537743.256 2090921.908, 11537740.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Existing</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11396008.1 2094168.895, 11397829.5...</td>\n",
       "      <td>POLYGON ((11397733.747 2100286.154, 11397740.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Existing</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11369167.465 2255664.932, 11361572...</td>\n",
       "      <td>POLYGON ((11361655.11 2244413.017, 11361642.56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Existing</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11369167.465 2255664.932, 11361366...</td>\n",
       "      <td>POLYGON ((11361424.554 2252493.232, 11359515.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       status  capacity_kV              value   id      source country  \\\n",
       "0    Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "1    Existing          230  transmission_line  1.0  World Bank    Laos   \n",
       "2    Existing          230  transmission_line  2.0  World Bank    Laos   \n",
       "3    Existing          115  transmission_line  3.0  World Bank    Laos   \n",
       "4    Existing          115  transmission_line  4.0  World Bank    Laos   \n",
       "..        ...          ...                ...  ...         ...     ...   \n",
       "422  Existing           22               None  NaN  World Bank    None   \n",
       "423  Existing           22               None  NaN  World Bank    None   \n",
       "424  Existing           22               None  NaN  World Bank    None   \n",
       "425  Existing           22               None  NaN  World Bank    None   \n",
       "426  Existing           22               None  NaN  World Bank    None   \n",
       "\n",
       "    operator undergrnd phases cables  year asset  \\\n",
       "0       None      None   None   None  None  line   \n",
       "1       None      None   None   None  None  line   \n",
       "2       None      None   None   None  None  line   \n",
       "3       None      None   None   None  None  line   \n",
       "4       None      None   None   None  None  line   \n",
       "..       ...       ...    ...    ...   ...   ...   \n",
       "422     None      None   None   None  None  line   \n",
       "423     None      None   None   None  None  line   \n",
       "424     None      None   None   None  None  line   \n",
       "425     None      None   None   None  None  line   \n",
       "426     None      None   None   None  None  line   \n",
       "\n",
       "                                              geometry  \\\n",
       "0    LINESTRING (11642041.532 2064458.971, 11641491...   \n",
       "1    LINESTRING (11642041.532 2064458.971, 11637642...   \n",
       "2    LINESTRING (11895120.2 1689115.931, 11894570.3...   \n",
       "3    LINESTRING (11417899.886 2043628.146, 11431921...   \n",
       "4    LINESTRING (11417899.886 2043628.146, 11432471...   \n",
       "..                                                 ...   \n",
       "422  LINESTRING (11532976.034 2090761.016, 11536981...   \n",
       "423  LINESTRING (11538373.443 2088607.412, 11537840...   \n",
       "424  LINESTRING (11396008.1 2094168.895, 11397829.5...   \n",
       "425  LINESTRING (11369167.465 2255664.932, 11361572...   \n",
       "426  LINESTRING (11369167.465 2255664.932, 11361366...   \n",
       "\n",
       "                                              buffered  \n",
       "0    POLYGON ((11641591.898 2002921.519, 11651201.1...  \n",
       "1    POLYGON ((11637741.737 2064075.819, 11637193.0...  \n",
       "2    POLYGON ((11894481.255 1691616.252, 11852218.4...  \n",
       "3    POLYGON ((11431917.506 2044306.41, 11431935.18...  \n",
       "4    POLYGON ((11432490.024 2040979.482, 11432509.1...  \n",
       "..                                                 ...  \n",
       "422  POLYGON ((11537052.726 2086775.9, 11537065.71 ...  \n",
       "423  POLYGON ((11537743.256 2090921.908, 11537740.7...  \n",
       "424  POLYGON ((11397733.747 2100286.154, 11397740.7...  \n",
       "425  POLYGON ((11361655.11 2244413.017, 11361642.56...  \n",
       "426  POLYGON ((11361424.554 2252493.232, 11359515.6...  \n",
       "\n",
       "[427 rows x 14 columns]"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_infra = open_pg_data('LAO')\n",
    "print(type(pg_infra))\n",
    "pg_infra[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "24824f71-092f-4509-97cf-4e292da71126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_damage_pg(country_code,pg_infra,hazard_type):\n",
    "\n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(vul_curve_path,hazard_type)\n",
    "    #curves['line'] = 1 # remove this when things work!\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    pg_lines,pg_points = pg_infra\n",
    "    \n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "        df_ds = open_storm_data(country_code)\n",
    "\n",
    "        # remove assets that will not have any damage\n",
    "        pg_lines = pg_lines.loc[pg_lines.asset != 'cable'].reset_index(drop=True)\n",
    "    \n",
    "    elif hazard_type=='fl':\n",
    "        # read flood data\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "        df_ds = open_flood_data(country_code) \n",
    "    \n",
    "    #calculate damaged lines/polygons/points in loop by climate_model\n",
    "    damaged_lines = {}\n",
    "    damaged_points = {}\n",
    "    \n",
    "    # calculate damaged lines/polygons/points in loop by climate_model\n",
    "    for climate_model in climate_models:\n",
    "        \n",
    "        if hazard_type == 'tc':\n",
    "            return_periods = ['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),'1_10{}'.format(climate_model),\n",
    "                              '1_25{}'.format(climate_model),'1_50{}'.format(climate_model),'1_100{}'.format(climate_model),\n",
    "                              '1_250{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "        elif hazard_type == 'fl':\n",
    "            return_periods = ['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000']  \n",
    "\n",
    "        # assess damage for lines\n",
    "        overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],pg_lines).T,\n",
    "                                     columns=['asset','hazard_point'])\n",
    "        \n",
    "        if len(overlay_lines) == 0:\n",
    "            damaged_lines[climate_model] = pd.DataFrame()\n",
    "        \n",
    "        else:\n",
    "            collect_line_damages = []\n",
    "            for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                              desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_line_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                           df_ds[climate_model],\n",
    "                                                                           pg_lines,\n",
    "                                                                           curves,\n",
    "                                                                           maxdam,\n",
    "                                                                           return_period,\n",
    "                                                                           country_code))\n",
    "\n",
    "            get_asset_type_line = dict(zip(pg_lines.index,pg_lines.asset))\n",
    "\n",
    "            if hazard_type == 'fl':\n",
    "                results = pd.DataFrame(collect_line_damages,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "            elif hazard_type == 'tc':\n",
    "                results = pd.DataFrame([item for sublist in collect_line_damages for item in sublist],\n",
    "                                       columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "            results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "            damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "        # assess damage for points\n",
    "        overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],pg_points).T,\n",
    "                                      columns=['asset','hazard_point'])\n",
    "        \n",
    "        if len(overlay_points) == 0:\n",
    "            damaged_points[climate_model] = pd.DataFrame()\n",
    "                          \n",
    "        else:\n",
    "            collect_point_damages = []\n",
    "            for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                              desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_point_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                            df_ds[climate_model],\n",
    "                                                                            pg_points,\n",
    "                                                                            curves,\n",
    "                                                                            maxdam,\n",
    "                                                                            return_period,\n",
    "                                                                            country_code))\n",
    "\n",
    "            get_asset_type_point = dict(zip(pg_points.index,pg_points.asset))\n",
    "\n",
    "            if hazard_type == 'fl':\n",
    "                results = pd.DataFrame(collect_point_damages ,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "            elif hazard_type == 'tc':\n",
    "                results = pd.DataFrame([item for sublist in collect_point_damages for item in sublist],\n",
    "                                       columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "\n",
    "            results['asset_type'] = results.asset.apply(lambda x : get_asset_type_point[x])    \n",
    "\n",
    "            damaged_points[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "    return damaged_lines,damaged_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d5fb3-c1c9-4e1e-a73c-fea26042357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pg_infra = open_pg_data('LAO')\n",
    "pg_damage_infra = assess_damage_pg('LAO',pg_infra,'tc')\n",
    "pg_damage_infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "64cfcf4a-3381-4a83-9f58-6b254ce75336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'_CMCC-CM2-VHR4':                       rp curve asset_type  asset       meandam      lowerdam  \\\n",
       "  0   1_1000_CMCC-CM2-VHR4  W5_1       line   6786  3.282313e+08  2.461735e+08   \n",
       "  1   1_1000_CMCC-CM2-VHR4  W5_2       line   6786  3.474282e+08  2.605711e+08   \n",
       "  2   1_1000_CMCC-CM2-VHR4  W5_3       line   6786  3.474282e+08  2.605711e+08   \n",
       "  3    1_100_CMCC-CM2-VHR4  W5_1       line   6786  3.282313e+08  2.461735e+08   \n",
       "  4    1_100_CMCC-CM2-VHR4  W5_2       line   6786  3.474282e+08  2.605711e+08   \n",
       "  5    1_100_CMCC-CM2-VHR4  W5_3       line   6786  3.474282e+08  2.605711e+08   \n",
       "  6     1_10_CMCC-CM2-VHR4  W5_1       line   6786  2.813719e+08  2.110289e+08   \n",
       "  7     1_10_CMCC-CM2-VHR4  W5_2       line   6786  3.181328e+08  2.385996e+08   \n",
       "  8     1_10_CMCC-CM2-VHR4  W5_3       line   6786  3.015049e+08  2.261287e+08   \n",
       "  9      1_1_CMCC-CM2-VHR4  W5_1       line   6786  2.813719e+08  2.110289e+08   \n",
       "  10     1_1_CMCC-CM2-VHR4  W5_2       line   6786  3.181328e+08  2.385996e+08   \n",
       "  11     1_1_CMCC-CM2-VHR4  W5_3       line   6786  3.015049e+08  2.261287e+08   \n",
       "  12   1_250_CMCC-CM2-VHR4  W5_1       line   6786  3.282313e+08  2.461735e+08   \n",
       "  13   1_250_CMCC-CM2-VHR4  W5_2       line   6786  3.474282e+08  2.605711e+08   \n",
       "  14   1_250_CMCC-CM2-VHR4  W5_3       line   6786  3.474282e+08  2.605711e+08   \n",
       "  15    1_25_CMCC-CM2-VHR4  W5_1       line   6786  3.282313e+08  2.461735e+08   \n",
       "  16    1_25_CMCC-CM2-VHR4  W5_2       line   6786  3.474282e+08  2.605711e+08   \n",
       "  17    1_25_CMCC-CM2-VHR4  W5_3       line   6786  3.474282e+08  2.605711e+08   \n",
       "  18     1_2_CMCC-CM2-VHR4  W5_1       line   6786  2.813719e+08  2.110289e+08   \n",
       "  19     1_2_CMCC-CM2-VHR4  W5_2       line   6786  3.181328e+08  2.385996e+08   \n",
       "  20     1_2_CMCC-CM2-VHR4  W5_3       line   6786  3.015049e+08  2.261287e+08   \n",
       "  21   1_500_CMCC-CM2-VHR4  W5_1       line   6786  3.282313e+08  2.461735e+08   \n",
       "  22   1_500_CMCC-CM2-VHR4  W5_2       line   6786  3.474282e+08  2.605711e+08   \n",
       "  23   1_500_CMCC-CM2-VHR4  W5_3       line   6786  3.474282e+08  2.605711e+08   \n",
       "  24    1_50_CMCC-CM2-VHR4  W5_1       line   6786  3.282313e+08  2.461735e+08   \n",
       "  25    1_50_CMCC-CM2-VHR4  W5_2       line   6786  3.474282e+08  2.605711e+08   \n",
       "  26    1_50_CMCC-CM2-VHR4  W5_3       line   6786  3.474282e+08  2.605711e+08   \n",
       "  27     1_5_CMCC-CM2-VHR4  W5_1       line   6786  2.813719e+08  2.110289e+08   \n",
       "  28     1_5_CMCC-CM2-VHR4  W5_2       line   6786  3.181328e+08  2.385996e+08   \n",
       "  29     1_5_CMCC-CM2-VHR4  W5_3       line   6786  3.015049e+08  2.261287e+08   \n",
       "  \n",
       "          upperdam  \n",
       "  0   4.102891e+08  \n",
       "  1   4.342852e+08  \n",
       "  2   4.342852e+08  \n",
       "  3   4.102891e+08  \n",
       "  4   4.342852e+08  \n",
       "  5   4.342852e+08  \n",
       "  6   3.517149e+08  \n",
       "  7   3.976660e+08  \n",
       "  8   3.768811e+08  \n",
       "  9   3.517149e+08  \n",
       "  10  3.976660e+08  \n",
       "  11  3.768811e+08  \n",
       "  12  4.102891e+08  \n",
       "  13  4.342852e+08  \n",
       "  14  4.342852e+08  \n",
       "  15  4.102891e+08  \n",
       "  16  4.342852e+08  \n",
       "  17  4.342852e+08  \n",
       "  18  3.517149e+08  \n",
       "  19  3.976660e+08  \n",
       "  20  3.768811e+08  \n",
       "  21  4.102891e+08  \n",
       "  22  4.342852e+08  \n",
       "  23  4.342852e+08  \n",
       "  24  4.102891e+08  \n",
       "  25  4.342852e+08  \n",
       "  26  4.342852e+08  \n",
       "  27  3.517149e+08  \n",
       "  28  3.976660e+08  \n",
       "  29  3.768811e+08  },\n",
       " {})"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_damage_infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "1fac49c0-8408-4d6a-b063-ef6180b6c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_analysis_pg(country_code,hazard_type): #\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        country_code (_type_): _description_\n",
    "        hazard_type (str, optional): _description_. Defaults to 'OSM'.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    # extract infrastructure data from OSM\n",
    "    pg_infra = open_pg_data(country_code)\n",
    "\n",
    "    # assess damage to wind storms\n",
    "    pg_damage_infra = assess_damage_pg(country_code,pg_infra,hazard_type)\n",
    "    \n",
    "    if hazard_type=='tc':\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "    elif hazard_type=='fl':\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "    \n",
    "    line_risk = {}\n",
    "    plant_risk = {}\n",
    "    substation_risk = {}\n",
    "    tower_risk = {}\n",
    "    pole_risk = {}\n",
    "    \n",
    "    for i in range(len(pg_damage_infra)):\n",
    "        for climate_model in climate_models:\n",
    "            df = pg_damage_infra[i][climate_model]\n",
    "            \n",
    "            if len(df) == 0:\n",
    "                print(\"No {}_{} risk of infra_type {} in {}\".format(hazard_type,climate_model,i,country_code))\n",
    "\n",
    "            else:\n",
    "                with pd.ExcelWriter(os.path.join(output_path,'damage','{}_{}_pg_{}_damage_{}'.format(country_code,climate_model,hazard_type,i)+'.xlsx')) as writer:\n",
    "                    df.to_excel(writer)\n",
    "\n",
    "                if hazard_type == 'tc':\n",
    "                    df['rp'] = df['rp'].replace(['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),\n",
    "                                                 '1_10{}'.format(climate_model),'1_25{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                                                 '1_100{}'.format(climate_model),'1_250{}'.format(climate_model),'1_500{}'.format(climate_model),\n",
    "                                                 '1_1000{}'.format(climate_model)],\n",
    "                                                [1,0.5,0.2,0.1,0.04,0.02,0.01,0.004,0.002,0.001])\n",
    "\n",
    "                elif hazard_type == 'fl':\n",
    "                    df['rp'] = df['rp'].replace(['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000'],\n",
    "                                                [1,0.5,0.2,0.1,0.04,0.02,0.01,0.004,0.002,0.001])\n",
    "\n",
    "                #assess risk for power lines\n",
    "                if i == 0:\n",
    "                    loss_list = df.meandam.values.tolist()\n",
    "                    RPS = df.rp.values.tolist()\n",
    "                    line_risk[climate_model] = integrate.simps(y=loss_list[::-1], x=RPS[::-1])\n",
    "\n",
    "                #assess risk for power plants, substations, power towers and power poles\n",
    "                elif i == 1:\n",
    "                    loss_list = df.loc[df['asset_type'] == 'plant']\n",
    "                    loss_list = loss_list.meandam.values.tolist()\n",
    "                    RPS = df.loc[df['asset_type'] == 'plant']\n",
    "                    RPS = RPS.rp.values.tolist()\n",
    "                    plant_risk[climate_model] = integrate.simps(y=loss_list[::-1], x=RPS[::-1])\n",
    "\n",
    "                    loss_list = df.loc[df['asset_type'] == 'substation']\n",
    "                    loss_list = loss_list.meandam.values.tolist()\n",
    "                    RPS = df.loc[df['asset_type'] == 'substation']\n",
    "                    RPS = RPS.rp.values.tolist()\n",
    "                    substation_risk[climate_model] = integrate.simps(y=loss_list[::-1], x=RPS[::-1])\n",
    "\n",
    "                    loss_list = df.loc[df['asset_type'] == 'power_tower']\n",
    "                    loss_list = loss_list.meandam.values.tolist()\n",
    "                    RPS = df.loc[df['asset_type'] == 'power_tower']\n",
    "                    RPS = RPS.rp.values.tolist()\n",
    "                    tower_risk[climate_model] = integrate.simps(y=loss_list[::-1], x=RPS[::-1])\n",
    "\n",
    "                    loss_list = df.loc[df['asset_type'] == 'power_pole']\n",
    "                    loss_list = loss_list.meandam.values.tolist()\n",
    "                    RPS = df.loc[df['asset_type'] == 'power_pole']\n",
    "                    RPS = RPS.rp.values.tolist()\n",
    "                    pole_risk[climate_model] = integrate.simps(y=loss_list[::-1], x=RPS[::-1])\n",
    "    \n",
    "    return line_risk,plant_risk,substation_risk,tower_risk,pole_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "55f35961-9d67-4c34-82fb-2150a356c7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for LAO fl (historical): 0it [00:00, ?it/s]\n",
      "point damage calculation for LAO fl (historical): 0it [00:00, ?it/s]\n",
      "polyline damage calculation for LAO fl (rcp8p5): 0it [00:00, ?it/s]\n",
      "point damage calculation for LAO fl (rcp8p5): 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'historical'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [642], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pg_damage_infra \u001b[38;5;241m=\u001b[39m \u001b[43mcountry_analysis_pg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLAO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [641], line 22\u001b[0m, in \u001b[0;36mcountry_analysis_pg\u001b[1;34m(country_code, hazard_type)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pg_damage_infra)):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m climate_model \u001b[38;5;129;01min\u001b[39;00m climate_models:\n\u001b[1;32m---> 22\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mpg_damage_infra\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclimate_model\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mExcelWriter(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_path,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdamage\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_pg_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_damage_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(country_code,climate_model,hazard_type,i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m writer:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'historical'"
     ]
    }
   ],
   "source": [
    "pg_damage_infra = country_analysis_pg('LAO','fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c27ed-b883-4878-b1d5-6f884e05ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_damage_infra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d834a-0c75-4ede-8c0e-d796e7e26a0e",
   "metadata": {},
   "source": [
    "# Save results of risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3abf597a-b538-446a-862b-3c9ed21ca2f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def risk_output(country_code,hazard_type,infra_type):\n",
    "    \n",
    "    if infra_type == 'osm':\n",
    "        total_risk = pd.DataFrame(country_analysis_osm(country_code,hazard_type))\n",
    "        total_risk.to_excel(os.path.join(output_path,'risk','{}_{}_{}_risk'.format(country_code,infra_type,hazard_type)+'.xlsx'))\n",
    "    \n",
    "    elif infra_type == 'gov':\n",
    "        total_risk = pd.DataFrame(country_analysis_pg(country_code,hazard_type))\n",
    "        total_risk.to_excel(os.path.join(output_path,'risk','{}_{}_{}_risk'.format(country_code,infra_type,hazard_type)+'.xlsx'))\n",
    "    \n",
    "    return total_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "172da5db-75f8-4773-8cb9-39c770cb82d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439/439 [00:02<00:00, 155.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:08<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45489/45489 [00:04<00:00, 9836.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n",
      "No power lines exposed to fl in LAO\n",
      "No power polygons exposed to fl in LAO\n",
      "No power points exposed to fl in LAO\n",
      "No power lines exposed to fl in LAO\n",
      "No power polygons exposed to fl in LAO\n",
      "No power points exposed to fl in LAO\n",
      "No risk: LAO historical\n",
      "No risk: LAO rcp8p5\n",
      "No risk: LAO historical\n",
      "No risk: LAO rcp8p5\n",
      "No risk: LAO historical\n",
      "No risk: LAO rcp8p5\n"
     ]
    }
   ],
   "source": [
    "total_risk = risk_output('LAO','fl','osm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5a9d9ed-2b37-4503-8e8f-b6bca5c4709c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2470/2470 [00:07<00:00, 335.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 368/368 [00:18<00:00, 19.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1608621/1608621 [02:42<00:00, 9895.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for TWN fl (historical): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:01<00:00, 31.32it/s]\n",
      "polygon damage calculation for TWN fl (historical): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:02<00:00, 20.43it/s]\n",
      "point damage calculation for TWN fl (historical): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 325/325 [00:05<00:00, 60.11it/s]\n",
      "polyline damage calculation for TWN fl (rcp8p5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 31.45it/s]\n",
      "polygon damage calculation for TWN fl (rcp8p5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:02<00:00, 20.88it/s]\n",
      "point damage calculation for TWN fl (rcp8p5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392/392 [00:06<00:00, 59.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>historical</th>\n",
       "      <th>rcp8p5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.054249e+05</td>\n",
       "      <td>1.369007e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.956667e+09</td>\n",
       "      <td>2.598843e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.313280e+06</td>\n",
       "      <td>6.924929e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.452217e+05</td>\n",
       "      <td>1.970477e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.953943e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     historical        rcp8p5\n",
       "0  1.054249e+05  1.369007e+05\n",
       "1  1.956667e+09  2.598843e+09\n",
       "2  5.313280e+06  6.924929e+06\n",
       "3  1.452217e+05  1.970477e+05\n",
       "4  0.000000e+00  1.953943e-01"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_risk = risk_output('TWN','fl','osm')\n",
    "total_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "f25448e6-5b5d-434d-8332-8471a4a7e2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rp</th>\n",
       "      <th>curve</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>meandam</th>\n",
       "      <th>lowerdam</th>\n",
       "      <th>upperdam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>1.658665e+09</td>\n",
       "      <td>4.523633e+08</td>\n",
       "      <td>2.261816e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>1.730781e+09</td>\n",
       "      <td>4.720311e+08</td>\n",
       "      <td>2.360156e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.388258e+09</td>\n",
       "      <td>6.513430e+08</td>\n",
       "      <td>3.256715e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.100</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.552940e+09</td>\n",
       "      <td>6.962564e+08</td>\n",
       "      <td>3.481282e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.040</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.767454e+09</td>\n",
       "      <td>7.547601e+08</td>\n",
       "      <td>3.773801e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.020</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.921201e+09</td>\n",
       "      <td>7.966912e+08</td>\n",
       "      <td>3.983456e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.010</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.080762e+09</td>\n",
       "      <td>8.402079e+08</td>\n",
       "      <td>4.201039e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.004</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.356950e+09</td>\n",
       "      <td>9.155320e+08</td>\n",
       "      <td>4.577660e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.528684e+09</td>\n",
       "      <td>9.623684e+08</td>\n",
       "      <td>4.811842e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.698459e+09</td>\n",
       "      <td>1.008671e+09</td>\n",
       "      <td>5.043354e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rp  curve asset_type       meandam      lowerdam      upperdam\n",
       "0   1.000  plant      plant  1.658665e+09  4.523633e+08  2.261816e+09\n",
       "2   0.500  plant      plant  1.730781e+09  4.720311e+08  2.360156e+09\n",
       "4   0.200  plant      plant  2.388258e+09  6.513430e+08  3.256715e+09\n",
       "6   0.100  plant      plant  2.552940e+09  6.962564e+08  3.481282e+09\n",
       "8   0.040  plant      plant  2.767454e+09  7.547601e+08  3.773801e+09\n",
       "10  0.020  plant      plant  2.921201e+09  7.966912e+08  3.983456e+09\n",
       "12  0.010  plant      plant  3.080762e+09  8.402079e+08  4.201039e+09\n",
       "14  0.004  plant      plant  3.356950e+09  9.155320e+08  4.577660e+09\n",
       "16  0.002  plant      plant  3.528684e+09  9.623684e+08  4.811842e+09\n",
       "18  0.001  plant      plant  3.698459e+09  1.008671e+09  5.043354e+09"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_damage_infra[1]['historical'].loc[osm_damage_infra[1]['historical']['asset_type'] == 'plant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "b3065e13-2e48-4dd3-b027-5d7815a9f94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.000\n",
       "1     1.000\n",
       "2     1.000\n",
       "3     0.500\n",
       "4     0.500\n",
       "5     0.500\n",
       "6     0.200\n",
       "7     0.200\n",
       "8     0.200\n",
       "9     0.100\n",
       "10    0.100\n",
       "11    0.100\n",
       "12    0.040\n",
       "13    0.040\n",
       "14    0.040\n",
       "15    0.020\n",
       "16    0.020\n",
       "17    0.020\n",
       "18    0.010\n",
       "19    0.010\n",
       "20    0.010\n",
       "21    0.004\n",
       "22    0.004\n",
       "23    0.004\n",
       "24    0.002\n",
       "25    0.002\n",
       "26    0.002\n",
       "27    0.001\n",
       "28    0.001\n",
       "29    0.001\n",
       "Name: rp, dtype: float64"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osm_damage_infra[0]['historical'].loc[:,\"rp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769479e-4a85-4931-af47-fb1ff09b73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def clip_gridfinder(country_code):\n",
    "    base_map_path = os.path.join(data_path,'base_map')\n",
    "\n",
    "    cty_boundary_path = os.path.join(base_map_path,'gadm41_{}.gpkg'.format(country_code))\n",
    "    cty_boundary = gpd.read_file(cty_boundary_path)\n",
    "    #mask = pd.DataFrame(mask.copy())\n",
    "    #mask.geometry = pygeos.from_shapely(mask.geometry)\n",
    "    #mask['geometry'] = reproject(mask)\n",
    "\n",
    "    gridfinder_path = r'C:\\Users\\mye500\\OneDrive - Vrije Universiteit Amsterdam\\01_Research-Projects\\01_risk_assessment\\PG_data\\gridfinder\\grid.gpkg'\n",
    "    gridfinder = gpd.read_file(gridfinder_path)\n",
    "    #gridfinder = pd.DataFrame(gridfinder.copy())\n",
    "    #gridfinder.geometry = pygeos.from_shapely(gridfinder.geometry)\n",
    "    #gridfinder['geometry'] = reproject(gridfinder)\n",
    "\n",
    "    clipped = gpd.clip(gridfinder,cty_boundary)\n",
    "\n",
    "    return clipped\n",
    "\n",
    "clip_gridfinder('TWN')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "fb67b933-b02e-478b-a41f-53764c711e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def monetary_risk(RPS,loss_list):\n",
    "def monetary_risk(osm_damage_infra,hazard_type):\n",
    "    \"\"\"\n",
    "    Calculates the monetary risk based on the return periods and the losses.\n",
    "    Arguments:\n",
    "        *RPS* : List of return periods (in years) for which the losses are calculated.\n",
    "        *loss_list* : List of losses (in euro) for each return period.\n",
    "    Returns:\n",
    "        *total_risk* : Returns the total risk for the area\n",
    "    \"\"\"\n",
    "    \n",
    "    # assess damage to hazard_type\n",
    "    #osm_damage_infra = country_analysis_osm(country_code,hazard_type)\n",
    "    \n",
    "    if hazard_type=='tc':\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "        total_risk = pd.DataFrame(columns=[climate_models])\n",
    "\n",
    "    elif hazard_type=='fl':\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "        total_risk = pd.DataFrame(columns=[climate_models])\n",
    "\n",
    "    line_risk = {}\n",
    "    plant_risk = {}\n",
    "    substation_risk = {}\n",
    "    tower_risk = {}\n",
    "    pole_risk = {}\n",
    "    total_risk = {}\n",
    "    osm_risk = {}\n",
    "    \n",
    "    asset_types = ['line','minor_line','cable','plant','substation','power_tower','power_pole']\n",
    "    \n",
    "    for climate_model in climate_models:\n",
    "        for i in range(len(osm_damage_infra)):\n",
    "            for asset_type in asset_types:\n",
    "                \n",
    "                df = osm_damage_infra[i][climate_model]\n",
    "                df['rp'] = df['rp'].replace(['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000'],\n",
    "                                            [1,0.5,0.2,0.1,0.04,0.02,0.01,0.004,0.002,0.001])\n",
    "                \n",
    "                loss_list = df.loc[df['asset_type'] == asset_type]\n",
    "                RPS = loss_list.rp.values.tolist()\n",
    "                #RPS = df.loc[df['asset_type'] == 'asset_type']\n",
    "                \n",
    "                loss_list = loss_list.meandam.values.tolist()\n",
    "                print(loss_list)\n",
    "                print(RPS)\n",
    "                \n",
    "                osm_risk[climate_model] = integrate.simps(y=loss_list[::-1], x=RPS[::-1])\n",
    "                \n",
    "                #'{}_risk'.format(asset_type)[climate_model] = integrate.simps(y=loss_list[::-1], x=RPS[::-1])\n",
    "                \n",
    "                #total_risk[climate_model] = total_risk.update(line_risk)\n",
    "                #print(integrate.simps(y=loss_list_line[::-1], x=RPS[::-1]))\n",
    "                #print(line_risk[climate_model])\n",
    "\n",
    "                \n",
    "                #total_risk[climate_model] = total_risk.update(plant_risk)\n",
    "                #total_risk.append(plant_risk[climate_model])\n",
    "\n",
    "    #total_risk = pd.DataFrame(total_risk[climate_model])\n",
    "    \"\"\"\n",
    "    if hazard_type == 'tc':\n",
    "        total_risk = pd.DataFrame({'historical':pd.Series(line_risk[0]['historical']),'rcp8p5':pd.Series(line_risk[1]['rcp8p5'])})\n",
    "    \n",
    "    elif hazard_type == 'fl':\n",
    "        total_risk = pd.DataFrame({'historical':pd.Series(line_risk[0]['historical']),'rcp8p5':pd.Series(line_risk[1]['rcp8p5'])})\n",
    "    \"\"\"        \n",
    "    return osm_risk#line_risk,plant_risk,substation_risk,tower_risk,pole_risk,total_risk#line_risk,plant_risk,substation_risk,tower_risk,pole_risk #integrate.simps(y=loss_list[::-1], x=RPS[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d911c-7f1d-41fc-bade-cb8ec5e31fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
