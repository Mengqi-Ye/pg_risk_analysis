{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5263e9-087d-4863-a4e5-839dc33017bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osgeo import ogr,gdal\n",
    "import os\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pyproj\n",
    "from pygeos import from_wkb,from_wkt\n",
    "import pygeos\n",
    "from tqdm import tqdm\n",
    "from shapely.wkb import loads\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from shapely.geometry import mapping\n",
    "pd.options.mode.chained_assignment = None\n",
    "from rasterio.mask import mask\n",
    "import rioxarray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6f11a902-f512-4fd3-b035-af38041ee083",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal.SetConfigOption(\"OSM_CONFIG_FILE\", os.path.join('..',\"osmconf.ini\"))\n",
    "\n",
    "# change paths to make it work on your own machine\n",
    "data_path = os.path.join('C:\\\\','Data','pg_risk_analysis')\n",
    "tc_path = os.path.join(data_path,'tc_netcdf')\n",
    "fl_path = os.path.join(data_path,'GLOFRIS')\n",
    "osm_data_path = os.path.join('C:\\\\','Data','country_osm')\n",
    "pg_data_path = os.path.join(data_path,'pg_data')\n",
    "vul_curve_path = os.path.join(data_path,'vulnerability_curves','input_vulnerability_data.xlsx')\n",
    "output_path = os.path.join('C:\\\\','projects','pg_risk_analysis','output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fc83d355-8c98-4ae6-97b1-3203a29a4fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_b(geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    This function builds an SQL query from the values passed to the retrieve() function.\n",
    "    Arguments:\n",
    "         *geoType* : Type of geometry (osm layer) to search for.\n",
    "         *keyCol* : A list of keys/columns that should be selected from the layer.\n",
    "         ***valConstraint* : A dictionary of constraints for the values. e.g. WHERE 'value'>20 or 'value'='constraint'\n",
    "    Returns:\n",
    "        *string: : a SQL query string.\n",
    "    \"\"\"\n",
    "    query = \"SELECT \" + \"osm_id\"\n",
    "    for a in keyCol: query+= \",\"+ a  \n",
    "    query += \" FROM \" + geoType + \" WHERE \"\n",
    "    # If there are values in the dictionary, add constraint clauses\n",
    "    if valConstraint: \n",
    "        for a in [*valConstraint]:\n",
    "            # For each value of the key, add the constraint\n",
    "            for b in valConstraint[a]: query += a + b\n",
    "        query+= \" AND \"\n",
    "    # Always ensures the first key/col provided is not Null.\n",
    "    query+= \"\"+str(keyCol[0]) +\" IS NOT NULL\" \n",
    "    return query \n",
    "\n",
    "\n",
    "def retrieve(osm_path,geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    Function to extract specified geometry and keys/values from OpenStreetMap\n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.     \n",
    "        *geoType* : Type of Geometry to retrieve. e.g. lines, multipolygons, etc.\n",
    "        *keyCol* : These keys will be returned as columns in the dataframe.\n",
    "        ***valConstraint: A dictionary specifiying the value constraints.  \n",
    "        A key can have multiple values (as a list) for more than one constraint for key/value.  \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all columns, geometries, and constraints specified.    \n",
    "    \"\"\"\n",
    "    driver=ogr.GetDriverByName('OSM')\n",
    "    data = driver.Open(osm_path)\n",
    "    query = query_b(geoType,keyCol,**valConstraint)\n",
    "    sql_lyr = data.ExecuteSQL(query)\n",
    "    features =[]\n",
    "    # cl = columns \n",
    "    cl = ['osm_id'] \n",
    "    for a in keyCol: cl.append(a)\n",
    "    if data is not None:\n",
    "        print('query is finished, lets start the loop')\n",
    "        for feature in tqdm(sql_lyr,desc='extract'):\n",
    "            #try:\n",
    "            if feature.GetField(keyCol[0]) is not None:\n",
    "                geom1 = (feature.geometry().ExportToWkt())\n",
    "                #print(geom1)\n",
    "                geom = from_wkt(feature.geometry().ExportToWkt()) \n",
    "                if geom is None:\n",
    "                    continue\n",
    "                # field will become a row in the dataframe.\n",
    "                field = []\n",
    "                for i in cl: field.append(feature.GetField(i))\n",
    "                field.append(geom)   \n",
    "                features.append(field)\n",
    "            #except:\n",
    "            #    print(\"WARNING: skipped OSM feature\")   \n",
    "    else:\n",
    "        print(\"ERROR: Nonetype error when requesting SQL. Check required.\")    \n",
    "    cl.append('geometry')                   \n",
    "    if len(features) > 0:\n",
    "        return pd.DataFrame(features,columns=cl)\n",
    "    else:\n",
    "        print(\"WARNING: No features or No Memory. returning empty GeoDataFrame\") \n",
    "        return pd.DataFrame(columns=['osm_id','geometry'])\n",
    "\n",
    "def power_polyline(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract all energy linestrings from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'lines',['power','voltage'])\n",
    "    \n",
    "    df = df.reset_index(drop=True).rename(columns={'power': 'asset'})\n",
    "    \n",
    "    #print(df) #check infra keys\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def power_polygon(osm_path): # check with joel, something was wrong here with extracting substations\n",
    "    \"\"\"\n",
    "    Function to extract energy polygons from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['other_tags']) \n",
    "    \n",
    "    df = df.loc[(df.other_tags.str.contains('power'))]   #keep rows containing power data         \n",
    "    df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})     \n",
    "    \n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"substation\"', case=False)]  = 'substation' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"plant\"', case=False)] = 'plant' #specify row\n",
    "    \n",
    "    df = df.loc[(df.asset == 'substation') | (df.asset == 'plant')]\n",
    "            \n",
    "    return df.reset_index(drop=True) \n",
    "\n",
    "def electricity(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract building polygons from OpenStreetMap    \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all unique building polygons.    \n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['power'])\n",
    "    \n",
    "    df = df.reset_index(drop=True).rename(columns={'power': 'asset'})\n",
    "    \n",
    "    #df = df[df.asset!='generator']\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"substation\"', case=False)]  = 'substation' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"plant\"', case=False)] = 'plant' #specify row\n",
    "    \n",
    "    #print(df)  #check infra keys\n",
    "    \n",
    "    df = df.loc[(df.asset == 'substation') | (df.asset == 'plant')]\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def retrieve_poly_subs(osm_path, w_list, b_list):\n",
    "    \"\"\"\n",
    "    Function to extract electricity substation polygons from OpenStreetMap\n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region\n",
    "        for which we want to do the analysis.\n",
    "        *w_list* :  white list of keywords to search in the other_tags columns\n",
    "        *b_list* :  black list of keywords of rows that should not be selected\n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique substation.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['other_tags'])\n",
    "    df = df[df.other_tags.str.contains('substation', case=False, na=False)]\n",
    "    #df = df.loc[(df.other_tags.str.contains('substation'))]\n",
    "    df = df[~df.other_tags.str.contains('|'.join(b_list))]\n",
    "    #df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})\n",
    "    df['asset']  = 'substation' #specify row\n",
    "    #df = df.loc[(df.asset == 'substation')] #specify row\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def power_point(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract energy points from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"   \n",
    "    df = retrieve(osm_path,'points',['other_tags']) \n",
    "    df = df.loc[(df.other_tags.str.contains('power'))]  #keep rows containing power data       \n",
    "    df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})     \n",
    "    \n",
    "    #print(df)\n",
    "    \n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"tower\"', case=False)]  = 'power_tower' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"pole\"', case=False)] = 'power_pole' #specify row\n",
    "    #df['asset'].loc[df['asset'].str.contains('\"utility\"=>\"power\"', case=False)] = 'power_tower' #specify row\n",
    "    \n",
    "    df = df.loc[(df.asset == 'power_tower') | (df.asset == 'power_pole')]\n",
    "            \n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "36fe9f2e-0be0-47fd-83ca-67f3a272279d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reproject(df_ds,current_crs=\"epsg:4326\",approximate_crs = \"epsg:3857\"):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        df_ds ([type]): [description]\n",
    "        current_crs (str, optional): [description]. Defaults to \"epsg:3857\".\n",
    "        approximate_crs (str, optional): [description]. Defaults to \"epsg:4326\".\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"    \n",
    "\n",
    "    geometries = df_ds['geometry']\n",
    "    coords = pygeos.get_coordinates(geometries)\n",
    "    transformer=pyproj.Transformer.from_crs(current_crs, approximate_crs,always_xy=True)\n",
    "    new_coords = transformer.transform(coords[:, 0], coords[:, 1])\n",
    "    \n",
    "    return pygeos.set_coordinates(geometries.copy(), np.array(new_coords).T) \n",
    "\n",
    "def load_curves_maxdam(vul_curve_path,hazard_type):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        data_path ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "\n",
    "    if hazard_type == 'tc':\n",
    "        sheet_name = 'wind_curves'\n",
    "    \n",
    "    elif hazard_type == 'fl':\n",
    "        sheet_name = 'flooding_curves' #_last_version\n",
    "    \n",
    "    # load curves and maximum damages as separate inputs\n",
    "    curves = pd.read_excel(vul_curve_path,sheet_name=sheet_name,skiprows=10,index_col=[0])\n",
    "    \n",
    "    if hazard_type == 'fl':\n",
    "        maxdam = pd.read_excel(vul_curve_path,sheet_name=sheet_name,index_col=[0]).iloc[:8]\n",
    "        #maxdam = maxdam.rename({'substation_point':'substation'},level=0,axis=1)\n",
    "        #maxdam = maxdam.rename({'plant_point':'plant'},level=0,axis=1)\n",
    "    elif hazard_type == 'tc':\n",
    "        maxdam = pd.read_excel(vul_curve_path,sheet_name=sheet_name,index_col=[0],header=[0,1]).iloc[:7]\n",
    "        maxdam = maxdam.rename({'substation_point':'substation'},level=0,axis=1)\n",
    "    \n",
    "    curves.columns = maxdam.columns\n",
    "        \n",
    "    #transpose maxdam so its easier work with the dataframe\n",
    "    maxdam = maxdam.T\n",
    "\n",
    "    #interpolate the curves to fill missing values\n",
    "    curves = curves.interpolate()\n",
    "    \n",
    "    return curves,maxdam\n",
    "\n",
    "def buffer_assets(assets, buffer_size=100):\n",
    "    \"\"\"\n",
    "    Create a buffer of a specified size around the geometries in a GeoDataFrame.\n",
    "    \n",
    "    Args:\n",
    "        assets (GeoDataFrame): A GeoDataFrame containing geometries to be buffered.\n",
    "        buffer_size (int, optional): The distance in the units of the GeoDataFrame's CRS to buffer the geometries.\n",
    "            Defaults to 100.\n",
    "    \n",
    "    Returns:\n",
    "        GeoDataFrame: A new GeoDataFrame with an additional column named 'buffered' containing the buffered\n",
    "            geometries.\n",
    "    \"\"\"\n",
    "    # Create a buffer of the specified size around the geometries\n",
    "    assets['buffered'] = pygeos.buffer(assets.geometry.values, buffer_size)\n",
    "    \n",
    "    return assets\n",
    "\n",
    "\n",
    "def overlay_hazard_assets(df_ds, assets):\n",
    "    \"\"\"\n",
    "    Overlay a set of assets with a hazard dataset and return the subset of assets that intersect with\n",
    "    one or more hazard polygons or lines.\n",
    "    \n",
    "    Args:\n",
    "        df_ds (GeoDataFrame): A GeoDataFrame containing the hazard dataset.\n",
    "        assets (GeoDataFrame): A GeoDataFrame containing the assets to be overlaid with the hazard dataset.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: A numpy array of integers representing the indices of the hazard geometries that intersect with\n",
    "            the assets. If the assets have a 'buffered' column, the buffered geometries are used for the overlay.\n",
    "    \"\"\"\n",
    "    hazard_tree = pygeos.STRtree(df_ds.geometry.values)\n",
    "    if (pygeos.get_type_id(assets.iloc[0].geometry) == 3) | (pygeos.get_type_id(assets.iloc[0].geometry) == 6):\n",
    "        return  hazard_tree.query_bulk(assets.geometry,predicate='intersects')    \n",
    "    else:\n",
    "        return  hazard_tree.query_bulk(assets.buffered,predicate='intersects')\n",
    "    \n",
    "def get_damage_per_asset_per_rp(asset,df_ds,assets,curves,maxdam,return_period,country):\n",
    "    \"\"\"\n",
    "    Calculates the damage per asset per return period based on asset type, hazard curves and maximum damage\n",
    "\n",
    "    Args:\n",
    "        asset (tuple): Tuple with two dictionaries, containing the asset index and the hazard point index of the asset\n",
    "        df_ds (pandas.DataFrame): A pandas DataFrame containing hazard points with a 'geometry' column\n",
    "        assets (geopandas.GeoDataFrame): A GeoDataFrame containing asset geometries and asset type information\n",
    "        curves (dict): A dictionary with the asset types as keys and their corresponding hazard curves as values\n",
    "        maxdam (pandas.DataFrame): A pandas DataFrame containing the maximum damage for each asset type\n",
    "        return_period (str): The return period for which the damage should be calculated\n",
    "        country (str): The country for which the damage should be calculated\n",
    "\n",
    "    Returns:\n",
    "        list or tuple: Depending on the input, the function either returns a list of tuples with the asset index, the curve name and the calculated damage, or a tuple with None, None, None if no hazard points are found\n",
    "    \"\"\"\n",
    "    \n",
    "    # find the exact hazard overlays:\n",
    "    get_hazard_points = df_ds.iloc[asset[1]['hazard_point'].values].reset_index()\n",
    "    get_hazard_points = get_hazard_points.loc[pygeos.intersects(get_hazard_points.geometry.values,assets.iloc[asset[0]].geometry)]\n",
    "\n",
    "    asset_type = assets.iloc[asset[0]].asset\n",
    "    asset_geom = assets.iloc[asset[0]].geometry\n",
    "\n",
    "    if asset_type in ['plant','substation','generator']:\n",
    "        maxdam_asset = maxdam.loc[asset_type].MaxDam/pygeos.area(asset_geom)\n",
    "        lowerdam_asset = maxdam.loc[asset_type].LowerDam/pygeos.area(asset_geom)\n",
    "        upperdam_asset = maxdam.loc[asset_type].UpperDam/pygeos.area(asset_geom)\n",
    "    else:\n",
    "        maxdam_asset = maxdam.loc[asset_type].MaxDam\n",
    "        lowerdam_asset = maxdam.loc[asset_type].LowerDam\n",
    "        upperdam_asset = maxdam.loc[asset_type].UpperDam\n",
    "\n",
    "    hazard_intensity = curves[asset_type].index.values\n",
    "    \n",
    "    if isinstance(curves[asset_type],pd.core.series.Series):\n",
    "        fragility_values = curves[asset_type].values.flatten()\n",
    "        only_one = True\n",
    "        curve_name = curves[asset_type].name\n",
    "    elif len(curves[asset_type].columns) == 1:\n",
    "        fragility_values = curves[asset_type].values.flatten()      \n",
    "        only_one = True   \n",
    "        curve_name = curves[asset_type].columns[0]\n",
    "    else:\n",
    "        fragility_values = curves[asset_type].values#.T[0]\n",
    "        maxdam_asset = maxdam_asset.values#[0]\n",
    "        only_one = False\n",
    "\n",
    "    if len(get_hazard_points) == 0:\n",
    "        return [return_period,asset[0],None,None,None,None]\n",
    "    else:\n",
    "        if only_one:    \n",
    "            # run the calculation as normal when the asset just has a single curve\n",
    "            if pygeos.get_type_id(asset_geom) == 1:            \n",
    "                get_hazard_points['overlay_meters'] = pygeos.length(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "                return [return_period,asset[0],curve_name,np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*maxdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*lowerdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*upperdam_asset)]\n",
    "\n",
    "            elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                get_hazard_points['overlay_m2'] = pygeos.area(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "                return [return_period,asset[0],curve_name,get_hazard_points.apply(lambda x: np.interp(x[return_period],hazard_intensity, \n",
    "                                                                  fragility_values)*maxdam_asset*x.overlay_m2,axis=1).sum(),\n",
    "                                                          get_hazard_points.apply(lambda x: np.interp(x[return_period],hazard_intensity, \n",
    "                                                                  fragility_values)*lowerdam_asset*x.overlay_m2,axis=1).sum(),\n",
    "                                                          get_hazard_points.apply(lambda x: np.interp(x[return_period],hazard_intensity, \n",
    "                                                                  fragility_values)*upperdam_asset*x.overlay_m2,axis=1).sum()]     \n",
    "\n",
    "            else:\n",
    "                return [return_period,asset[0],curve_name,np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*maxdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*lowerdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*upperdam_asset)]\n",
    "        else:\n",
    "            # run the calculation when the asset has multiple curves\n",
    "            if pygeos.get_type_id(asset_geom) == 1:            \n",
    "                get_hazard_points['overlay_meters'] = pygeos.length(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                get_hazard_points['overlay_m2'] = pygeos.area(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            \n",
    "            collect_all = []\n",
    "            for iter_,curve_ids in enumerate(curves[asset_type].columns):\n",
    "                if pygeos.get_type_id(asset_geom) == 1:                           \n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*get_hazard_points.overlay_meters*maxdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*get_hazard_points.overlay_meters*lowerdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*get_hazard_points.overlay_meters*upperdam_asset[iter_])])\n",
    "                \n",
    "                elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                        get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity,\n",
    "                                                                                    fragility_values.T[iter_])*maxdam_asset[iter_]*x.overlay_m2,axis=1).sum(),\n",
    "                                        get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity,\n",
    "                                                                                    fragility_values.T[iter_])*lowerdam_asset[iter_]*x.overlay_m2,axis=1).sum(),\n",
    "                                        get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity,\n",
    "                                                                                    fragility_values.T[iter_])*upperdam_asset[iter_]*x.overlay_m2,axis=1).sum()])\n",
    "\n",
    "                else:\n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*maxdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*lowerdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*upperdam_asset[iter_])])\n",
    "            return collect_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1bf0e992-b4d1-46b0-a952-488ac8c5b2b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Infrastructure type</th>\n",
       "      <th>Code</th>\n",
       "      <th>Type vulnerability data</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Specific occupancy</th>\n",
       "      <th>Reference</th>\n",
       "      <th>MaxDam</th>\n",
       "      <th>LowerDam</th>\n",
       "      <th>UpperDam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>plant</th>\n",
       "      <td>F1_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>Small/medium/large power plants</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>469326964.354556</td>\n",
       "      <td>127998263.005788</td>\n",
       "      <td>639991315.02894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>substation</th>\n",
       "      <td>F2_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>Low/medium/high voltage substation</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>34132870.134877</td>\n",
       "      <td>12799826.300579</td>\n",
       "      <td>63999131.502894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_tower</th>\n",
       "      <td>F3_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>128807.753197</td>\n",
       "      <td>22657.06884</td>\n",
       "      <td>437857.236411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_pole</th>\n",
       "      <td>F4_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>22706.148119</td>\n",
       "      <td>10805.300809</td>\n",
       "      <td>35832.221593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>F5_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>918.052146</td>\n",
       "      <td>136.209517</td>\n",
       "      <td>2095.531033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minor_line</th>\n",
       "      <td>F5_2</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>minor line</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>509.785702</td>\n",
       "      <td>62.865931</td>\n",
       "      <td>955.562151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cable</th>\n",
       "      <td>F5_3</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>cable: Distribution circuits elevated crossings</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>3400.782131</td>\n",
       "      <td>461.016827</td>\n",
       "      <td>9639.442752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plant_point</th>\n",
       "      <td>F1_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>Small/medium/large power plants</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>469326964.354556</td>\n",
       "      <td>127998263.005788</td>\n",
       "      <td>639991315.02894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>substation_point</th>\n",
       "      <td>F2_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>Low/medium/high voltage substation</td>\n",
       "      <td>FEMA, 2013</td>\n",
       "      <td>34132870.134877</td>\n",
       "      <td>12799826.300579</td>\n",
       "      <td>63999131.502894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Infrastructure type  Code Type vulnerability data           Unit  \\\n",
       "plant                F1_1                   curve  euro/facility   \n",
       "substation           F2_1                   curve  euro/facility   \n",
       "power_tower          F3_1                   curve  euro/facility   \n",
       "power_pole           F4_1                   curve  euro/facility   \n",
       "line                 F5_1                   curve         euro/m   \n",
       "minor_line           F5_2                   curve         euro/m   \n",
       "cable                F5_3                   curve         euro/m   \n",
       "plant_point          F1_1                   curve  euro/facility   \n",
       "substation_point     F2_1                   curve  euro/facility   \n",
       "\n",
       "Infrastructure type                               Specific occupancy  \\\n",
       "plant                                Small/medium/large power plants   \n",
       "substation                        Low/medium/high voltage substation   \n",
       "power_tower                                                      NaN   \n",
       "power_pole                                                       NaN   \n",
       "line                                                             NaN   \n",
       "minor_line                                                minor line   \n",
       "cable                cable: Distribution circuits elevated crossings   \n",
       "plant_point                          Small/medium/large power plants   \n",
       "substation_point                  Low/medium/high voltage substation   \n",
       "\n",
       "Infrastructure type   Reference            MaxDam          LowerDam  \\\n",
       "plant                FEMA, 2013  469326964.354556  127998263.005788   \n",
       "substation           FEMA, 2013   34132870.134877   12799826.300579   \n",
       "power_tower          FEMA, 2013     128807.753197       22657.06884   \n",
       "power_pole           FEMA, 2013      22706.148119      10805.300809   \n",
       "line                 FEMA, 2013        918.052146        136.209517   \n",
       "minor_line           FEMA, 2013        509.785702         62.865931   \n",
       "cable                FEMA, 2013       3400.782131        461.016827   \n",
       "plant_point          FEMA, 2013  469326964.354556  127998263.005788   \n",
       "substation_point     FEMA, 2013   34132870.134877   12799826.300579   \n",
       "\n",
       "Infrastructure type         UpperDam  \n",
       "plant                639991315.02894  \n",
       "substation           63999131.502894  \n",
       "power_tower            437857.236411  \n",
       "power_pole              35832.221593  \n",
       "line                     2095.531033  \n",
       "minor_line                955.562151  \n",
       "cable                    9639.442752  \n",
       "plant_point          639991315.02894  \n",
       "substation_point     63999131.502894  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_curves_maxdam(vul_curve_path,'fl')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9896d9f-4592-4552-8876-c1340f3e09f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_storm_data(climate_model,basin,bbox,ne_crs):\n",
    "    \n",
    "    with xr.open_dataset(os.path.join(tc_path,'STORM_FIXED_RETURN_PERIODS{}_{}.nc'.format(climate_model,basin))) as ds:\n",
    "        \n",
    "        ds.rio.write_crs(4326, inplace=True)\n",
    "        ds = ds.rio.clip_box(minx=bbox[0],miny=bbox[1],maxx=bbox[2],maxy=bbox[3])\n",
    "        \n",
    "        # get the mean values\n",
    "        df_ds = ds['mean'].to_dataframe().unstack(level=2).reset_index()\n",
    "\n",
    "        # create geometry values and drop lat lon columns\n",
    "        df_ds['geometry'] = [pygeos.points(x) for x in list(zip(df_ds['lon'],df_ds['lat']))]\n",
    "        df_ds = df_ds.drop(['lat','lon'],axis=1,level=0)\n",
    "        \n",
    "        # interpolate wind speeds of 1, 2, and 5-yr return period\n",
    "        ## rename columns to return periods (must be integer for interpolating)\n",
    "        df_ds_geometry = pd.DataFrame()\n",
    "        df_ds_geometry['geometry'] = df_ds['geometry']\n",
    "        df_ds = df_ds.drop(['geometry'],axis=1,level=0)\n",
    "        df_ds = df_ds['mean']\n",
    "        df_ds.columns = [int(x) for x in ds['mean']['rp']]\n",
    "        df_ds[1] = np.nan\n",
    "        df_ds[2] = np.nan\n",
    "        df_ds[5] = np.nan\n",
    "        df_ds[25] = np.nan\n",
    "        df_ds[250] = np.nan\n",
    "        df_ds = df_ds.reindex(sorted(df_ds.columns), axis=1)\n",
    "        df_ds = df_ds.interpolate(method='linear',axis=1,limit_direction='both')\n",
    "        df_ds['geometry'] = df_ds_geometry['geometry']\n",
    "        #df_ds = df_ds[['1','2','5','10','25','50','100','250','500','1000','geometry']]\n",
    "        df_ds = df_ds[[1,2,5,10,25,50,100,250,500,1000,'geometry']]\n",
    "        \n",
    "        #rename columns to return periods\n",
    "        #return_periods = ['1_{}{}'.format(int(x),climate_model) for x in ds['rp']]\n",
    "        df_ds.columns = ['1_{}{}'.format(int(x),climate_model) for x in [1,2,5,10,25,50,100,250,500,1000]] +['geometry']     \n",
    "        df_ds['geometry'] = pygeos.buffer(df_ds.geometry,radius=0.1/2,cap_style='square').values\n",
    "        df_ds['geometry'] = reproject(df_ds)\n",
    "            \n",
    "        # drop all non values to reduce size\n",
    "        #df_ds = df_ds.loc[~df_ds['1_10000{}'.format(climate_model)].isna()].reset_index(drop=True)\n",
    "        df_ds = df_ds.fillna(0)\n",
    "        #df_ds = df_ds[['1','2','5','10','25','50','100','250','500','1000']]\n",
    "        #df_ds = df_ds[['1_{}{}'.format(int(x),climate_model) for x in list(df_ds.columns.get_level_values(0))[:-1]]+['geometry']]\n",
    "\n",
    "    return df_ds\n",
    "\n",
    "def open_storm_data(country_code):\n",
    "    climate_models = ['_CMCC-CM2-VHR4'] #'','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM'\n",
    "    df_ds = {}\n",
    "    \n",
    "    country_basin = {\n",
    "    \"BRN\": [\"WP\"],\n",
    "    \"KHM\": [\"WP\"],\n",
    "    \"CHN\": [\"WP\", \"NI\"],\n",
    "    \"IDN\": [\"SI\", \"SP\", \"NI\", \"WP\"],\n",
    "    \"JPN\": [\"WP\"],\n",
    "    \"LAO\": [\"WP\"],\n",
    "    \"MYS\": [\"WP\", \"NI\"],\n",
    "    \"MNG\": [\"WP\", \"NI\"],\n",
    "    \"MMR\": [\"NI\", \"WP\"],\n",
    "    \"PRK\": [\"WP\"],\n",
    "    \"PHL\": [\"WP\"],\n",
    "    \"SGP\": [\"WP\"],\n",
    "    \"KOR\": [\"WP\"],\n",
    "    \"TWN\": [\"WP\"],\n",
    "    \"THA\": [\"WP\", \"NI\"],\n",
    "    \"VNM\": [\"WP\"] }\n",
    "    \n",
    "    # load country geometry file and create geometry to clip\n",
    "    ne_countries = gpd.read_file('C:\\\\Data\\\\natural_earth\\\\ne_10m_admin_0_countries.shp') \n",
    "    ne_crs = ne_countries.crs\n",
    "    bbox = ne_countries.loc[ne_countries['ISO_A3']==country_code].geometry.buffer(1).values[0].bounds\n",
    "\n",
    "    for climate_model in climate_models:\n",
    "        concat_prep = []\n",
    "        #combine STORM data from different basins\n",
    "        if \"WP\" in country_basin[country_code]:\n",
    "            WP = load_storm_data(climate_model,'WP',bbox,ne_crs)\n",
    "            concat_prep.append(WP)\n",
    "        if \"SP\" in country_basin[country_code]:\n",
    "            SP = load_storm_data(climate_model,'SP',bbox,ne_crs)\n",
    "            concat_prep.append(SP)\n",
    "        if \"NI\" in country_basin[country_code]:            \n",
    "            NI = load_storm_data(climate_model,'NI',bbox,ne_crs)\n",
    "            concat_prep.append(NI)            \n",
    "        if \"SI\" in country_basin[country_code]:       \n",
    "            SI = load_storm_data(climate_model,'SI',bbox,ne_crs)\n",
    "            concat_prep.append(SI)            \n",
    "                   \n",
    "        df_ds_cl = pd.concat(concat_prep,keys=country_basin[country_code])#,sp,ni,si,'sp','ni','si'])\n",
    "\n",
    "        df_ds_cl = df_ds_cl.reset_index(drop=True)\n",
    "        \n",
    "        df_ds[climate_model] = df_ds_cl\n",
    "    \n",
    "    return df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b43b71-49ee-4aee-aca7-db18ecbd8b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "twn_wind=open_storm_data('TWN')\n",
    "print(type(twn_wind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7059f5f8-fff4-4827-a187-bebcf957230d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.89 s\n",
      "Wall time: 2.88 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_2</th>\n",
       "      <th>1_5</th>\n",
       "      <th>1_10</th>\n",
       "      <th>1_25</th>\n",
       "      <th>1_50</th>\n",
       "      <th>1_100</th>\n",
       "      <th>1_250</th>\n",
       "      <th>1_500</th>\n",
       "      <th>1_1000</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.484970</td>\n",
       "      <td>31.484970</td>\n",
       "      <td>31.484970</td>\n",
       "      <td>31.484970</td>\n",
       "      <td>34.882271</td>\n",
       "      <td>37.150791</td>\n",
       "      <td>38.786932</td>\n",
       "      <td>41.029938</td>\n",
       "      <td>42.933264</td>\n",
       "      <td>43.897242</td>\n",
       "      <td>POLYGON ((13057776.27 2391878.588, 13057776.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.561684</td>\n",
       "      <td>31.561684</td>\n",
       "      <td>31.561684</td>\n",
       "      <td>31.561684</td>\n",
       "      <td>34.941517</td>\n",
       "      <td>37.417290</td>\n",
       "      <td>38.952814</td>\n",
       "      <td>40.987155</td>\n",
       "      <td>42.433489</td>\n",
       "      <td>43.846372</td>\n",
       "      <td>POLYGON ((13068908.219 2391878.588, 13068908.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.559660</td>\n",
       "      <td>31.559660</td>\n",
       "      <td>31.559660</td>\n",
       "      <td>31.559660</td>\n",
       "      <td>34.989208</td>\n",
       "      <td>37.441990</td>\n",
       "      <td>39.295692</td>\n",
       "      <td>41.087890</td>\n",
       "      <td>42.636647</td>\n",
       "      <td>43.937314</td>\n",
       "      <td>POLYGON ((13080040.168 2391878.588, 13080040.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.649051</td>\n",
       "      <td>31.649051</td>\n",
       "      <td>31.649051</td>\n",
       "      <td>31.649051</td>\n",
       "      <td>35.093386</td>\n",
       "      <td>37.464786</td>\n",
       "      <td>39.427878</td>\n",
       "      <td>41.296611</td>\n",
       "      <td>42.939086</td>\n",
       "      <td>44.289626</td>\n",
       "      <td>POLYGON ((13091172.117 2391878.588, 13091172.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.749391</td>\n",
       "      <td>31.749391</td>\n",
       "      <td>31.749391</td>\n",
       "      <td>31.749391</td>\n",
       "      <td>35.266336</td>\n",
       "      <td>37.634156</td>\n",
       "      <td>39.579647</td>\n",
       "      <td>41.514516</td>\n",
       "      <td>42.741313</td>\n",
       "      <td>44.298240</td>\n",
       "      <td>POLYGON ((13102304.066 2391878.588, 13102304.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>35.069860</td>\n",
       "      <td>35.069860</td>\n",
       "      <td>35.069860</td>\n",
       "      <td>35.069860</td>\n",
       "      <td>39.243768</td>\n",
       "      <td>42.045388</td>\n",
       "      <td>44.128518</td>\n",
       "      <td>46.371252</td>\n",
       "      <td>48.097373</td>\n",
       "      <td>49.527067</td>\n",
       "      <td>POLYGON ((13658901.52 3036284.923, 13658901.52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>35.159120</td>\n",
       "      <td>35.159120</td>\n",
       "      <td>35.159120</td>\n",
       "      <td>35.159120</td>\n",
       "      <td>39.261418</td>\n",
       "      <td>41.821312</td>\n",
       "      <td>44.056902</td>\n",
       "      <td>46.617187</td>\n",
       "      <td>48.180678</td>\n",
       "      <td>49.415934</td>\n",
       "      <td>POLYGON ((13670033.469 3036284.923, 13670033.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>35.238116</td>\n",
       "      <td>35.238116</td>\n",
       "      <td>35.238116</td>\n",
       "      <td>35.238116</td>\n",
       "      <td>39.250911</td>\n",
       "      <td>41.894078</td>\n",
       "      <td>44.101615</td>\n",
       "      <td>46.562302</td>\n",
       "      <td>47.930412</td>\n",
       "      <td>48.967779</td>\n",
       "      <td>POLYGON ((13681165.418 3036284.923, 13681165.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>35.309186</td>\n",
       "      <td>35.309186</td>\n",
       "      <td>35.309186</td>\n",
       "      <td>35.309186</td>\n",
       "      <td>39.248515</td>\n",
       "      <td>41.935010</td>\n",
       "      <td>44.177309</td>\n",
       "      <td>46.750433</td>\n",
       "      <td>47.926717</td>\n",
       "      <td>48.968906</td>\n",
       "      <td>POLYGON ((13692297.368 3036284.923, 13692297.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>35.334279</td>\n",
       "      <td>35.334279</td>\n",
       "      <td>35.334279</td>\n",
       "      <td>35.334279</td>\n",
       "      <td>39.291144</td>\n",
       "      <td>41.815739</td>\n",
       "      <td>44.186469</td>\n",
       "      <td>46.671538</td>\n",
       "      <td>47.922262</td>\n",
       "      <td>49.403801</td>\n",
       "      <td>POLYGON ((13703429.317 3036284.923, 13703429.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3186 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1_1        1_2        1_5       1_10       1_25       1_50  \\\n",
       "0     31.484970  31.484970  31.484970  31.484970  34.882271  37.150791   \n",
       "1     31.561684  31.561684  31.561684  31.561684  34.941517  37.417290   \n",
       "2     31.559660  31.559660  31.559660  31.559660  34.989208  37.441990   \n",
       "3     31.649051  31.649051  31.649051  31.649051  35.093386  37.464786   \n",
       "4     31.749391  31.749391  31.749391  31.749391  35.266336  37.634156   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "3181  35.069860  35.069860  35.069860  35.069860  39.243768  42.045388   \n",
       "3182  35.159120  35.159120  35.159120  35.159120  39.261418  41.821312   \n",
       "3183  35.238116  35.238116  35.238116  35.238116  39.250911  41.894078   \n",
       "3184  35.309186  35.309186  35.309186  35.309186  39.248515  41.935010   \n",
       "3185  35.334279  35.334279  35.334279  35.334279  39.291144  41.815739   \n",
       "\n",
       "          1_100      1_250      1_500     1_1000  \\\n",
       "0     38.786932  41.029938  42.933264  43.897242   \n",
       "1     38.952814  40.987155  42.433489  43.846372   \n",
       "2     39.295692  41.087890  42.636647  43.937314   \n",
       "3     39.427878  41.296611  42.939086  44.289626   \n",
       "4     39.579647  41.514516  42.741313  44.298240   \n",
       "...         ...        ...        ...        ...   \n",
       "3181  44.128518  46.371252  48.097373  49.527067   \n",
       "3182  44.056902  46.617187  48.180678  49.415934   \n",
       "3183  44.101615  46.562302  47.930412  48.967779   \n",
       "3184  44.177309  46.750433  47.926717  48.968906   \n",
       "3185  44.186469  46.671538  47.922262  49.403801   \n",
       "\n",
       "                                               geometry  \n",
       "0     POLYGON ((13057776.27 2391878.588, 13057776.27...  \n",
       "1     POLYGON ((13068908.219 2391878.588, 13068908.2...  \n",
       "2     POLYGON ((13080040.168 2391878.588, 13080040.1...  \n",
       "3     POLYGON ((13091172.117 2391878.588, 13091172.1...  \n",
       "4     POLYGON ((13102304.066 2391878.588, 13102304.0...  \n",
       "...                                                 ...  \n",
       "3181  POLYGON ((13658901.52 3036284.923, 13658901.52...  \n",
       "3182  POLYGON ((13670033.469 3036284.923, 13670033.4...  \n",
       "3183  POLYGON ((13681165.418 3036284.923, 13681165.4...  \n",
       "3184  POLYGON ((13692297.368 3036284.923, 13692297.3...  \n",
       "3185  POLYGON ((13703429.317 3036284.923, 13703429.3...  \n",
       "\n",
       "[3186 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "open_storm_data('TWN')['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c7ff6dd-a3f2-4e2a-becd-e5cffa38edde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clip_flood_data(country_code):\n",
    "\n",
    "    # load country geometry file and create geometry to clip\n",
    "    ne_countries = gpd.read_file('C:\\\\Data\\\\natural_earth\\\\ne_10m_admin_0_countries.shp') \n",
    "    geometry = ne_countries.loc[ne_countries['ISO_A3']==country_code].geometry.values[0]\n",
    "    geoms = [mapping(geometry)]\n",
    "    \n",
    "    #climate_model: historical, rcp4p5, rcp8p5; time_period: hist, 2030, 2050, 2080\n",
    "    rps = ['0001','0002','0005','0010','0025','0050','0100','0250','0500','1000']\n",
    "    climate_models = ['historical','rcp8p5']\n",
    "    \n",
    "    \n",
    "    for rp in rps:\n",
    "        #global input_file\n",
    "        for climate_model in climate_models:\n",
    "            if climate_model=='historical':\n",
    "                #f rps=='0001':\n",
    "                    input_file = os.path.join(fl_path,'global',\n",
    "                                              'inuncoast_{}_nosub_hist_rp{}_0.tif'.format(climate_model,rp)) \n",
    "                #elif rps==['0002','0005','0010','0025','0050','0100','0250','0500','1000']:\n",
    "                #    input_file = os.path.join(fl_path,'global',\n",
    "                #                              'inuncoast_{}_nosub_hist_rp{}_0.tif'.format(climate_model,rp)) \n",
    "            elif climate_model=='rcp8p5':\n",
    "                #f rps=='0001':\n",
    "                    input_file = os.path.join(fl_path,'global',\n",
    "                                              'inuncoast_{}_nosub_2030_rp{}_0.tif'.format(climate_model,rp))\n",
    "                #elif rps==['0002','0005','0010','0025','0050','0100','0250','0500','1000']:\n",
    "                #    input_file = os.path.join(fl_path,'global',\n",
    "                #                              'inuncoast_{}_nosub_2030_rp{}_0.tif'.format(climate_model,rp))\n",
    "            \n",
    "            # load raster file and save clipped version\n",
    "            with rasterio.open(input_file) as src:\n",
    "                out_image, out_transform = mask(src, geoms, crop=True)\n",
    "                out_meta = src.meta\n",
    "\n",
    "                out_meta.update({\"driver\": \"GTiff\",\n",
    "                         \"height\": out_image.shape[1],\n",
    "                         \"width\": out_image.shape[2],\n",
    "                         \"transform\": out_transform})\n",
    "\n",
    "                file_path = os.path.join(fl_path,'country','_'.join([country_code]+input_file.split('_')[3:]))\n",
    "\n",
    "                with rasterio.open(file_path, \"w\", **out_meta) as dest:\n",
    "                    dest.write(out_image)\n",
    "\n",
    "def load_flood_data(country_code,climate_model):\n",
    "    files = [x for x in os.listdir(os.path.join(fl_path,'country'))  if country_code in x ]\n",
    "    \n",
    "    rps = ['0001','0002','0005','0010','0025','0050','0100','0250','0500','1000']\n",
    "    collect_df_ds = []\n",
    "    \n",
    "    if climate_model=='historical':\n",
    "        print('Loading historical coastal flood data ...')\n",
    "        for rp in rps:\n",
    "            #for file in files:\n",
    "            file_path = os.path.join(fl_path,'country','{}_{}_nosub_hist_rp{}_0.tif'.format(country_code,climate_model,rp))\n",
    "            with xr.open_dataset(file_path) as ds: #, engine=\"rasterio\"\n",
    "                df_ds = ds.to_dataframe().reset_index()\n",
    "                df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "                df_ds = df_ds.rename(columns={'band_data': 'rp'+rp}) #rename to return period\n",
    "                \n",
    "                # move from meters to centimeters\n",
    "                df_ds['rp'+rp] = (df_ds['rp'+rp]*100)         \n",
    "                df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "                df_ds = df_ds.dropna()\n",
    "                df_ds = df_ds.reset_index(drop=True)\n",
    "                df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=0.00833/2,cap_style='square').values  #?????????????????????????\n",
    "                df_ds['geometry'] = reproject(df_ds)\n",
    "                collect_df_ds.append(df_ds)\n",
    "\n",
    "        df_all = collect_df_ds[0].merge(collect_df_ds[1]).merge(collect_df_ds[2]).merge(collect_df_ds[3]).merge(collect_df_ds[4])\\\n",
    "                 .merge(collect_df_ds[5]).merge(collect_df_ds[6]).merge(collect_df_ds[7]).merge(collect_df_ds[8]).merge(collect_df_ds[9])\n",
    "        df_all = df_all.loc[df_all['rp1000']>0].reset_index(drop=True)\n",
    "\n",
    "    elif climate_model=='rcp8p5':\n",
    "        print('Loading future coastal flood data ...')\n",
    "        for rp in rps:\n",
    "            #for file in files:\n",
    "            file_path = os.path.join(fl_path,'country','{}_{}_nosub_2030_rp{}_0.tif'.format(country_code,climate_model,rp))\n",
    "            with xr.open_dataset(file_path) as ds: #, engine=\"rasterio\"\n",
    "                df_ds = ds.to_dataframe().reset_index()\n",
    "                df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "                df_ds = df_ds.rename(columns={'band_data': 'rp'+rp}) #rename to return period\n",
    "                df_ds['rp'+rp] = (df_ds['rp'+rp]*100)\n",
    "                df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "                df_ds = df_ds.dropna()\n",
    "                df_ds = df_ds.reset_index(drop=True)\n",
    "                df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=0.00833/2,cap_style='square').values\n",
    "                df_ds['geometry'] = reproject(df_ds)\n",
    "                collect_df_ds.append(df_ds)\n",
    "\n",
    "        df_all = collect_df_ds[0].merge(collect_df_ds[1]).merge(collect_df_ds[2]).merge(collect_df_ds[3]).merge(collect_df_ds[4])\\\n",
    "                 .merge(collect_df_ds[5]).merge(collect_df_ds[6]).merge(collect_df_ds[7]).merge(collect_df_ds[8]).merge(collect_df_ds[9])\n",
    "\n",
    "        df_all = df_all.loc[df_all['rp1000']>0].reset_index(drop=True)\n",
    "    return df_all\n",
    "\n",
    "def open_flood_data(country_code):\n",
    "    climate_models = ['historical','rcp8p5']\n",
    "    df_ds = {}\n",
    "    for climate_model in climate_models:\n",
    "        #hist = load_flood_data(country_code,'historical')\n",
    "        #rcp8p5 = load_flood_data(country_code,'rcp8p5')\n",
    "        #df_ds_sc = pd.concat([hist,rcp8p5],keys=['historical','rcp8p5'])\n",
    "        df_ds_sc = load_flood_data(country_code,climate_model)\n",
    "\n",
    "        df_ds[climate_model] = df_ds_sc\n",
    "    \n",
    "    return df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ebbb408-29e0-4128-ad1b-2a7eae99b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_flood_data('KHM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5ac9f48-e434-4893-8c04-07e663921d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n",
      "CPU times: total: 30.8 s\n",
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "twn_flood = open_flood_data('TWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4cb2960-1dbe-4c3e-b9c9-4a65773bddd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(twn_flood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6e24a4d-35cc-4bdd-8d69-4d2c504fe1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rp0001</th>\n",
       "      <th>geometry</th>\n",
       "      <th>rp0002</th>\n",
       "      <th>rp0005</th>\n",
       "      <th>rp0010</th>\n",
       "      <th>rp0025</th>\n",
       "      <th>rp0050</th>\n",
       "      <th>rp0100</th>\n",
       "      <th>rp0250</th>\n",
       "      <th>rp0500</th>\n",
       "      <th>rp1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176.420731</td>\n",
       "      <td>POLYGON ((13168167.913 2811396.474, 13168167.9...</td>\n",
       "      <td>190.869278</td>\n",
       "      <td>226.426697</td>\n",
       "      <td>249.968765</td>\n",
       "      <td>279.714294</td>\n",
       "      <td>301.781189</td>\n",
       "      <td>323.685181</td>\n",
       "      <td>352.525330</td>\n",
       "      <td>374.301910</td>\n",
       "      <td>396.062744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190.201111</td>\n",
       "      <td>POLYGON ((13169095.575 2810377.258, 13169095.5...</td>\n",
       "      <td>204.649658</td>\n",
       "      <td>240.207077</td>\n",
       "      <td>263.749146</td>\n",
       "      <td>293.494690</td>\n",
       "      <td>315.561554</td>\n",
       "      <td>337.465546</td>\n",
       "      <td>366.305695</td>\n",
       "      <td>388.082275</td>\n",
       "      <td>409.843170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>POLYGON ((13170023.238 2811396.474, 13170023.2...</td>\n",
       "      <td>10.197401</td>\n",
       "      <td>45.754814</td>\n",
       "      <td>69.296883</td>\n",
       "      <td>99.042419</td>\n",
       "      <td>121.109299</td>\n",
       "      <td>143.013290</td>\n",
       "      <td>171.853455</td>\n",
       "      <td>193.630035</td>\n",
       "      <td>215.390869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>POLYGON ((13170023.238 2810377.258, 13170023.2...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.110926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>POLYGON ((13170950.9 2811396.474, 13170950.9 2...</td>\n",
       "      <td>98.447418</td>\n",
       "      <td>134.004837</td>\n",
       "      <td>157.546906</td>\n",
       "      <td>187.292435</td>\n",
       "      <td>209.359314</td>\n",
       "      <td>231.263306</td>\n",
       "      <td>260.103455</td>\n",
       "      <td>281.880035</td>\n",
       "      <td>303.640900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>127.308418</td>\n",
       "      <td>POLYGON ((13525317.946 2521533.141, 13525317.9...</td>\n",
       "      <td>129.873520</td>\n",
       "      <td>136.186218</td>\n",
       "      <td>140.365738</td>\n",
       "      <td>145.646622</td>\n",
       "      <td>149.564270</td>\n",
       "      <td>153.452972</td>\n",
       "      <td>158.573105</td>\n",
       "      <td>162.439209</td>\n",
       "      <td>166.302521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>9.339666</td>\n",
       "      <td>POLYGON ((13526245.608 2519531.048, 13526245.6...</td>\n",
       "      <td>11.904764</td>\n",
       "      <td>18.217468</td>\n",
       "      <td>22.396994</td>\n",
       "      <td>27.677870</td>\n",
       "      <td>31.595516</td>\n",
       "      <td>35.484219</td>\n",
       "      <td>40.604355</td>\n",
       "      <td>44.470451</td>\n",
       "      <td>48.333763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>POLYGON ((13559641.456 2840983.226, 13559641.4...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.591582</td>\n",
       "      <td>11.742449</td>\n",
       "      <td>16.855263</td>\n",
       "      <td>23.587109</td>\n",
       "      <td>28.670193</td>\n",
       "      <td>33.749603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>POLYGON ((13560569.118 2840983.226, 13560569.1...</td>\n",
       "      <td>17.736244</td>\n",
       "      <td>26.036049</td>\n",
       "      <td>31.531216</td>\n",
       "      <td>38.474392</td>\n",
       "      <td>43.625259</td>\n",
       "      <td>48.738075</td>\n",
       "      <td>55.469917</td>\n",
       "      <td>60.553001</td>\n",
       "      <td>65.632416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>POLYGON ((13560569.118 2839962.04, 13560569.11...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.818989</td>\n",
       "      <td>8.902073</td>\n",
       "      <td>13.981485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1003 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          rp0001                                           geometry  \\\n",
       "0     176.420731  POLYGON ((13168167.913 2811396.474, 13168167.9...   \n",
       "1     190.201111  POLYGON ((13169095.575 2810377.258, 13169095.5...   \n",
       "2       0.000000  POLYGON ((13170023.238 2811396.474, 13170023.2...   \n",
       "3       0.000000  POLYGON ((13170023.238 2810377.258, 13170023.2...   \n",
       "4       0.000000  POLYGON ((13170950.9 2811396.474, 13170950.9 2...   \n",
       "...          ...                                                ...   \n",
       "998   127.308418  POLYGON ((13525317.946 2521533.141, 13525317.9...   \n",
       "999     9.339666  POLYGON ((13526245.608 2519531.048, 13526245.6...   \n",
       "1000    0.000000  POLYGON ((13559641.456 2840983.226, 13559641.4...   \n",
       "1001    0.000000  POLYGON ((13560569.118 2840983.226, 13560569.1...   \n",
       "1002    0.000000  POLYGON ((13560569.118 2839962.04, 13560569.11...   \n",
       "\n",
       "          rp0002      rp0005      rp0010      rp0025      rp0050      rp0100  \\\n",
       "0     190.869278  226.426697  249.968765  279.714294  301.781189  323.685181   \n",
       "1     204.649658  240.207077  263.749146  293.494690  315.561554  337.465546   \n",
       "2      10.197401   45.754814   69.296883   99.042419  121.109299  143.013290   \n",
       "3       0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4      98.447418  134.004837  157.546906  187.292435  209.359314  231.263306   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "998   129.873520  136.186218  140.365738  145.646622  149.564270  153.452972   \n",
       "999    11.904764   18.217468   22.396994   27.677870   31.595516   35.484219   \n",
       "1000    0.000000    0.000000    0.000000    6.591582   11.742449   16.855263   \n",
       "1001   17.736244   26.036049   31.531216   38.474392   43.625259   48.738075   \n",
       "1002    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "          rp0250      rp0500      rp1000  \n",
       "0     352.525330  374.301910  396.062744  \n",
       "1     366.305695  388.082275  409.843170  \n",
       "2     171.853455  193.630035  215.390869  \n",
       "3       0.000000    0.000000   11.110926  \n",
       "4     260.103455  281.880035  303.640900  \n",
       "...          ...         ...         ...  \n",
       "998   158.573105  162.439209  166.302521  \n",
       "999    40.604355   44.470451   48.333763  \n",
       "1000   23.587109   28.670193   33.749603  \n",
       "1001   55.469917   60.553001   65.632416  \n",
       "1002    3.818989    8.902073   13.981485  \n",
       "\n",
       "[1003 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twn_flood['historical']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3de688-606c-4dd2-abe3-f37015c7442e",
   "metadata": {},
   "source": [
    "# OSM data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "934161b6-5f01-4315-87b3-9e4a7bd70876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_osm_infrastructure(country_code,osm_data_path):\n",
    "\n",
    "    # lines\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    osm_lines = power_polyline(osm_path)\n",
    "    osm_lines['geometry'] = reproject(osm_lines)\n",
    "    osm_lines = buffer_assets(osm_lines.loc[osm_lines.asset.isin(\n",
    "        ['cable','minor_cable','line','minor_line'])],buffer_size=100).reset_index(drop=True)\n",
    "    \n",
    "    # polygons\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    osm_poly = electricity(osm_path)\n",
    "    osm_poly['geometry'] = reproject(osm_poly)\n",
    "    \n",
    "    # points\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    osm_points = power_point(osm_path)\n",
    "    osm_points['geometry'] = reproject(osm_points)\n",
    "    osm_points = buffer_assets(osm_points.loc[osm_points.asset.isin(\n",
    "        ['power_tower','power_pole'])],buffer_size=100).reset_index(drop=True)\n",
    "    #print(osm_points)\n",
    "    #print(type(osm_points))\n",
    "\n",
    "    return osm_lines,osm_poly,osm_points\n",
    "\n",
    "\n",
    "#print(type(osm_power_infra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b16fbb7a-d740-4b39-bfdd-127321fb4cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|████████████████████████████████████████████████████████████████████| 2470/2470 [00:08<00:00, 286.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|███████████████████████████████████████████████████████████████████████| 368/368 [00:19<00:00, 18.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|█████████████████████████████████████████████████████████████| 1608621/1608621 [03:02<00:00, 8836.35it/s]\n"
     ]
    }
   ],
   "source": [
    "osm_power_infra = extract_osm_infrastructure('TWN',osm_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9dc748e9-7357-4296-ab28-711503d43cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(osm_power_infra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "abb7a943-1950-445c-8328-f6db95b7f163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assess_damage_osm(country_code,osm_power_infra,hazard_type):\n",
    "    \n",
    "    # set paths\n",
    "    # data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path = set_paths()\n",
    "\n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(vul_curve_path,hazard_type)\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    osm_lines,osm_poly,osm_points = osm_power_infra\n",
    "\n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = ['_CMCC-CM2-VHR4']#'','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM'\n",
    "        df_ds = open_storm_data(country_code)\n",
    "        \n",
    "        # remove assets that will not have any damage\n",
    "        osm_lines = osm_lines.loc[osm_lines.asset != 'cable'].reset_index(drop=True)\n",
    "        osm_poly = osm_poly.loc[osm_poly.asset != 'plant'].reset_index(drop=True)\n",
    "\n",
    "    elif hazard_type=='fl':\n",
    "        # read flood data\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "        df_ds = open_flood_data(country_code) \n",
    "        \n",
    "    #calculate damaged lines/polygons/points in loop by climate_model\n",
    "    damaged_lines = {}\n",
    "    damaged_poly = {}\n",
    "    damaged_points = {}\n",
    "    \n",
    "    for climate_model in climate_models:\n",
    "        \n",
    "        if hazard_type == 'tc':\n",
    "            return_periods = ['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),'1_10{}'.format(climate_model),\n",
    "                              '1_25{}'.format(climate_model),'1_50{}'.format(climate_model),'1_100{}'.format(climate_model),\n",
    "                              '1_250{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "        elif hazard_type == 'fl':\n",
    "            return_periods = ['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000']  \n",
    "\n",
    "        # assess damage for lines\n",
    "        overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_lines).T,\n",
    "                                     columns=['asset','hazard_point'])\n",
    "        \n",
    "        \n",
    "        collect_line_damages = []\n",
    "        for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                          desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "            for return_period in return_periods:\n",
    "                collect_line_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                       df_ds[climate_model],\n",
    "                                                                       osm_lines,\n",
    "                                                                       curves,\n",
    "                                                                       maxdam,\n",
    "                                                                       return_period,\n",
    "                                                                       country_code))\n",
    "\n",
    "        get_asset_type_line = dict(zip(osm_lines.index,osm_lines.asset))\n",
    "        \n",
    "        if hazard_type == 'fl':\n",
    "            results = pd.DataFrame(collect_line_damages,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "        elif hazard_type == 'tc':\n",
    "            results = pd.DataFrame([item for sublist in collect_line_damages \n",
    "                                    for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "        \n",
    "        results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "        damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "            \n",
    "        # assess damage for polygons\n",
    "        if len(osm_poly) > 0:\n",
    "            overlay_poly = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_poly).T,\n",
    "                                    columns=['asset','hazard_point'])\n",
    "        else:\n",
    "            overlay_poly = pd.DataFrame()\n",
    "            \n",
    "        if len(overlay_poly) == 0:\n",
    "            damaged_poly[climate_model] = pd.DataFrame()\n",
    "        \n",
    "        else:\n",
    "            collect_poly_damages = []\n",
    "            for asset in tqdm(overlay_poly.groupby('asset'),total=len(overlay_poly.asset.unique()),\n",
    "                              desc='polygon damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_poly_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                           df_ds[climate_model],\n",
    "                                                                           osm_poly,\n",
    "                                                                           curves,\n",
    "                                                                           maxdam,\n",
    "                                                                           return_period,\n",
    "                                                                           country_code))\n",
    "\n",
    "            get_asset_type_poly = dict(zip(osm_poly.index,osm_poly.asset))\n",
    "\n",
    "            if hazard_type == 'fl':\n",
    "                results = pd.DataFrame(collect_poly_damages ,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "            elif hazard_type == 'tc':\n",
    "                results = pd.DataFrame([item for sublist in collect_poly_damages \n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "            \n",
    "            results['asset_type'] = results.asset.apply(lambda x : get_asset_type_poly[x])    \n",
    "\n",
    "            damaged_poly[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "        # assess damage for points\n",
    "        overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],osm_points).T,\n",
    "                                      columns=['asset','hazard_point'])\n",
    "        collect_point_damages = []\n",
    "        for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                          desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "            for return_period in return_periods:\n",
    "                collect_point_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                        df_ds[climate_model],\n",
    "                                                                        osm_points,\n",
    "                                                                        curves,\n",
    "                                                                        maxdam,\n",
    "                                                                        return_period,\n",
    "                                                                        country_code))\n",
    "\n",
    "        get_asset_type_point = dict(zip(osm_points.index,osm_points.asset))\n",
    "\n",
    "        if hazard_type == 'fl':\n",
    "            results = pd.DataFrame(collect_point_damages ,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "        elif hazard_type == 'tc':\n",
    "            results = pd.DataFrame([item for sublist in collect_point_damages \n",
    "                                    for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "  \n",
    "        results['asset_type'] = results.asset.apply(lambda x : get_asset_type_point[x])    \n",
    "    \n",
    "        damaged_points[climate_model] = results.groupby(['rp','curve','asset_type']).sum().drop(['asset'], axis=1).reset_index()\n",
    "\n",
    "    return damaged_lines,damaged_poly,damaged_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ac71f06a-d796-456c-a7b5-4564ba01f806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for TWN fl (historical): 100%|█████████████████████████████| 58/58 [00:02<00:00, 24.44it/s]\n",
      "polygon damage calculation for TWN fl (historical): 100%|██████████████████████████████| 60/60 [00:03<00:00, 16.63it/s]\n",
      "point damage calculation for TWN fl (historical): 100%|██████████████████████████████| 325/325 [00:06<00:00, 46.80it/s]\n",
      "polyline damage calculation for TWN fl (rcp8p5): 100%|█████████████████████████████████| 69/69 [00:02<00:00, 24.76it/s]\n",
      "polygon damage calculation for TWN fl (rcp8p5): 100%|██████████████████████████████████| 61/61 [00:03<00:00, 16.68it/s]\n",
      "point damage calculation for TWN fl (rcp8p5): 100%|██████████████████████████████████| 392/392 [00:08<00:00, 45.93it/s]\n"
     ]
    }
   ],
   "source": [
    "osm_damage_infra = assess_damage_osm('TWN',osm_power_infra,'fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f2f2c812-e814-4791-a7c3-850f7a42e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.ExcelWriter(os.path.join(output_path,'output.xlsx')) as writer:  \n",
    "#    osm_damage_infra[0]['historical'].to_excel(writer, sheet_name='Sheet_name_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "313d91ab-0996-4aa6-8de6-49b0cb2bf424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rp</th>\n",
       "      <th>curve</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>meandam</th>\n",
       "      <th>lowerdam</th>\n",
       "      <th>upperdam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rp0001</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>1.658665e+09</td>\n",
       "      <td>4.523633e+08</td>\n",
       "      <td>2.261816e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rp0001</td>\n",
       "      <td>substation</td>\n",
       "      <td>substation</td>\n",
       "      <td>4.614857e+06</td>\n",
       "      <td>1.730571e+06</td>\n",
       "      <td>8.652857e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rp0002</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>1.730781e+09</td>\n",
       "      <td>4.720311e+08</td>\n",
       "      <td>2.360156e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rp0002</td>\n",
       "      <td>substation</td>\n",
       "      <td>substation</td>\n",
       "      <td>4.703594e+06</td>\n",
       "      <td>1.763848e+06</td>\n",
       "      <td>8.819239e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rp0005</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.388258e+09</td>\n",
       "      <td>6.513430e+08</td>\n",
       "      <td>3.256715e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rp0005</td>\n",
       "      <td>substation</td>\n",
       "      <td>substation</td>\n",
       "      <td>6.540315e+06</td>\n",
       "      <td>2.452618e+06</td>\n",
       "      <td>1.226309e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rp0010</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.552940e+09</td>\n",
       "      <td>6.962564e+08</td>\n",
       "      <td>3.481282e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rp0010</td>\n",
       "      <td>substation</td>\n",
       "      <td>substation</td>\n",
       "      <td>6.904518e+06</td>\n",
       "      <td>2.589194e+06</td>\n",
       "      <td>1.294597e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rp0025</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.767454e+09</td>\n",
       "      <td>7.547601e+08</td>\n",
       "      <td>3.773801e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rp0025</td>\n",
       "      <td>substation</td>\n",
       "      <td>substation</td>\n",
       "      <td>7.130537e+06</td>\n",
       "      <td>2.673951e+06</td>\n",
       "      <td>1.336976e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rp0050</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>2.921201e+09</td>\n",
       "      <td>7.966912e+08</td>\n",
       "      <td>3.983456e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rp0050</td>\n",
       "      <td>substation</td>\n",
       "      <td>substation</td>\n",
       "      <td>7.199425e+06</td>\n",
       "      <td>2.699784e+06</td>\n",
       "      <td>1.349892e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rp0100</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.080762e+09</td>\n",
       "      <td>8.402079e+08</td>\n",
       "      <td>4.201039e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rp0100</td>\n",
       "      <td>substation</td>\n",
       "      <td>substation</td>\n",
       "      <td>7.337966e+06</td>\n",
       "      <td>2.751737e+06</td>\n",
       "      <td>1.375869e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rp0250</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.356950e+09</td>\n",
       "      <td>9.155320e+08</td>\n",
       "      <td>4.577660e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rp0250</td>\n",
       "      <td>substation</td>\n",
       "      <td>substation</td>\n",
       "      <td>7.585611e+06</td>\n",
       "      <td>2.844604e+06</td>\n",
       "      <td>1.422302e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rp0500</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.528684e+09</td>\n",
       "      <td>9.623684e+08</td>\n",
       "      <td>4.811842e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rp0500</td>\n",
       "      <td>substation</td>\n",
       "      <td>substation</td>\n",
       "      <td>7.795779e+06</td>\n",
       "      <td>2.923417e+06</td>\n",
       "      <td>1.461708e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rp1000</td>\n",
       "      <td>plant</td>\n",
       "      <td>plant</td>\n",
       "      <td>3.698459e+09</td>\n",
       "      <td>1.008671e+09</td>\n",
       "      <td>5.043354e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rp1000</td>\n",
       "      <td>substation</td>\n",
       "      <td>substation</td>\n",
       "      <td>8.086173e+06</td>\n",
       "      <td>3.032315e+06</td>\n",
       "      <td>1.516157e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rp       curve  asset_type       meandam      lowerdam      upperdam\n",
       "0   rp0001       plant       plant  1.658665e+09  4.523633e+08  2.261816e+09\n",
       "1   rp0001  substation  substation  4.614857e+06  1.730571e+06  8.652857e+06\n",
       "2   rp0002       plant       plant  1.730781e+09  4.720311e+08  2.360156e+09\n",
       "3   rp0002  substation  substation  4.703594e+06  1.763848e+06  8.819239e+06\n",
       "4   rp0005       plant       plant  2.388258e+09  6.513430e+08  3.256715e+09\n",
       "5   rp0005  substation  substation  6.540315e+06  2.452618e+06  1.226309e+07\n",
       "6   rp0010       plant       plant  2.552940e+09  6.962564e+08  3.481282e+09\n",
       "7   rp0010  substation  substation  6.904518e+06  2.589194e+06  1.294597e+07\n",
       "8   rp0025       plant       plant  2.767454e+09  7.547601e+08  3.773801e+09\n",
       "9   rp0025  substation  substation  7.130537e+06  2.673951e+06  1.336976e+07\n",
       "10  rp0050       plant       plant  2.921201e+09  7.966912e+08  3.983456e+09\n",
       "11  rp0050  substation  substation  7.199425e+06  2.699784e+06  1.349892e+07\n",
       "12  rp0100       plant       plant  3.080762e+09  8.402079e+08  4.201039e+09\n",
       "13  rp0100  substation  substation  7.337966e+06  2.751737e+06  1.375869e+07\n",
       "14  rp0250       plant       plant  3.356950e+09  9.155320e+08  4.577660e+09\n",
       "15  rp0250  substation  substation  7.585611e+06  2.844604e+06  1.422302e+07\n",
       "16  rp0500       plant       plant  3.528684e+09  9.623684e+08  4.811842e+09\n",
       "17  rp0500  substation  substation  7.795779e+06  2.923417e+06  1.461708e+07\n",
       "18  rp1000       plant       plant  3.698459e+09  1.008671e+09  5.043354e+09\n",
       "19  rp1000  substation  substation  8.086173e+06  3.032315e+06  1.516157e+07"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract nested dict by key\n",
    "osm_damage_infra[1]['historical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5d5e4b99-fb9d-4e25-a456-757930e52242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(osm_damage_infra[0]['historical']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "457c186a-018f-4a87-b4e0-c0a7e2927aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_analysis_osm(country_code,hazard_type): #\n",
    "    \n",
    "    # extract infrastructure data from OSM\n",
    "    #osm_power_infra = extract_osm_infrastructure(country_code,osm_data_path)  #!!!!!!!!!!!!!!!!!!!!!!!!DELETE NOTES AFTER TEST\n",
    "    \n",
    "    # assess damage to hazard_type\n",
    "    osm_damage_infra = assess_damage_osm(country_code,osm_power_infra,hazard_type)\n",
    "    \n",
    "    if hazard_type=='tc':\n",
    "        climate_models = ['_CMCC-CM2-VHR4'] #'','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM'\n",
    "    elif hazard_type=='fl':\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "    #print(len(osm_damage_infra))\n",
    "        \n",
    "    for i in range(len(osm_damage_infra)):\n",
    "        for climate_model in climate_models:\n",
    "            with pd.ExcelWriter(os.path.join(output_path,'damage','{}_{}_osm_{}_damage_{}'.format(country_code,climate_model,hazard_type,i)+'.xlsx')) as writer:\n",
    "                osm_damage_infra[i][climate_model].to_excel(writer)\n",
    "\n",
    "    return osm_damage_infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b08ddf81-6571-4e42-bbdd-b6b6e948186a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for TWN fl (historical): 100%|█████████████████████████████| 58/58 [00:01<00:00, 29.46it/s]\n",
      "polygon damage calculation for TWN fl (historical): 100%|██████████████████████████████| 60/60 [00:03<00:00, 19.88it/s]\n",
      "point damage calculation for TWN fl (historical): 100%|██████████████████████████████| 325/325 [00:07<00:00, 44.62it/s]\n",
      "polyline damage calculation for TWN fl (rcp8p5): 100%|█████████████████████████████████| 69/69 [00:02<00:00, 27.83it/s]\n",
      "polygon damage calculation for TWN fl (rcp8p5): 100%|██████████████████████████████████| 61/61 [00:03<00:00, 18.41it/s]\n",
      "point damage calculation for TWN fl (rcp8p5): 100%|██████████████████████████████████| 392/392 [00:07<00:00, 52.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 56.6 s\n",
      "Wall time: 59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "osm_damage_infra = country_analysis_osm('TWN','fl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ba717-0015-4527-bf1a-a9556f87a541",
   "metadata": {},
   "source": [
    "# Government data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ef53a27c-f539-43db-9870-1ee933ddf7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load collected power grid data\n",
    "def extract_pg_data(country_code,pg_type):\n",
    "    files = [x for x in os.listdir(pg_data_path)  if country_code in x ]\n",
    "    \n",
    "    if pg_type=='line':\n",
    "        for file in files: \n",
    "            file_path = os.path.join(pg_data_path,'{}_{}.gpkg'.format(country_code,pg_type))\n",
    "\n",
    "            pg_data_country = gpd.read_file(file_path)\n",
    "            pg_data_country = pd.DataFrame(pg_data_country.copy())\n",
    "            #print(pg_data_country.head())\n",
    "            pg_data_country.geometry = pygeos.from_shapely(pg_data_country.geometry)\n",
    "            pg_data_country['geometry'] = reproject(pg_data_country)\n",
    "\n",
    "        pg_data_country = buffer_assets(pg_data_country.loc[pg_data_country.asset.isin(['line'])],buffer_size=100).reset_index(drop=True)\n",
    "\n",
    "    elif pg_type=='point':\n",
    "        for file in files:\n",
    "            file_path = os.path.join(pg_data_path,'{}_{}.gpkg'.format(country_code,pg_type))\n",
    "                \n",
    "            pg_data_country = gpd.read_file(file_path)\n",
    "            pg_data_country = pd.DataFrame(pg_data_country.copy())\n",
    "            #print(pg_data_country.head())\n",
    "            pg_data_country.geometry = pygeos.from_shapely(pg_data_country.geometry)\n",
    "            pg_data_country['geometry'] = reproject(pg_data_country)\n",
    "            #print(pg_data_country)\n",
    "\n",
    "        pg_data_country = buffer_assets(pg_data_country.loc[pg_data_country.asset.isin(['plant_point','substation_point','power_tower','power_pole'])],buffer_size=100).reset_index(drop=True)\n",
    "\n",
    "    return pg_data_country\n",
    "\n",
    "def open_pg_data(country_code):\n",
    "    pg_lines = extract_pg_data(country_code,'line')\n",
    "    #pg_points = extract_pg_data(country_code,'point')\n",
    "\n",
    "    return pg_lines#,pg_points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e6a7cdb0-f9a6-4d0c-9dd9-c9d88d7e98e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>capacity_kV</th>\n",
       "      <th>value</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>country</th>\n",
       "      <th>operator</th>\n",
       "      <th>undergrnd</th>\n",
       "      <th>phases</th>\n",
       "      <th>cables</th>\n",
       "      <th>year</th>\n",
       "      <th>asset</th>\n",
       "      <th>geometry</th>\n",
       "      <th>buffered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Existing</td>\n",
       "      <td>230</td>\n",
       "      <td>transmission_line</td>\n",
       "      <td>0.0</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>Laos</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11642041.532 2064458.971, 11641491...</td>\n",
       "      <td>POLYGON ((11641591.898 2002921.519, 11651201.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Existing</td>\n",
       "      <td>230</td>\n",
       "      <td>transmission_line</td>\n",
       "      <td>1.0</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>Laos</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11642041.532 2064458.971, 11637642...</td>\n",
       "      <td>POLYGON ((11637741.737 2064075.819, 11637193.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Existing</td>\n",
       "      <td>230</td>\n",
       "      <td>transmission_line</td>\n",
       "      <td>2.0</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>Laos</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11895120.2 1689115.931, 11894570.3...</td>\n",
       "      <td>POLYGON ((11894481.255 1691616.252, 11852218.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Existing</td>\n",
       "      <td>115</td>\n",
       "      <td>transmission_line</td>\n",
       "      <td>3.0</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>Laos</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11417899.886 2043628.146, 11431921...</td>\n",
       "      <td>POLYGON ((11431917.506 2044306.41, 11431935.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Existing</td>\n",
       "      <td>115</td>\n",
       "      <td>transmission_line</td>\n",
       "      <td>4.0</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>Laos</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11417899.886 2043628.146, 11432471...</td>\n",
       "      <td>POLYGON ((11432490.024 2040979.482, 11432509.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Existing</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11532976.034 2090761.016, 11536981...</td>\n",
       "      <td>POLYGON ((11537052.726 2086775.9, 11537065.71 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Existing</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11538373.443 2088607.412, 11537840...</td>\n",
       "      <td>POLYGON ((11537743.256 2090921.908, 11537740.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Existing</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11396008.1 2094168.895, 11397829.5...</td>\n",
       "      <td>POLYGON ((11397733.747 2100286.154, 11397740.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Existing</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11369167.465 2255664.932, 11361572...</td>\n",
       "      <td>POLYGON ((11361655.11 2244413.017, 11361642.56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Existing</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>line</td>\n",
       "      <td>LINESTRING (11369167.465 2255664.932, 11361366...</td>\n",
       "      <td>POLYGON ((11361424.554 2252493.232, 11359515.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       status  capacity_kV              value   id      source country  \\\n",
       "0    Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "1    Existing          230  transmission_line  1.0  World Bank    Laos   \n",
       "2    Existing          230  transmission_line  2.0  World Bank    Laos   \n",
       "3    Existing          115  transmission_line  3.0  World Bank    Laos   \n",
       "4    Existing          115  transmission_line  4.0  World Bank    Laos   \n",
       "..        ...          ...                ...  ...         ...     ...   \n",
       "422  Existing           22               None  NaN  World Bank    None   \n",
       "423  Existing           22               None  NaN  World Bank    None   \n",
       "424  Existing           22               None  NaN  World Bank    None   \n",
       "425  Existing           22               None  NaN  World Bank    None   \n",
       "426  Existing           22               None  NaN  World Bank    None   \n",
       "\n",
       "    operator undergrnd phases cables  year asset  \\\n",
       "0       None      None   None   None  None  line   \n",
       "1       None      None   None   None  None  line   \n",
       "2       None      None   None   None  None  line   \n",
       "3       None      None   None   None  None  line   \n",
       "4       None      None   None   None  None  line   \n",
       "..       ...       ...    ...    ...   ...   ...   \n",
       "422     None      None   None   None  None  line   \n",
       "423     None      None   None   None  None  line   \n",
       "424     None      None   None   None  None  line   \n",
       "425     None      None   None   None  None  line   \n",
       "426     None      None   None   None  None  line   \n",
       "\n",
       "                                              geometry  \\\n",
       "0    LINESTRING (11642041.532 2064458.971, 11641491...   \n",
       "1    LINESTRING (11642041.532 2064458.971, 11637642...   \n",
       "2    LINESTRING (11895120.2 1689115.931, 11894570.3...   \n",
       "3    LINESTRING (11417899.886 2043628.146, 11431921...   \n",
       "4    LINESTRING (11417899.886 2043628.146, 11432471...   \n",
       "..                                                 ...   \n",
       "422  LINESTRING (11532976.034 2090761.016, 11536981...   \n",
       "423  LINESTRING (11538373.443 2088607.412, 11537840...   \n",
       "424  LINESTRING (11396008.1 2094168.895, 11397829.5...   \n",
       "425  LINESTRING (11369167.465 2255664.932, 11361572...   \n",
       "426  LINESTRING (11369167.465 2255664.932, 11361366...   \n",
       "\n",
       "                                              buffered  \n",
       "0    POLYGON ((11641591.898 2002921.519, 11651201.1...  \n",
       "1    POLYGON ((11637741.737 2064075.819, 11637193.0...  \n",
       "2    POLYGON ((11894481.255 1691616.252, 11852218.4...  \n",
       "3    POLYGON ((11431917.506 2044306.41, 11431935.18...  \n",
       "4    POLYGON ((11432490.024 2040979.482, 11432509.1...  \n",
       "..                                                 ...  \n",
       "422  POLYGON ((11537052.726 2086775.9, 11537065.71 ...  \n",
       "423  POLYGON ((11537743.256 2090921.908, 11537740.7...  \n",
       "424  POLYGON ((11397733.747 2100286.154, 11397740.7...  \n",
       "425  POLYGON ((11361655.11 2244413.017, 11361642.56...  \n",
       "426  POLYGON ((11361424.554 2252493.232, 11359515.6...  \n",
       "\n",
       "[427 rows x 14 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_infra = open_pg_data('LAO')\n",
    "print(type(pg_infra))\n",
    "pg_infra[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "24824f71-092f-4509-97cf-4e292da71126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_damage_pg(country_code,pg_infra,hazard_type):\n",
    "    \n",
    "    # set paths\n",
    "    # data_path,tc_path,fl_path,pg_data_path,pg_data_path,vul_curve_path,output_path = set_paths()\n",
    "\n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(vul_curve_path,hazard_type)\n",
    "    #curves['line'] = 1 # remove this when things work!\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    pg_lines,pg_points = pg_infra\n",
    "    #pg_lines = pg_infra\n",
    "    \n",
    "    #pg_lines.head(5)\n",
    "    #pg_points.head(5)\n",
    "    \n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = ['_CMCC-CM2-VHR4'] #'','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM'\n",
    "        df_ds = open_storm_data(country_code)\n",
    "\n",
    "        # remove assets that will not have any damage\n",
    "        pg_lines = pg_lines.loc[pg_lines.asset != 'cable'].reset_index(drop=True)\n",
    "    \n",
    "    elif hazard_type=='fl':\n",
    "        # read flood data\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "        df_ds = open_flood_data(country_code) \n",
    "    \n",
    "    #calculate damaged lines/polygons/points in loop by climate_model\n",
    "    damaged_lines = {}\n",
    "    damaged_points = {}\n",
    "    \n",
    "    # calculate damaged lines/polygons/points in loop by climate_model\n",
    "    for climate_model in climate_models:\n",
    "        \n",
    "        if hazard_type == 'tc':\n",
    "            return_periods = ['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),'1_10{}'.format(climate_model),\n",
    "                              '1_25{}'.format(climate_model),'1_50{}'.format(climate_model),'1_100{}'.format(climate_model),\n",
    "                              '1_250{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "        elif hazard_type == 'fl':\n",
    "            return_periods = ['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000']  \n",
    "\n",
    "        # assess damage for lines\n",
    "        overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],pg_lines).T,\n",
    "                                     columns=['asset','hazard_point'])\n",
    "        \n",
    "        collect_line_damages = []\n",
    "        for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                          desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "            for return_period in return_periods:\n",
    "                collect_line_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                       df_ds[climate_model],\n",
    "                                                                       pg_lines,\n",
    "                                                                       curves,\n",
    "                                                                       maxdam,\n",
    "                                                                       return_period,\n",
    "                                                                       country_code))\n",
    "\n",
    "        get_asset_type_line = dict(zip(pg_lines.index,pg_lines.asset))\n",
    "        print(get_asset_type_line)\n",
    "\n",
    "        if hazard_type == 'fl':\n",
    "            results = pd.DataFrame(collect_line_damages,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "        elif hazard_type == 'tc':\n",
    "            results = pd.DataFrame([item for sublist in collect_line_damages \n",
    "                                    for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "            \n",
    "        results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "        damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().reset_index()\n",
    "        \n",
    "        # assess damage for points\n",
    "        overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],pg_points).T,\n",
    "                                      columns=['asset','hazard_point'])\n",
    "        collect_point_damages = []\n",
    "        for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                          desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "            for return_period in return_periods:\n",
    "                collect_point_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                        df_ds[climate_model],\n",
    "                                                                        pg_points,\n",
    "                                                                        curves,\n",
    "                                                                        maxdam,\n",
    "                                                                        return_period,\n",
    "                                                                        country_code))\n",
    "\n",
    "        get_asset_type_point = dict(zip(pg_points.index,pg_points.asset))\n",
    "\n",
    "        if hazard_type == 'fl':\n",
    "            results = pd.DataFrame(collect_point_damages ,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "        elif hazard_type == 'tc':\n",
    "            results = pd.DataFrame([item for sublist in collect_point_damages \n",
    "                                    for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "  \n",
    "        results['asset_type'] = results.asset.apply(lambda x : get_asset_type_point[x])    \n",
    "    \n",
    "        damaged_points[climate_model] = results.groupby(['rp','curve','asset_type']).sum().reset_index()\n",
    "        \n",
    "    return damaged_lines,damaged_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d5fb3-c1c9-4e1e-a73c-fea26042357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pg_infra = open_pg_data('TWN')\n",
    "pg_damage_infra = assess_damage_pg('TWN',pg_infra,'fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "64cfcf4a-3381-4a83-9f58-6b254ce75336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'_CMCC-CM2-VHR4':                       rp curve asset_type  asset       meandam      lowerdam  \\\n",
       "  0   1_1000_CMCC-CM2-VHR4  W5_1       line   6786  3.282313e+08  2.461735e+08   \n",
       "  1   1_1000_CMCC-CM2-VHR4  W5_2       line   6786  3.474282e+08  2.605711e+08   \n",
       "  2   1_1000_CMCC-CM2-VHR4  W5_3       line   6786  3.474282e+08  2.605711e+08   \n",
       "  3    1_100_CMCC-CM2-VHR4  W5_1       line   6786  3.282313e+08  2.461735e+08   \n",
       "  4    1_100_CMCC-CM2-VHR4  W5_2       line   6786  3.474282e+08  2.605711e+08   \n",
       "  5    1_100_CMCC-CM2-VHR4  W5_3       line   6786  3.474282e+08  2.605711e+08   \n",
       "  6     1_10_CMCC-CM2-VHR4  W5_1       line   6786  2.813719e+08  2.110289e+08   \n",
       "  7     1_10_CMCC-CM2-VHR4  W5_2       line   6786  3.181328e+08  2.385996e+08   \n",
       "  8     1_10_CMCC-CM2-VHR4  W5_3       line   6786  3.015049e+08  2.261287e+08   \n",
       "  9      1_1_CMCC-CM2-VHR4  W5_1       line   6786  2.813719e+08  2.110289e+08   \n",
       "  10     1_1_CMCC-CM2-VHR4  W5_2       line   6786  3.181328e+08  2.385996e+08   \n",
       "  11     1_1_CMCC-CM2-VHR4  W5_3       line   6786  3.015049e+08  2.261287e+08   \n",
       "  12   1_250_CMCC-CM2-VHR4  W5_1       line   6786  3.282313e+08  2.461735e+08   \n",
       "  13   1_250_CMCC-CM2-VHR4  W5_2       line   6786  3.474282e+08  2.605711e+08   \n",
       "  14   1_250_CMCC-CM2-VHR4  W5_3       line   6786  3.474282e+08  2.605711e+08   \n",
       "  15    1_25_CMCC-CM2-VHR4  W5_1       line   6786  3.282313e+08  2.461735e+08   \n",
       "  16    1_25_CMCC-CM2-VHR4  W5_2       line   6786  3.474282e+08  2.605711e+08   \n",
       "  17    1_25_CMCC-CM2-VHR4  W5_3       line   6786  3.474282e+08  2.605711e+08   \n",
       "  18     1_2_CMCC-CM2-VHR4  W5_1       line   6786  2.813719e+08  2.110289e+08   \n",
       "  19     1_2_CMCC-CM2-VHR4  W5_2       line   6786  3.181328e+08  2.385996e+08   \n",
       "  20     1_2_CMCC-CM2-VHR4  W5_3       line   6786  3.015049e+08  2.261287e+08   \n",
       "  21   1_500_CMCC-CM2-VHR4  W5_1       line   6786  3.282313e+08  2.461735e+08   \n",
       "  22   1_500_CMCC-CM2-VHR4  W5_2       line   6786  3.474282e+08  2.605711e+08   \n",
       "  23   1_500_CMCC-CM2-VHR4  W5_3       line   6786  3.474282e+08  2.605711e+08   \n",
       "  24    1_50_CMCC-CM2-VHR4  W5_1       line   6786  3.282313e+08  2.461735e+08   \n",
       "  25    1_50_CMCC-CM2-VHR4  W5_2       line   6786  3.474282e+08  2.605711e+08   \n",
       "  26    1_50_CMCC-CM2-VHR4  W5_3       line   6786  3.474282e+08  2.605711e+08   \n",
       "  27     1_5_CMCC-CM2-VHR4  W5_1       line   6786  2.813719e+08  2.110289e+08   \n",
       "  28     1_5_CMCC-CM2-VHR4  W5_2       line   6786  3.181328e+08  2.385996e+08   \n",
       "  29     1_5_CMCC-CM2-VHR4  W5_3       line   6786  3.015049e+08  2.261287e+08   \n",
       "  \n",
       "          upperdam  \n",
       "  0   4.102891e+08  \n",
       "  1   4.342852e+08  \n",
       "  2   4.342852e+08  \n",
       "  3   4.102891e+08  \n",
       "  4   4.342852e+08  \n",
       "  5   4.342852e+08  \n",
       "  6   3.517149e+08  \n",
       "  7   3.976660e+08  \n",
       "  8   3.768811e+08  \n",
       "  9   3.517149e+08  \n",
       "  10  3.976660e+08  \n",
       "  11  3.768811e+08  \n",
       "  12  4.102891e+08  \n",
       "  13  4.342852e+08  \n",
       "  14  4.342852e+08  \n",
       "  15  4.102891e+08  \n",
       "  16  4.342852e+08  \n",
       "  17  4.342852e+08  \n",
       "  18  3.517149e+08  \n",
       "  19  3.976660e+08  \n",
       "  20  3.768811e+08  \n",
       "  21  4.102891e+08  \n",
       "  22  4.342852e+08  \n",
       "  23  4.342852e+08  \n",
       "  24  4.102891e+08  \n",
       "  25  4.342852e+08  \n",
       "  26  4.342852e+08  \n",
       "  27  3.517149e+08  \n",
       "  28  3.976660e+08  \n",
       "  29  3.768811e+08  },\n",
       " {})"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_damage_infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "1fac49c0-8408-4d6a-b063-ef6180b6c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_analysis_pg(country_code,hazard_type): #\n",
    "    \n",
    "    # extract infrastructure data from pg data\n",
    "    pg_infra = open_pg_data(country_code)\n",
    "\n",
    "    # assess damage to wind storms\n",
    "    pg_damage_infra = assess_damage_pg(country_code,pg_infra,hazard_type)\n",
    "    \n",
    "    if hazard_type=='tc':\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "    elif hazard_type=='fl':\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "        \n",
    "    for i in range(len(pg_damage_infra)):\n",
    "        for climate_model in climate_models:\n",
    "            with pd.ExcelWriter(os.path.join(output_path,'damage','{}_{}_pg_{}_damage_{}'.format(country_code,climate_model,hazard_type,i)+'.xlsx')) as writer:\n",
    "                #pg_damage_infra[i][climate_model].drop(['asset'], axis=1).to_excel(writer)\n",
    "                pg_damage_infra[i][climate_model].to_excel(writer)\n",
    "\n",
    "    return pg_damage_infra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44657b7f-88dd-4f91-a71c-cadebdc8a59c",
   "metadata": {},
   "source": [
    "## pg_damage_infra = country_analysis_pg('LAO','fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769479e-4a85-4931-af47-fb1ff09b73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def clip_gridfinder(country_code):\n",
    "    base_map_path = os.path.join(data_path,'base_map')\n",
    "\n",
    "    cty_boundary_path = os.path.join(base_map_path,'gadm41_{}.gpkg'.format(country_code))\n",
    "    cty_boundary = gpd.read_file(cty_boundary_path)\n",
    "    #mask = pd.DataFrame(mask.copy())\n",
    "    #mask.geometry = pygeos.from_shapely(mask.geometry)\n",
    "    #mask['geometry'] = reproject(mask)\n",
    "\n",
    "    gridfinder_path = r'C:\\Users\\mye500\\OneDrive - Vrije Universiteit Amsterdam\\01_Research-Projects\\01_risk_assessment\\PG_data\\gridfinder\\grid.gpkg'\n",
    "    gridfinder = gpd.read_file(gridfinder_path)\n",
    "    #gridfinder = pd.DataFrame(gridfinder.copy())\n",
    "    #gridfinder.geometry = pygeos.from_shapely(gridfinder.geometry)\n",
    "    #gridfinder['geometry'] = reproject(gridfinder)\n",
    "\n",
    "    clipped = gpd.clip(gridfinder,cty_boundary)\n",
    "\n",
    "    return clipped\n",
    "\n",
    "clip_gridfinder('TWN')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
