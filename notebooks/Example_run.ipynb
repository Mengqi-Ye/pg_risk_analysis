{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5263e9-087d-4863-a4e5-839dc33017bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osgeo import ogr,gdal\n",
    "import os\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pyproj\n",
    "from pygeos import from_wkb,from_wkt\n",
    "import pygeos\n",
    "from tqdm import tqdm\n",
    "from shapely.wkb import loads\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from shapely.geometry import mapping\n",
    "pd.options.mode.chained_assignment = None\n",
    "from rasterio.mask import mask\n",
    "import rioxarray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6f11a902-f512-4fd3-b035-af38041ee083",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal.SetConfigOption(\"OSM_CONFIG_FILE\", os.path.join('..',\"osmconf.ini\"))\n",
    "\n",
    "# change paths to make it work on your own machine\n",
    "data_path = os.path.join('C:\\\\','Data','pg_risk_analysis')\n",
    "tc_path = os.path.join(data_path,'tc_netcdf')\n",
    "fl_path = os.path.join(data_path,'GLOFRIS')\n",
    "osm_data_path = os.path.join('C:\\\\','Data','country_osm')\n",
    "pg_data_path = os.path.join(data_path,'pg_data')\n",
    "vul_curve_path = os.path.join(data_path,'vulnerability_curves','input_vulnerability_data.xlsx')\n",
    "output_path = os.path.join('C:\\\\','projects','pg_risk_analysis','output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fc83d355-8c98-4ae6-97b1-3203a29a4fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_b(geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    This function builds an SQL query from the values passed to the retrieve() function.\n",
    "    Arguments:\n",
    "         *geoType* : Type of geometry (osm layer) to search for.\n",
    "         *keyCol* : A list of keys/columns that should be selected from the layer.\n",
    "         ***valConstraint* : A dictionary of constraints for the values. e.g. WHERE 'value'>20 or 'value'='constraint'\n",
    "    Returns:\n",
    "        *string: : a SQL query string.\n",
    "    \"\"\"\n",
    "    query = \"SELECT \" + \"osm_id\"\n",
    "    for a in keyCol: query+= \",\"+ a  \n",
    "    query += \" FROM \" + geoType + \" WHERE \"\n",
    "    # If there are values in the dictionary, add constraint clauses\n",
    "    if valConstraint: \n",
    "        for a in [*valConstraint]:\n",
    "            # For each value of the key, add the constraint\n",
    "            for b in valConstraint[a]: query += a + b\n",
    "        query+= \" AND \"\n",
    "    # Always ensures the first key/col provided is not Null.\n",
    "    query+= \"\"+str(keyCol[0]) +\" IS NOT NULL\" \n",
    "    return query \n",
    "\n",
    "\n",
    "def retrieve(osm_path,geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    Function to extract specified geometry and keys/values from OpenStreetMap\n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.     \n",
    "        *geoType* : Type of Geometry to retrieve. e.g. lines, multipolygons, etc.\n",
    "        *keyCol* : These keys will be returned as columns in the dataframe.\n",
    "        ***valConstraint: A dictionary specifiying the value constraints.  \n",
    "        A key can have multiple values (as a list) for more than one constraint for key/value.  \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all columns, geometries, and constraints specified.    \n",
    "    \"\"\"\n",
    "    driver=ogr.GetDriverByName('OSM')\n",
    "    data = driver.Open(osm_path)\n",
    "    query = query_b(geoType,keyCol,**valConstraint)\n",
    "    sql_lyr = data.ExecuteSQL(query)\n",
    "    features =[]\n",
    "    # cl = columns \n",
    "    cl = ['osm_id'] \n",
    "    for a in keyCol: cl.append(a)\n",
    "    if data is not None:\n",
    "        print('query is finished, lets start the loop')\n",
    "        for feature in tqdm(sql_lyr,desc='extract'):\n",
    "            #try:\n",
    "            if feature.GetField(keyCol[0]) is not None:\n",
    "                geom1 = (feature.geometry().ExportToWkt())\n",
    "                #print(geom1)\n",
    "                geom = from_wkt(feature.geometry().ExportToWkt()) \n",
    "                if geom is None:\n",
    "                    continue\n",
    "                # field will become a row in the dataframe.\n",
    "                field = []\n",
    "                for i in cl: field.append(feature.GetField(i))\n",
    "                field.append(geom)   \n",
    "                features.append(field)\n",
    "            #except:\n",
    "            #    print(\"WARNING: skipped OSM feature\")   \n",
    "    else:\n",
    "        print(\"ERROR: Nonetype error when requesting SQL. Check required.\")    \n",
    "    cl.append('geometry')                   \n",
    "    if len(features) > 0:\n",
    "        return pd.DataFrame(features,columns=cl)\n",
    "    else:\n",
    "        print(\"WARNING: No features or No Memory. returning empty GeoDataFrame\") \n",
    "        return pd.DataFrame(columns=['osm_id','geometry'])\n",
    "\n",
    "def power_polyline(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract all energy linestrings from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'lines',['power','voltage'])\n",
    "    \n",
    "    df = df.reset_index(drop=True).rename(columns={'power': 'asset'})\n",
    "    \n",
    "    #print(df) #check infra keys\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def power_polygon(osm_path): # check with joel, something was wrong here with extracting substations\n",
    "    \"\"\"\n",
    "    Function to extract energy polygons from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['other_tags']) \n",
    "    \n",
    "    df = df.loc[(df.other_tags.str.contains('power'))]   #keep rows containing power data         \n",
    "    df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})     \n",
    "    \n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"substation\"', case=False)]  = 'substation' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"plant\"', case=False)] = 'plant' #specify row\n",
    "    \n",
    "    df = df.loc[(df.asset == 'substation') | (df.asset == 'plant')]\n",
    "            \n",
    "    return df.reset_index(drop=True) \n",
    "\n",
    "def electricity(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract building polygons from OpenStreetMap    \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all unique building polygons.    \n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['power'])\n",
    "    \n",
    "    df = df.reset_index(drop=True).rename(columns={'power': 'asset'})\n",
    "    \n",
    "    #df = df[df.asset!='generator']\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"substation\"', case=False)]  = 'substation' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"plant\"', case=False)] = 'plant' #specify row\n",
    "    \n",
    "    #print(df)  #check infra keys\n",
    "    \n",
    "    df = df.loc[(df.asset == 'substation') | (df.asset == 'plant')]\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def retrieve_poly_subs(osm_path, w_list, b_list):\n",
    "    \"\"\"\n",
    "    Function to extract electricity substation polygons from OpenStreetMap\n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region\n",
    "        for which we want to do the analysis.\n",
    "        *w_list* :  white list of keywords to search in the other_tags columns\n",
    "        *b_list* :  black list of keywords of rows that should not be selected\n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique substation.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['other_tags'])\n",
    "    df = df[df.other_tags.str.contains('substation', case=False, na=False)]\n",
    "    #df = df.loc[(df.other_tags.str.contains('substation'))]\n",
    "    df = df[~df.other_tags.str.contains('|'.join(b_list))]\n",
    "    #df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})\n",
    "    df['asset']  = 'substation' #specify row\n",
    "    #df = df.loc[(df.asset == 'substation')] #specify row\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def power_point(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract energy points from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"   \n",
    "    df = retrieve(osm_path,'points',['other_tags']) \n",
    "    df = df.loc[(df.other_tags.str.contains('power'))]  #keep rows containing power data       \n",
    "    df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})     \n",
    "    \n",
    "    #print(df)\n",
    "    \n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"tower\"', case=False)]  = 'power_tower' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"pole\"', case=False)] = 'power_pole' #specify row\n",
    "    #df['asset'].loc[df['asset'].str.contains('\"utility\"=>\"power\"', case=False)] = 'power_tower' #specify row\n",
    "    \n",
    "    df = df.loc[(df.asset == 'power_tower') | (df.asset == 'power_pole')]\n",
    "            \n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "36fe9f2e-0be0-47fd-83ca-67f3a272279d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reproject(df_ds,current_crs=\"epsg:4326\",approximate_crs = \"epsg:3857\"):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        df_ds ([type]): [description]\n",
    "        current_crs (str, optional): [description]. Defaults to \"epsg:3857\".\n",
    "        approximate_crs (str, optional): [description]. Defaults to \"epsg:4326\".\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"    \n",
    "\n",
    "    geometries = df_ds['geometry']\n",
    "    coords = pygeos.get_coordinates(geometries)\n",
    "    transformer=pyproj.Transformer.from_crs(current_crs, approximate_crs,always_xy=True)\n",
    "    new_coords = transformer.transform(coords[:, 0], coords[:, 1])\n",
    "    \n",
    "    return pygeos.set_coordinates(geometries.copy(), np.array(new_coords).T) \n",
    "\n",
    "def load_curves_maxdam(vul_curve_path,hazard_type):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        data_path ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "\n",
    "    if hazard_type == 'tc':\n",
    "        sheet_name = 'wind_curves'\n",
    "    \n",
    "    elif hazard_type == 'fl':\n",
    "        sheet_name = 'flooding_curves'\n",
    "    \n",
    "    # load curves and maximum damages as separate inputs\n",
    "    curves = pd.read_excel(vul_curve_path,sheet_name=sheet_name,skiprows=11,index_col=[0])\n",
    "    \n",
    "    if hazard_type == 'fl':\n",
    "        maxdam = pd.read_excel(vul_curve_path,sheet_name=sheet_name,index_col=[0]).iloc[:8]\n",
    "    elif hazard_type == 'tc':\n",
    "        maxdam = pd.read_excel(vul_curve_path,sheet_name=sheet_name,index_col=[0],header=[0,1]).iloc[:8]\n",
    "        maxdam = maxdam.rename({'substation_point':'substation'},level=0,axis=1)\n",
    "            \n",
    "    curves.columns = maxdam.columns\n",
    "        \n",
    "    #transpose maxdam so its easier work with the dataframe\n",
    "    maxdam = maxdam.T\n",
    "\n",
    "    #interpolate the curves to fill missing values\n",
    "    curves = curves.interpolate()\n",
    "    \n",
    "    return curves,maxdam\n",
    "\n",
    "def buffer_assets(assets, buffer_size=100):\n",
    "    \"\"\"\n",
    "    Create a buffer of a specified size around the geometries in a GeoDataFrame.\n",
    "    \n",
    "    Args:\n",
    "        assets (GeoDataFrame): A GeoDataFrame containing geometries to be buffered.\n",
    "        buffer_size (int, optional): The distance in the units of the GeoDataFrame's CRS to buffer the geometries.\n",
    "            Defaults to 100.\n",
    "    \n",
    "    Returns:\n",
    "        GeoDataFrame: A new GeoDataFrame with an additional column named 'buffered' containing the buffered\n",
    "            geometries.\n",
    "    \"\"\"\n",
    "    # Create a buffer of the specified size around the geometries\n",
    "    assets['buffered'] = pygeos.buffer(assets.geometry.values, buffer_size)\n",
    "    \n",
    "    return assets\n",
    "\n",
    "\n",
    "def overlay_hazard_assets(df_ds, assets):\n",
    "    \"\"\"\n",
    "    Overlay a set of assets with a hazard dataset and return the subset of assets that intersect with\n",
    "    one or more hazard polygons or lines.\n",
    "    \n",
    "    Args:\n",
    "        df_ds (GeoDataFrame): A GeoDataFrame containing the hazard dataset.\n",
    "        assets (GeoDataFrame): A GeoDataFrame containing the assets to be overlaid with the hazard dataset.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: A numpy array of integers representing the indices of the hazard geometries that intersect with\n",
    "            the assets. If the assets have a 'buffered' column, the buffered geometries are used for the overlay.\n",
    "    \"\"\"\n",
    "    hazard_tree = pygeos.STRtree(df_ds.geometry.values)\n",
    "    if (pygeos.get_type_id(assets.iloc[0].geometry) == 3) | (pygeos.get_type_id(assets.iloc[0].geometry) == 6):\n",
    "        return  hazard_tree.query_bulk(assets.geometry,predicate='intersects')    \n",
    "    else:\n",
    "        return  hazard_tree.query_bulk(assets.buffered,predicate='intersects')\n",
    "    \n",
    "def get_damage_per_asset_per_rp(asset,df_ds,assets,curves,maxdam,return_period,country):\n",
    "    \"\"\"\n",
    "    Calculates the damage per asset per return period based on asset type, hazard curves and maximum damage\n",
    "\n",
    "    Args:\n",
    "        asset (tuple): Tuple with two dictionaries, containing the asset index and the hazard point index of the asset\n",
    "        df_ds (pandas.DataFrame): A pandas DataFrame containing hazard points with a 'geometry' column\n",
    "        assets (geopandas.GeoDataFrame): A GeoDataFrame containing asset geometries and asset type information\n",
    "        curves (dict): A dictionary with the asset types as keys and their corresponding hazard curves as values\n",
    "        maxdam (pandas.DataFrame): A pandas DataFrame containing the maximum damage for each asset type\n",
    "        return_period (str): The return period for which the damage should be calculated\n",
    "        country (str): The country for which the damage should be calculated\n",
    "\n",
    "    Returns:\n",
    "        list or tuple: Depending on the input, the function either returns a list of tuples with the asset index, the curve name and the calculated damage, or a tuple with None, None, None if no hazard points are found\n",
    "    \"\"\"\n",
    "    \n",
    "    # find the exact hazard overlays:\n",
    "    get_hazard_points = df_ds.iloc[asset[1]['hazard_point'].values].reset_index()\n",
    "    get_hazard_points = get_hazard_points.loc[pygeos.intersects(get_hazard_points.geometry.values,assets.iloc[asset[0]].geometry)]\n",
    "\n",
    "    \n",
    "    asset_type = assets.iloc[asset[0]].asset\n",
    "    asset_geom = assets.iloc[asset[0]].geometry\n",
    "\n",
    "    if asset_type in ['plant','substation','generator']:\n",
    "        maxdam_asset = maxdam.loc[asset_type].MaxDam/pygeos.area(asset_geom)\n",
    "        lowerdam_asset = maxdam.loc[asset_type].LowerDam/pygeos.area(asset_geom)\n",
    "        upperdam_asset = maxdam.loc[asset_type].UpperDam/pygeos.area(asset_geom)\n",
    "    else:\n",
    "        maxdam_asset = maxdam.loc[asset_type].MaxDam\n",
    "        lowerdam_asset = maxdam.loc[asset_type].LowerDam\n",
    "        upperdam_asset = maxdam.loc[asset_type].UpperDam\n",
    "\n",
    "    hazard_intensity = curves[asset_type].index.values\n",
    "    \n",
    "    if isinstance(curves[asset_type],pd.core.series.Series):\n",
    "        fragility_values = curves[asset_type].values.flatten()\n",
    "        only_one = True\n",
    "        curve_name = curves[asset_type].name\n",
    "    elif len(curves[asset_type].columns) == 1:\n",
    "        fragility_values = curves[asset_type].values.flatten()      \n",
    "        only_one = True   \n",
    "        curve_name = curves[asset_type].columns[0]\n",
    "    else:\n",
    "        fragility_values = curves[asset_type].values#.T[0]\n",
    "        maxdam_asset = maxdam_asset.values#[0]\n",
    "        only_one = False\n",
    "\n",
    "    if len(get_hazard_points) == 0:\n",
    "        return [return_period,asset[0],None,None]\n",
    "    else:\n",
    "        if only_one:    \n",
    "            # run the calculation as normal when the asset just has a single curve\n",
    "            if pygeos.get_type_id(asset_geom) == 1:            \n",
    "                get_hazard_points['overlay_meters'] = pygeos.length(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "                return [return_period,asset[0],curve_name,np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*maxdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*lowerdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*upperdam_asset)]\n",
    "\n",
    "            elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                get_hazard_points['overlay_m2'] = pygeos.area(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "                return [return_period,asset[0],curve_name,get_hazard_points.apply(lambda x: np.interp(x[return_period],hazard_intensity, \n",
    "                                                                  fragility_values)*maxdam_asset*x.overlay_m2,axis=1).sum(),\n",
    "                                                          get_hazard_points.apply(lambda x: np.interp(x[return_period],hazard_intensity, \n",
    "                                                                  fragility_values)*lowerdam_asset*x.overlay_m2,axis=1).sum(),\n",
    "                                                          get_hazard_points.apply(lambda x: np.interp(x[return_period],hazard_intensity, \n",
    "                                                                  fragility_values)*upperdam_asset*x.overlay_m2,axis=1).sum()]     \n",
    "\n",
    "            else:\n",
    "                return [return_period,asset[0],curve_name,np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*maxdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*lowerdam_asset),\n",
    "                                                          np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*upperdam_asset)]\n",
    "        else:\n",
    "            if pygeos.get_type_id(asset_geom) == 1:            \n",
    "                get_hazard_points['overlay_meters'] = pygeos.length(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                get_hazard_points['overlay_m2'] = pygeos.area(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            \n",
    "            collect_all = []\n",
    "            for iter_,curve_ids in enumerate(curves[asset_type].columns):\n",
    "                if pygeos.get_type_id(asset_geom) == 1:                           \n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*get_hazard_points.overlay_meters*maxdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*get_hazard_points.overlay_meters*lowerdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*get_hazard_points.overlay_meters*upperdam_asset[iter_])])\n",
    "                \n",
    "                elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                        get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity,\n",
    "                                                                                    fragility_values.T[iter_])*maxdam_asset[iter_]*x.overlay_m2,axis=1).sum(),\n",
    "                                        get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity,\n",
    "                                                                                    fragility_values.T[iter_])*lowerdam_asset[iter_]*x.overlay_m2,axis=1).sum(),\n",
    "                                        get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity,\n",
    "                                                                                    fragility_values.T[iter_])*upperdam_asset[iter_]*x.overlay_m2,axis=1).sum()])\n",
    "\n",
    "                else:\n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*maxdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*lowerdam_asset[iter_]),\n",
    "                                        np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                          hazard_intensity,fragility_values.T[iter_]))*upperdam_asset[iter_])])\n",
    "            return collect_all\n",
    "\n",
    "\"\"\"\n",
    "def get_lowerdam_per_asset_per_rp(asset,df_ds,assets,curves,maxdam,return_period,country):\n",
    "    \"\"\"\n",
    "    Calculates the lower damage per asset per return period based on asset type, hazard curves and maximum damage\n",
    "\n",
    "    Args:\n",
    "        asset (tuple): Tuple with two dictionaries, containing the asset index and the hazard point index of the asset\n",
    "        df_ds (pandas.DataFrame): A pandas DataFrame containing hazard points with a 'geometry' column\n",
    "        assets (geopandas.GeoDataFrame): A GeoDataFrame containing asset geometries and asset type information\n",
    "        curves (dict): A dictionary with the asset types as keys and their corresponding hazard curves as values\n",
    "        maxdam (pandas.DataFrame): A pandas DataFrame containing the maximum damage for each asset type\n",
    "        return_period (str): The return period for which the damage should be calculated\n",
    "        country (str): The country for which the damage should be calculated\n",
    "\n",
    "    Returns:\n",
    "        list or tuple: Depending on the input, the function either returns a list of tuples with the asset index, the curve name and the calculated damage, or a tuple with None, None, None if no hazard points are found\n",
    "    \"\"\"\n",
    "    \n",
    "    # find the exact hazard overlays:\n",
    "    get_hazard_points = df_ds.iloc[asset[1]['hazard_point'].values].reset_index()\n",
    "    get_hazard_points = get_hazard_points.loc[pygeos.intersects(get_hazard_points.geometry.values,assets.iloc[asset[0]].geometry)]\n",
    "\n",
    "    \n",
    "    asset_type = assets.iloc[asset[0]].asset\n",
    "    asset_geom = assets.iloc[asset[0]].geometry\n",
    "\n",
    "    if asset_type in ['plant','substation','generator']:\n",
    "        lowerdam_asset = maxdam.loc[asset_type].LowerDam/pygeos.area(asset_geom)\n",
    "    else:\n",
    "        lowerdam_asset = maxdam.loc[asset_type].LowerDam\n",
    "\n",
    "    hazard_intensity = curves[asset_type].index.values\n",
    "    \n",
    "    if isinstance(curves[asset_type],pd.core.series.Series):\n",
    "        fragility_values = curves[asset_type].values.flatten()\n",
    "        only_one = True\n",
    "        curve_name = curves[asset_type].name\n",
    "    elif len(curves[asset_type].columns) == 1:\n",
    "        fragility_values = curves[asset_type].values.flatten()      \n",
    "        only_one = True   \n",
    "        curve_name = curves[asset_type].columns[0]\n",
    "    else:\n",
    "        fragility_values = curves[asset_type].values#.T[0]\n",
    "        lowerdam_asset = lowerdam_asset.values#[0]\n",
    "        only_one = False\n",
    "\n",
    "    if len(get_hazard_points) == 0:\n",
    "        return [return_period,asset[0],None,None]\n",
    "    else:\n",
    "        if only_one:    \n",
    "            # run the calculation as normal when the asset just has a single curve\n",
    "            if pygeos.get_type_id(asset_geom) == 1:            \n",
    "                get_hazard_points['overlay_meters'] = pygeos.length(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "                return [return_period,asset[0],curve_name,np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                             fragility_values))*get_hazard_points.overlay_meters*lowerdam_asset)]\n",
    "\n",
    "            elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                get_hazard_points['overlay_m2'] = pygeos.area(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "                return [return_period,asset[0],curve_name,get_hazard_points.apply(lambda x: np.interp(x[return_period], \n",
    "                                                                  hazard_intensity, \n",
    "                                                                  fragility_values)*lowerdam_asset*x.overlay_m2,axis=1).sum()]     \n",
    "\n",
    "            else:\n",
    "                return [return_period,asset[0],curve_name,np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                                             hazard_intensity,fragility_values))*lowerdam_asset)]\n",
    "        else:\n",
    "            if pygeos.get_type_id(asset_geom) == 1:            \n",
    "                get_hazard_points['overlay_meters'] = pygeos.length(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                get_hazard_points['overlay_m2'] = pygeos.area(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            \n",
    "            collect_all = []\n",
    "            for iter_,curve_ids in enumerate(curves[asset_type].columns):\n",
    "                if pygeos.get_type_id(asset_geom) == 1:                           \n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],np.sum((np.interp(get_hazard_points[return_period].values,\n",
    "                                      hazard_intensity,\n",
    "                                      fragility_values.T[iter_]))*get_hazard_points.overlay_meters*lowerdam_asset[iter_])])\n",
    "                \n",
    "                elif (pygeos.get_type_id(asset_geom) == 3) | (pygeos.get_type_id(asset_geom) == 6) :\n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],get_hazard_points.apply(lambda x: np.interp(x[return_period], \n",
    "                                                              hazard_intensity, \n",
    "                                                              fragility_values.T[iter_])*lowerdam_asset[iter_]*x.overlay_m2,axis=1).sum()])     \n",
    "\n",
    "                else:\n",
    "                    collect_all.append([return_period,asset[0],curves[asset_type].columns[iter_],\n",
    "                                              np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,\n",
    "                                                                fragility_values.T[iter_]))*lowerdam_asset[iter_])])\n",
    "            return collect_all\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1bf0e992-b4d1-46b0-a952-488ac8c5b2b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Infrastructure type</th>\n",
       "      <th>Code</th>\n",
       "      <th>Type vulnerability data</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Unit</th>\n",
       "      <th>MaxDam</th>\n",
       "      <th>LowerDam</th>\n",
       "      <th>UpperDam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>plant</th>\n",
       "      <td>F1_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>469326964.354556</td>\n",
       "      <td>127998263.005788</td>\n",
       "      <td>639991315.02894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>substation</th>\n",
       "      <td>F2_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34132870.134877</td>\n",
       "      <td>12799826.300579</td>\n",
       "      <td>63999131.502894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_tower</th>\n",
       "      <td>F3_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128807.753197</td>\n",
       "      <td>22657.06884</td>\n",
       "      <td>437857.236411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_pole</th>\n",
       "      <td>F4_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22706.148119</td>\n",
       "      <td>10805.300809</td>\n",
       "      <td>35832.221593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>F5_1</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>918.052146</td>\n",
       "      <td>136.209517</td>\n",
       "      <td>2095.531033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cable</th>\n",
       "      <td>F5_2</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3400.782131</td>\n",
       "      <td>461.016827</td>\n",
       "      <td>9639.442752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minor_line</th>\n",
       "      <td>F5_3</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>509.785702</td>\n",
       "      <td>62.865931</td>\n",
       "      <td>955.562151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plant_point</th>\n",
       "      <td>F1_2</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>469326964.354556</td>\n",
       "      <td>127998263.005788</td>\n",
       "      <td>639991315.02894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>substation_point</th>\n",
       "      <td>F2_2</td>\n",
       "      <td>curve</td>\n",
       "      <td>euro/facility</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34132870.134877</td>\n",
       "      <td>12799826.300579</td>\n",
       "      <td>63999131.502894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Infrastructure type  Code Type vulnerability data           Unit Unit Unit  \\\n",
       "plant                F1_1                   curve  euro/facility  NaN  NaN   \n",
       "substation           F2_1                   curve  euro/facility  NaN  NaN   \n",
       "power_tower          F3_1                   curve  euro/facility  NaN  NaN   \n",
       "power_pole           F4_1                   curve  euro/facility  NaN  NaN   \n",
       "line                 F5_1                   curve         euro/m  NaN  NaN   \n",
       "cable                F5_2                   curve         euro/m  NaN  NaN   \n",
       "minor_line           F5_3                   curve         euro/m  NaN  NaN   \n",
       "plant_point          F1_2                   curve  euro/facility  NaN  NaN   \n",
       "substation_point     F2_2                   curve  euro/facility  NaN  NaN   \n",
       "\n",
       "Infrastructure type            MaxDam          LowerDam         UpperDam  \n",
       "plant                469326964.354556  127998263.005788  639991315.02894  \n",
       "substation            34132870.134877   12799826.300579  63999131.502894  \n",
       "power_tower             128807.753197       22657.06884    437857.236411  \n",
       "power_pole               22706.148119      10805.300809     35832.221593  \n",
       "line                       918.052146        136.209517      2095.531033  \n",
       "cable                     3400.782131        461.016827      9639.442752  \n",
       "minor_line                 509.785702         62.865931       955.562151  \n",
       "plant_point          469326964.354556  127998263.005788  639991315.02894  \n",
       "substation_point      34132870.134877   12799826.300579  63999131.502894  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_curves_maxdam(vul_curve_path,'fl')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e9896d9f-4592-4552-8876-c1340f3e09f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_storm_data(climate_model,basin,bbox,ne_crs):\n",
    "    \n",
    "    with xr.open_dataset(os.path.join(tc_path,'STORM_FIXED_RETURN_PERIODS{}_{}.nc'.format(climate_model,basin))) as ds:\n",
    "        \n",
    "        ds.rio.write_crs(4326, inplace=True)\n",
    "        ds = ds.rio.clip_box(minx=bbox[0],miny=bbox[1],maxx=bbox[2],maxy=bbox[3])\n",
    "        \n",
    "        # get the mean values\n",
    "        df_ds = ds['mean'].to_dataframe().unstack(level=2).reset_index()\n",
    "\n",
    "        # create geometry values and drop lat lon columns\n",
    "        df_ds['geometry'] = [pygeos.points(x) for x in list(zip(df_ds['lon'],df_ds['lat']))]\n",
    "        df_ds = df_ds.drop(['lat','lon'],axis=1,level=0)\n",
    "        \n",
    "        # interpolate wind speeds of 1, 2, and 5-yr return period\n",
    "        ## rename columns to return periods (must be integer for interpolating)\n",
    "        df_ds_geometry = pd.DataFrame()\n",
    "        df_ds_geometry['geometry'] = df_ds['geometry']\n",
    "        df_ds = df_ds.drop(['geometry'],axis=1,level=0)\n",
    "        df_ds = df_ds['mean']\n",
    "        df_ds.columns = [int(x) for x in ds['mean']['rp']]\n",
    "        df_ds[1] = np.nan\n",
    "        df_ds[2] = np.nan\n",
    "        df_ds[5] = np.nan\n",
    "        df_ds[25] = np.nan\n",
    "        df_ds[250] = np.nan\n",
    "        df_ds = df_ds.reindex(sorted(df_ds.columns), axis=1)\n",
    "        df_ds = df_ds.interpolate(method='linear',axis=1,limit_direction='both')\n",
    "        df_ds['geometry'] = df_ds_geometry['geometry']\n",
    "        #df_ds = df_ds[['1','2','5','10','25','50','100','250','500','1000','geometry']]\n",
    "        df_ds = df_ds[[1,2,5,10,25,50,100,250,500,1000,'geometry']]\n",
    "        \n",
    "        #rename columns to return periods\n",
    "        #return_periods = ['1_{}{}'.format(int(x),climate_model) for x in ds['rp']]\n",
    "        df_ds.columns = ['1_{}{}'.format(int(x),climate_model) for x in [1,2,5,10,25,50,100,250,500,1000]] +['geometry']     \n",
    "        df_ds['geometry'] = pygeos.buffer(df_ds.geometry,radius=0.1/2,cap_style='square').values\n",
    "        df_ds['geometry'] = reproject(df_ds)\n",
    "            \n",
    "        # drop all non values to reduce size\n",
    "        #df_ds = df_ds.loc[~df_ds['1_10000{}'.format(climate_model)].isna()].reset_index(drop=True)\n",
    "        df_ds = df_ds.fillna(0)\n",
    "        #df_ds = df_ds[['1','2','5','10','25','50','100','250','500','1000']]\n",
    "        #df_ds = df_ds[['1_{}{}'.format(int(x),climate_model) for x in list(df_ds.columns.get_level_values(0))[:-1]]+['geometry']]\n",
    "\n",
    "    return df_ds\n",
    "\n",
    "def open_storm_data(country_code):\n",
    "    climate_models = ['_CMCC-CM2-VHR4'] #'','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM'\n",
    "    df_ds = {}\n",
    "    \n",
    "    country_basin = {\n",
    "    \"BRN\": [\"WP\"],\n",
    "    \"KHM\": [\"WP\"],\n",
    "    \"CHN\": [\"WP\", \"NI\"],\n",
    "    \"IDN\": [\"SI\", \"SP\", \"NI\", \"WP\"],\n",
    "    \"JPN\": [\"WP\"],\n",
    "    \"LAO\": [\"WP\"],\n",
    "    \"MYS\": [\"WP\", \"NI\"],\n",
    "    \"MNG\": [\"WP\", \"NI\"],\n",
    "    \"MMR\": [\"NI\", \"WP\"],\n",
    "    \"PRK\": [\"WP\"],\n",
    "    \"PHL\": [\"WP\"],\n",
    "    \"SGP\": [\"WP\"],\n",
    "    \"KOR\": [\"WP\"],\n",
    "    \"TWN\": [\"WP\"],\n",
    "    \"THA\": [\"WP\", \"NI\"],\n",
    "    \"VNM\": [\"WP\"] }\n",
    "    \n",
    "    # load country geometry file and create geometry to clip\n",
    "    ne_countries = gpd.read_file('C:\\\\Data\\\\natural_earth\\\\ne_10m_admin_0_countries.shp') \n",
    "    ne_crs = ne_countries.crs\n",
    "    bbox = ne_countries.loc[ne_countries['ISO_A3']==country_code].geometry.buffer(1).values[0].bounds\n",
    "\n",
    "    for climate_model in climate_models:\n",
    "        concat_prep = []\n",
    "        #combine STORM data from different basins\n",
    "        if \"WP\" in country_basin[country_code]:\n",
    "            WP = load_storm_data(climate_model,'WP',bbox,ne_crs)\n",
    "            concat_prep.append(WP)\n",
    "        if \"SP\" in country_basin[country_code]:\n",
    "            SP = load_storm_data(climate_model,'SP',bbox,ne_crs)\n",
    "            concat_prep.append(SP)\n",
    "        if \"NI\" in country_basin[country_code]:            \n",
    "            NI = load_storm_data(climate_model,'NI',bbox,ne_crs)\n",
    "            concat_prep.append(NI)            \n",
    "        if \"SI\" in country_basin[country_code]:       \n",
    "            SI = load_storm_data(climate_model,'SI',bbox,ne_crs)\n",
    "            concat_prep.append(SI)            \n",
    "                   \n",
    "        df_ds_cl = pd.concat(concat_prep,keys=country_basin[country_code])#,sp,ni,si,'sp','ni','si'])\n",
    "\n",
    "        df_ds_cl = df_ds_cl.reset_index(drop=True)\n",
    "        \n",
    "        df_ds[climate_model] = df_ds_cl\n",
    "    \n",
    "    return df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b43b71-49ee-4aee-aca7-db18ecbd8b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "twn_wind=open_storm_data('TWN')\n",
    "print(type(twn_wind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7059f5f8-fff4-4827-a187-bebcf957230d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.89 s\n",
      "Wall time: 2.88 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_2</th>\n",
       "      <th>1_5</th>\n",
       "      <th>1_10</th>\n",
       "      <th>1_25</th>\n",
       "      <th>1_50</th>\n",
       "      <th>1_100</th>\n",
       "      <th>1_250</th>\n",
       "      <th>1_500</th>\n",
       "      <th>1_1000</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.484970</td>\n",
       "      <td>31.484970</td>\n",
       "      <td>31.484970</td>\n",
       "      <td>31.484970</td>\n",
       "      <td>34.882271</td>\n",
       "      <td>37.150791</td>\n",
       "      <td>38.786932</td>\n",
       "      <td>41.029938</td>\n",
       "      <td>42.933264</td>\n",
       "      <td>43.897242</td>\n",
       "      <td>POLYGON ((13057776.27 2391878.588, 13057776.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.561684</td>\n",
       "      <td>31.561684</td>\n",
       "      <td>31.561684</td>\n",
       "      <td>31.561684</td>\n",
       "      <td>34.941517</td>\n",
       "      <td>37.417290</td>\n",
       "      <td>38.952814</td>\n",
       "      <td>40.987155</td>\n",
       "      <td>42.433489</td>\n",
       "      <td>43.846372</td>\n",
       "      <td>POLYGON ((13068908.219 2391878.588, 13068908.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.559660</td>\n",
       "      <td>31.559660</td>\n",
       "      <td>31.559660</td>\n",
       "      <td>31.559660</td>\n",
       "      <td>34.989208</td>\n",
       "      <td>37.441990</td>\n",
       "      <td>39.295692</td>\n",
       "      <td>41.087890</td>\n",
       "      <td>42.636647</td>\n",
       "      <td>43.937314</td>\n",
       "      <td>POLYGON ((13080040.168 2391878.588, 13080040.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.649051</td>\n",
       "      <td>31.649051</td>\n",
       "      <td>31.649051</td>\n",
       "      <td>31.649051</td>\n",
       "      <td>35.093386</td>\n",
       "      <td>37.464786</td>\n",
       "      <td>39.427878</td>\n",
       "      <td>41.296611</td>\n",
       "      <td>42.939086</td>\n",
       "      <td>44.289626</td>\n",
       "      <td>POLYGON ((13091172.117 2391878.588, 13091172.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.749391</td>\n",
       "      <td>31.749391</td>\n",
       "      <td>31.749391</td>\n",
       "      <td>31.749391</td>\n",
       "      <td>35.266336</td>\n",
       "      <td>37.634156</td>\n",
       "      <td>39.579647</td>\n",
       "      <td>41.514516</td>\n",
       "      <td>42.741313</td>\n",
       "      <td>44.298240</td>\n",
       "      <td>POLYGON ((13102304.066 2391878.588, 13102304.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>35.069860</td>\n",
       "      <td>35.069860</td>\n",
       "      <td>35.069860</td>\n",
       "      <td>35.069860</td>\n",
       "      <td>39.243768</td>\n",
       "      <td>42.045388</td>\n",
       "      <td>44.128518</td>\n",
       "      <td>46.371252</td>\n",
       "      <td>48.097373</td>\n",
       "      <td>49.527067</td>\n",
       "      <td>POLYGON ((13658901.52 3036284.923, 13658901.52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>35.159120</td>\n",
       "      <td>35.159120</td>\n",
       "      <td>35.159120</td>\n",
       "      <td>35.159120</td>\n",
       "      <td>39.261418</td>\n",
       "      <td>41.821312</td>\n",
       "      <td>44.056902</td>\n",
       "      <td>46.617187</td>\n",
       "      <td>48.180678</td>\n",
       "      <td>49.415934</td>\n",
       "      <td>POLYGON ((13670033.469 3036284.923, 13670033.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>35.238116</td>\n",
       "      <td>35.238116</td>\n",
       "      <td>35.238116</td>\n",
       "      <td>35.238116</td>\n",
       "      <td>39.250911</td>\n",
       "      <td>41.894078</td>\n",
       "      <td>44.101615</td>\n",
       "      <td>46.562302</td>\n",
       "      <td>47.930412</td>\n",
       "      <td>48.967779</td>\n",
       "      <td>POLYGON ((13681165.418 3036284.923, 13681165.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>35.309186</td>\n",
       "      <td>35.309186</td>\n",
       "      <td>35.309186</td>\n",
       "      <td>35.309186</td>\n",
       "      <td>39.248515</td>\n",
       "      <td>41.935010</td>\n",
       "      <td>44.177309</td>\n",
       "      <td>46.750433</td>\n",
       "      <td>47.926717</td>\n",
       "      <td>48.968906</td>\n",
       "      <td>POLYGON ((13692297.368 3036284.923, 13692297.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>35.334279</td>\n",
       "      <td>35.334279</td>\n",
       "      <td>35.334279</td>\n",
       "      <td>35.334279</td>\n",
       "      <td>39.291144</td>\n",
       "      <td>41.815739</td>\n",
       "      <td>44.186469</td>\n",
       "      <td>46.671538</td>\n",
       "      <td>47.922262</td>\n",
       "      <td>49.403801</td>\n",
       "      <td>POLYGON ((13703429.317 3036284.923, 13703429.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3186 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1_1        1_2        1_5       1_10       1_25       1_50  \\\n",
       "0     31.484970  31.484970  31.484970  31.484970  34.882271  37.150791   \n",
       "1     31.561684  31.561684  31.561684  31.561684  34.941517  37.417290   \n",
       "2     31.559660  31.559660  31.559660  31.559660  34.989208  37.441990   \n",
       "3     31.649051  31.649051  31.649051  31.649051  35.093386  37.464786   \n",
       "4     31.749391  31.749391  31.749391  31.749391  35.266336  37.634156   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "3181  35.069860  35.069860  35.069860  35.069860  39.243768  42.045388   \n",
       "3182  35.159120  35.159120  35.159120  35.159120  39.261418  41.821312   \n",
       "3183  35.238116  35.238116  35.238116  35.238116  39.250911  41.894078   \n",
       "3184  35.309186  35.309186  35.309186  35.309186  39.248515  41.935010   \n",
       "3185  35.334279  35.334279  35.334279  35.334279  39.291144  41.815739   \n",
       "\n",
       "          1_100      1_250      1_500     1_1000  \\\n",
       "0     38.786932  41.029938  42.933264  43.897242   \n",
       "1     38.952814  40.987155  42.433489  43.846372   \n",
       "2     39.295692  41.087890  42.636647  43.937314   \n",
       "3     39.427878  41.296611  42.939086  44.289626   \n",
       "4     39.579647  41.514516  42.741313  44.298240   \n",
       "...         ...        ...        ...        ...   \n",
       "3181  44.128518  46.371252  48.097373  49.527067   \n",
       "3182  44.056902  46.617187  48.180678  49.415934   \n",
       "3183  44.101615  46.562302  47.930412  48.967779   \n",
       "3184  44.177309  46.750433  47.926717  48.968906   \n",
       "3185  44.186469  46.671538  47.922262  49.403801   \n",
       "\n",
       "                                               geometry  \n",
       "0     POLYGON ((13057776.27 2391878.588, 13057776.27...  \n",
       "1     POLYGON ((13068908.219 2391878.588, 13068908.2...  \n",
       "2     POLYGON ((13080040.168 2391878.588, 13080040.1...  \n",
       "3     POLYGON ((13091172.117 2391878.588, 13091172.1...  \n",
       "4     POLYGON ((13102304.066 2391878.588, 13102304.0...  \n",
       "...                                                 ...  \n",
       "3181  POLYGON ((13658901.52 3036284.923, 13658901.52...  \n",
       "3182  POLYGON ((13670033.469 3036284.923, 13670033.4...  \n",
       "3183  POLYGON ((13681165.418 3036284.923, 13681165.4...  \n",
       "3184  POLYGON ((13692297.368 3036284.923, 13692297.3...  \n",
       "3185  POLYGON ((13703429.317 3036284.923, 13703429.3...  \n",
       "\n",
       "[3186 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "open_storm_data('TWN')['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c7ff6dd-a3f2-4e2a-becd-e5cffa38edde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clip_flood_data(country_code):\n",
    "\n",
    "    # load country geometry file and create geometry to clip\n",
    "    ne_countries = gpd.read_file('C:\\\\Data\\\\natural_earth\\\\ne_10m_admin_0_countries.shp') \n",
    "    geometry = ne_countries.loc[ne_countries['ISO_A3']==country_code].geometry.values[0]\n",
    "    geoms = [mapping(geometry)]\n",
    "    \n",
    "    #climate_model: historical, rcp4p5, rcp8p5; time_period: hist, 2030, 2050, 2080\n",
    "    rps = ['0001','0002','0005','0010','0025','0050','0100','0250','0500','1000']\n",
    "    climate_models = ['historical','rcp8p5']\n",
    "    \n",
    "    \n",
    "    for rp in rps:\n",
    "        #global input_file\n",
    "        for climate_model in climate_models:\n",
    "            if climate_model=='historical':\n",
    "                #f rps=='0001':\n",
    "                    input_file = os.path.join(fl_path,'global',\n",
    "                                              'inuncoast_{}_nosub_hist_rp{}_0.tif'.format(climate_model,rp)) \n",
    "                #elif rps==['0002','0005','0010','0025','0050','0100','0250','0500','1000']:\n",
    "                #    input_file = os.path.join(fl_path,'global',\n",
    "                #                              'inuncoast_{}_nosub_hist_rp{}_0.tif'.format(climate_model,rp)) \n",
    "            elif climate_model=='rcp8p5':\n",
    "                #f rps=='0001':\n",
    "                    input_file = os.path.join(fl_path,'global',\n",
    "                                              'inuncoast_{}_nosub_2030_rp{}_0.tif'.format(climate_model,rp))\n",
    "                #elif rps==['0002','0005','0010','0025','0050','0100','0250','0500','1000']:\n",
    "                #    input_file = os.path.join(fl_path,'global',\n",
    "                #                              'inuncoast_{}_nosub_2030_rp{}_0.tif'.format(climate_model,rp))\n",
    "            \n",
    "            # load raster file and save clipped version\n",
    "            with rasterio.open(input_file) as src:\n",
    "                out_image, out_transform = mask(src, geoms, crop=True)\n",
    "                out_meta = src.meta\n",
    "\n",
    "                out_meta.update({\"driver\": \"GTiff\",\n",
    "                         \"height\": out_image.shape[1],\n",
    "                         \"width\": out_image.shape[2],\n",
    "                         \"transform\": out_transform})\n",
    "\n",
    "                file_path = os.path.join(fl_path,'country','_'.join([country_code]+input_file.split('_')[3:]))\n",
    "\n",
    "                with rasterio.open(file_path, \"w\", **out_meta) as dest:\n",
    "                    dest.write(out_image)\n",
    "\n",
    "def load_flood_data(country_code,climate_model):\n",
    "    files = [x for x in os.listdir(os.path.join(fl_path,'country'))  if country_code in x ]\n",
    "    \n",
    "    rps = ['0001','0002','0005','0010','0025','0050','0100','0250','0500','1000']\n",
    "    collect_df_ds = []\n",
    "    \n",
    "    if climate_model=='historical':\n",
    "        print('Loading historical coastal flood data ...')\n",
    "        for rp in rps:\n",
    "            #for file in files:\n",
    "            file_path = os.path.join(fl_path,'country','{}_{}_nosub_hist_rp{}_0.tif'.format(country_code,climate_model,rp))\n",
    "            with xr.open_dataset(file_path) as ds: #, engine=\"rasterio\"\n",
    "                df_ds = ds.to_dataframe().reset_index()\n",
    "                df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "                df_ds = df_ds.rename(columns={'band_data': 'rp'+rp}) #rename to return period\n",
    "                \n",
    "                # move from meters to centimeters\n",
    "                df_ds['rp'+rp] = (df_ds['rp'+rp]*100)         \n",
    "                df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "                df_ds = df_ds.dropna()\n",
    "                df_ds = df_ds.reset_index(drop=True)\n",
    "                df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=0.00833/2,cap_style='square').values  #?????????????????????????\n",
    "                df_ds['geometry'] = reproject(df_ds)\n",
    "                collect_df_ds.append(df_ds)\n",
    "\n",
    "        df_all = collect_df_ds[0].merge(collect_df_ds[1]).merge(collect_df_ds[2]).merge(collect_df_ds[3]).merge(collect_df_ds[4])\\\n",
    "                 .merge(collect_df_ds[5]).merge(collect_df_ds[6]).merge(collect_df_ds[7]).merge(collect_df_ds[8]).merge(collect_df_ds[9])\n",
    "        df_all = df_all.loc[df_all['rp1000']>0].reset_index(drop=True)\n",
    "\n",
    "    elif climate_model=='rcp8p5':\n",
    "        print('Loading future coastal flood data ...')\n",
    "        for rp in rps:\n",
    "            #for file in files:\n",
    "            file_path = os.path.join(fl_path,'country','{}_{}_nosub_2030_rp{}_0.tif'.format(country_code,climate_model,rp))\n",
    "            with xr.open_dataset(file_path) as ds: #, engine=\"rasterio\"\n",
    "                df_ds = ds.to_dataframe().reset_index()\n",
    "                df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "                df_ds = df_ds.rename(columns={'band_data': 'rp'+rp}) #rename to return period\n",
    "                df_ds['rp'+rp] = (df_ds['rp'+rp]*100)\n",
    "                df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "                df_ds = df_ds.dropna()\n",
    "                df_ds = df_ds.reset_index(drop=True)\n",
    "                df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=0.00833/2,cap_style='square').values\n",
    "                df_ds['geometry'] = reproject(df_ds)\n",
    "                collect_df_ds.append(df_ds)\n",
    "\n",
    "        df_all = collect_df_ds[0].merge(collect_df_ds[1]).merge(collect_df_ds[2]).merge(collect_df_ds[3]).merge(collect_df_ds[4])\\\n",
    "                 .merge(collect_df_ds[5]).merge(collect_df_ds[6]).merge(collect_df_ds[7]).merge(collect_df_ds[8]).merge(collect_df_ds[9])\n",
    "\n",
    "        df_all = df_all.loc[df_all['rp1000']>0].reset_index(drop=True)\n",
    "    return df_all\n",
    "\n",
    "def open_flood_data(country_code):\n",
    "    climate_models = ['historical','rcp8p5']\n",
    "    df_ds = {}\n",
    "    for climate_model in climate_models:\n",
    "        #hist = load_flood_data(country_code,'historical')\n",
    "        #rcp8p5 = load_flood_data(country_code,'rcp8p5')\n",
    "        #df_ds_sc = pd.concat([hist,rcp8p5],keys=['historical','rcp8p5'])\n",
    "        df_ds_sc = load_flood_data(country_code,climate_model)\n",
    "\n",
    "        df_ds[climate_model] = df_ds_sc\n",
    "    \n",
    "    return df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ebbb408-29e0-4128-ad1b-2a7eae99b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_flood_data('KHM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5ac9f48-e434-4893-8c04-07e663921d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n",
      "CPU times: total: 30.8 s\n",
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "twn_flood = open_flood_data('TWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4cb2960-1dbe-4c3e-b9c9-4a65773bddd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(twn_flood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6e24a4d-35cc-4bdd-8d69-4d2c504fe1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rp0001</th>\n",
       "      <th>geometry</th>\n",
       "      <th>rp0002</th>\n",
       "      <th>rp0005</th>\n",
       "      <th>rp0010</th>\n",
       "      <th>rp0025</th>\n",
       "      <th>rp0050</th>\n",
       "      <th>rp0100</th>\n",
       "      <th>rp0250</th>\n",
       "      <th>rp0500</th>\n",
       "      <th>rp1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176.420731</td>\n",
       "      <td>POLYGON ((13168167.913 2811396.474, 13168167.9...</td>\n",
       "      <td>190.869278</td>\n",
       "      <td>226.426697</td>\n",
       "      <td>249.968765</td>\n",
       "      <td>279.714294</td>\n",
       "      <td>301.781189</td>\n",
       "      <td>323.685181</td>\n",
       "      <td>352.525330</td>\n",
       "      <td>374.301910</td>\n",
       "      <td>396.062744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190.201111</td>\n",
       "      <td>POLYGON ((13169095.575 2810377.258, 13169095.5...</td>\n",
       "      <td>204.649658</td>\n",
       "      <td>240.207077</td>\n",
       "      <td>263.749146</td>\n",
       "      <td>293.494690</td>\n",
       "      <td>315.561554</td>\n",
       "      <td>337.465546</td>\n",
       "      <td>366.305695</td>\n",
       "      <td>388.082275</td>\n",
       "      <td>409.843170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>POLYGON ((13170023.238 2811396.474, 13170023.2...</td>\n",
       "      <td>10.197401</td>\n",
       "      <td>45.754814</td>\n",
       "      <td>69.296883</td>\n",
       "      <td>99.042419</td>\n",
       "      <td>121.109299</td>\n",
       "      <td>143.013290</td>\n",
       "      <td>171.853455</td>\n",
       "      <td>193.630035</td>\n",
       "      <td>215.390869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>POLYGON ((13170023.238 2810377.258, 13170023.2...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.110926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>POLYGON ((13170950.9 2811396.474, 13170950.9 2...</td>\n",
       "      <td>98.447418</td>\n",
       "      <td>134.004837</td>\n",
       "      <td>157.546906</td>\n",
       "      <td>187.292435</td>\n",
       "      <td>209.359314</td>\n",
       "      <td>231.263306</td>\n",
       "      <td>260.103455</td>\n",
       "      <td>281.880035</td>\n",
       "      <td>303.640900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>127.308418</td>\n",
       "      <td>POLYGON ((13525317.946 2521533.141, 13525317.9...</td>\n",
       "      <td>129.873520</td>\n",
       "      <td>136.186218</td>\n",
       "      <td>140.365738</td>\n",
       "      <td>145.646622</td>\n",
       "      <td>149.564270</td>\n",
       "      <td>153.452972</td>\n",
       "      <td>158.573105</td>\n",
       "      <td>162.439209</td>\n",
       "      <td>166.302521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>9.339666</td>\n",
       "      <td>POLYGON ((13526245.608 2519531.048, 13526245.6...</td>\n",
       "      <td>11.904764</td>\n",
       "      <td>18.217468</td>\n",
       "      <td>22.396994</td>\n",
       "      <td>27.677870</td>\n",
       "      <td>31.595516</td>\n",
       "      <td>35.484219</td>\n",
       "      <td>40.604355</td>\n",
       "      <td>44.470451</td>\n",
       "      <td>48.333763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>POLYGON ((13559641.456 2840983.226, 13559641.4...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.591582</td>\n",
       "      <td>11.742449</td>\n",
       "      <td>16.855263</td>\n",
       "      <td>23.587109</td>\n",
       "      <td>28.670193</td>\n",
       "      <td>33.749603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>POLYGON ((13560569.118 2840983.226, 13560569.1...</td>\n",
       "      <td>17.736244</td>\n",
       "      <td>26.036049</td>\n",
       "      <td>31.531216</td>\n",
       "      <td>38.474392</td>\n",
       "      <td>43.625259</td>\n",
       "      <td>48.738075</td>\n",
       "      <td>55.469917</td>\n",
       "      <td>60.553001</td>\n",
       "      <td>65.632416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>POLYGON ((13560569.118 2839962.04, 13560569.11...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.818989</td>\n",
       "      <td>8.902073</td>\n",
       "      <td>13.981485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1003 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          rp0001                                           geometry  \\\n",
       "0     176.420731  POLYGON ((13168167.913 2811396.474, 13168167.9...   \n",
       "1     190.201111  POLYGON ((13169095.575 2810377.258, 13169095.5...   \n",
       "2       0.000000  POLYGON ((13170023.238 2811396.474, 13170023.2...   \n",
       "3       0.000000  POLYGON ((13170023.238 2810377.258, 13170023.2...   \n",
       "4       0.000000  POLYGON ((13170950.9 2811396.474, 13170950.9 2...   \n",
       "...          ...                                                ...   \n",
       "998   127.308418  POLYGON ((13525317.946 2521533.141, 13525317.9...   \n",
       "999     9.339666  POLYGON ((13526245.608 2519531.048, 13526245.6...   \n",
       "1000    0.000000  POLYGON ((13559641.456 2840983.226, 13559641.4...   \n",
       "1001    0.000000  POLYGON ((13560569.118 2840983.226, 13560569.1...   \n",
       "1002    0.000000  POLYGON ((13560569.118 2839962.04, 13560569.11...   \n",
       "\n",
       "          rp0002      rp0005      rp0010      rp0025      rp0050      rp0100  \\\n",
       "0     190.869278  226.426697  249.968765  279.714294  301.781189  323.685181   \n",
       "1     204.649658  240.207077  263.749146  293.494690  315.561554  337.465546   \n",
       "2      10.197401   45.754814   69.296883   99.042419  121.109299  143.013290   \n",
       "3       0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "4      98.447418  134.004837  157.546906  187.292435  209.359314  231.263306   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "998   129.873520  136.186218  140.365738  145.646622  149.564270  153.452972   \n",
       "999    11.904764   18.217468   22.396994   27.677870   31.595516   35.484219   \n",
       "1000    0.000000    0.000000    0.000000    6.591582   11.742449   16.855263   \n",
       "1001   17.736244   26.036049   31.531216   38.474392   43.625259   48.738075   \n",
       "1002    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "          rp0250      rp0500      rp1000  \n",
       "0     352.525330  374.301910  396.062744  \n",
       "1     366.305695  388.082275  409.843170  \n",
       "2     171.853455  193.630035  215.390869  \n",
       "3       0.000000    0.000000   11.110926  \n",
       "4     260.103455  281.880035  303.640900  \n",
       "...          ...         ...         ...  \n",
       "998   158.573105  162.439209  166.302521  \n",
       "999    40.604355   44.470451   48.333763  \n",
       "1000   23.587109   28.670193   33.749603  \n",
       "1001   55.469917   60.553001   65.632416  \n",
       "1002    3.818989    8.902073   13.981485  \n",
       "\n",
       "[1003 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twn_flood['historical']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3de688-606c-4dd2-abe3-f37015c7442e",
   "metadata": {},
   "source": [
    "# OSM data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "934161b6-5f01-4315-87b3-9e4a7bd70876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_osm_infrastructure(country_code,osm_data_path):\n",
    "\n",
    "    # lines\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    power_lines_country = power_polyline(osm_path)\n",
    "    power_lines_country['geometry'] = reproject(power_lines_country)\n",
    "    power_lines_country = buffer_assets(power_lines_country.loc[power_lines_country.asset.isin(\n",
    "        ['cable','minor_cable','line','minor_line'])],buffer_size=100).reset_index(drop=True)\n",
    "    \n",
    "    # polygons\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    power_poly_country = electricity(osm_path)\n",
    "    power_poly_country['geometry'] = reproject(power_poly_country)\n",
    "    \n",
    "    # points\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    power_points_country = power_point(osm_path)\n",
    "    power_points_country['geometry'] = reproject(power_points_country)\n",
    "    power_points_country = buffer_assets(power_points_country.loc[power_points_country.asset.isin(\n",
    "        ['power_tower','power_pole'])],buffer_size=100).reset_index(drop=True)\n",
    "    #print(power_points_country)\n",
    "    #print(type(power_points_country))\n",
    "\n",
    "    return power_lines_country,power_poly_country,power_points_country\n",
    "\n",
    "\n",
    "#print(type(osm_power_infra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b16fbb7a-d740-4b39-bfdd-127321fb4cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|████████████████████████████████████████████████████████████████████| 2470/2470 [00:06<00:00, 357.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|███████████████████████████████████████████████████████████████████████| 368/368 [00:16<00:00, 22.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|████████████████████████████████████████████████████████████| 1608621/1608621 [02:40<00:00, 10052.17it/s]\n"
     ]
    }
   ],
   "source": [
    "osm_power_infra = extract_osm_infrastructure('TWN',osm_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "abb7a943-1950-445c-8328-f6db95b7f163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assess_damage_osm(country_code,osm_power_infra,hazard_type):\n",
    "    \n",
    "    # set paths\n",
    "    # data_path,tc_path,fl_path,osm_data_path,pg_data_path,vul_curve_path,output_path = set_paths()\n",
    "\n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(vul_curve_path,hazard_type)\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    power_lines,power_poly,power_points = osm_power_infra\n",
    "\n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "        df_ds = open_storm_data(country_code)\n",
    "        \n",
    "        # remove assets that will not have any damage\n",
    "        power_lines = power_lines.loc[power_lines.asset != 'cable'].reset_index(drop=True)\n",
    "        power_poly = power_poly.loc[power_poly.asset != 'plant'].reset_index(drop=True)\n",
    "\n",
    "    elif hazard_type=='fl':\n",
    "        # read flood data\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "        df_ds = open_flood_data(country_code) \n",
    "        \n",
    "    #calculate damaged lines/polygons/points in loop by climate_model\n",
    "    damaged_lines = {}\n",
    "    damaged_poly = {}\n",
    "    damaged_points = {}\n",
    "    \n",
    "    for climate_model in climate_models:\n",
    "        \n",
    "        if hazard_type == 'tc':\n",
    "            return_periods = ['1_1{}'.format(climate_model),'1_2{}'.format(climate_model),'1_5{}'.format(climate_model),'1_10{}'.format(climate_model),\n",
    "                              '1_25{}'.format(climate_model),'1_50{}'.format(climate_model),'1_100{}'.format(climate_model),\n",
    "                              '1_250{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "        elif hazard_type == 'fl':\n",
    "            return_periods = ['rp0001','rp0002','rp0005','rp0010','rp0025','rp0050','rp0100','rp0250','rp0500','rp1000']  \n",
    "\n",
    "        # assess damage for lines\n",
    "        overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],power_lines).T,\n",
    "                                     columns=['asset','hazard_point'])\n",
    "        \n",
    "        \n",
    "        collect_line_damages = []\n",
    "        for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                          desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "            for return_period in return_periods:\n",
    "                collect_line_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                       df_ds[climate_model],\n",
    "                                                                       power_lines,\n",
    "                                                                       curves,\n",
    "                                                                       maxdam,\n",
    "                                                                       return_period,\n",
    "                                                                       country_code))\n",
    "\n",
    "        get_asset_type_line = dict(zip(power_lines.index,power_lines.asset))\n",
    "\n",
    "        if hazard_type == 'fl':\n",
    "            results = pd.DataFrame(collect_line_damages,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])  #columns=['rp','asset','curve','damage']\n",
    "        elif hazard_type == 'tc':\n",
    "            results = pd.DataFrame([item for sublist in collect_line_damages \n",
    "                                    for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "        \n",
    "        results['asset_type'] = results.asset.apply(lambda x : get_asset_type_line[x])\n",
    "\n",
    "        damaged_lines[climate_model] = results.groupby(['rp','curve','asset_type']).sum().reset_index()\n",
    "            \n",
    "        # assess damage for polygons\n",
    "        if len(power_poly) > 0:\n",
    "            overlay_poly = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],power_poly).T,\n",
    "                                    columns=['asset','hazard_point'])\n",
    "        else:\n",
    "            overlay_poly = pd.DataFrame()\n",
    "            \n",
    "        if len(overlay_poly) == 0:\n",
    "            damaged_poly[climate_model] = pd.DataFrame()\n",
    "        \n",
    "        else:\n",
    "            collect_poly_damages = []\n",
    "            for asset in tqdm(overlay_poly.groupby('asset'),total=len(overlay_poly.asset.unique()),\n",
    "                              desc='polygon damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_poly_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                           df_ds[climate_model],\n",
    "                                                                           power_poly,\n",
    "                                                                           curves,\n",
    "                                                                           maxdam,\n",
    "                                                                           return_period,\n",
    "                                                                           country_code))\n",
    "\n",
    "            get_asset_type_poly = dict(zip(power_poly.index,power_poly.asset))\n",
    "\n",
    "            if hazard_type == 'fl':\n",
    "                results = pd.DataFrame(collect_poly_damages ,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "            elif hazard_type == 'tc':\n",
    "                results = pd.DataFrame([item for sublist in collect_poly_damages \n",
    "                                        for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "            \n",
    "            results['asset_type'] = results.asset.apply(lambda x : get_asset_type_poly[x])    \n",
    "\n",
    "            damaged_poly[climate_model] = results.groupby(['rp','curve','asset_type']).sum().reset_index()\n",
    "\n",
    "        # assess damage for points\n",
    "        overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],power_points).T,\n",
    "                                      columns=['asset','hazard_point'])\n",
    "        collect_point_damages = []\n",
    "        for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                          desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "            for return_period in return_periods:\n",
    "                collect_point_damages.append(get_damage_per_asset_per_rp(asset,\n",
    "                                                                        df_ds[climate_model],\n",
    "                                                                        power_points,\n",
    "                                                                        curves,\n",
    "                                                                        maxdam,\n",
    "                                                                        return_period,\n",
    "                                                                        country_code))\n",
    "\n",
    "        get_asset_type_point = dict(zip(power_points.index,power_points.asset))\n",
    "\n",
    "        if hazard_type == 'fl':\n",
    "            results = pd.DataFrame(collect_point_damages ,columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "        elif hazard_type == 'tc':\n",
    "            results = pd.DataFrame([item for sublist in collect_point_damages \n",
    "                                    for item in sublist],columns=['rp','asset','curve','meandam','lowerdam','upperdam'])\n",
    "  \n",
    "        results['asset_type'] = results.asset.apply(lambda x : get_asset_type_point[x])    \n",
    "    \n",
    "        damaged_points[climate_model] = results.groupby(['rp','curve','asset_type']).sum().reset_index()\n",
    "\n",
    "    return damaged_lines,damaged_poly,damaged_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ac71f06a-d796-456c-a7b5-4564ba01f806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for TWN fl (historical): 100%|█████████████████████████████| 58/58 [00:01<00:00, 32.20it/s]\n",
      "polygon damage calculation for TWN fl (historical): 100%|██████████████████████████████| 60/60 [00:02<00:00, 21.96it/s]\n",
      "point damage calculation for TWN fl (historical): 100%|██████████████████████████████| 325/325 [00:05<00:00, 61.18it/s]\n",
      "polyline damage calculation for TWN fl (rcp8p5): 100%|█████████████████████████████████| 69/69 [00:02<00:00, 31.97it/s]\n",
      "polygon damage calculation for TWN fl (rcp8p5): 100%|██████████████████████████████████| 61/61 [00:02<00:00, 22.02it/s]\n",
      "point damage calculation for TWN fl (rcp8p5): 100%|██████████████████████████████████| 392/392 [00:06<00:00, 61.23it/s]\n"
     ]
    }
   ],
   "source": [
    "osm_damage_infra = assess_damage_osm('TWN',osm_power_infra,'fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f2f2c812-e814-4791-a7c3-850f7a42e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.ExcelWriter(os.path.join(output_path,'output.xlsx')) as writer:  \n",
    "#    osm_damage_infra[0]['historical'].to_excel(writer, sheet_name='Sheet_name_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e4092487-d2be-4fc2-b251-36d3e26c6b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'historical':          rp       curve  asset_type      lowerdam       upperdam  \\\n",
       "  0    rp0001       cable       cable      0.000000       0.000000   \n",
       "  1    rp0001        line        line      0.000000       0.000000   \n",
       "  2    rp0001        line        line    225.322420    3466.498766   \n",
       "  3    rp0001        line        line    285.544771    4392.996471   \n",
       "  4    rp0001        line        line    602.625133    9271.155891   \n",
       "  ..      ...         ...         ...           ...            ...   \n",
       "  265  rp1000        line        line   7230.362784  111236.350526   \n",
       "  266  rp1000        line        line  14400.462669  221545.579528   \n",
       "  267  rp1000        line        line  15128.444282  232745.296647   \n",
       "  268  rp1000        line        line  16984.226826  261295.797316   \n",
       "  269  rp1000  minor_line  minor_line    239.436292    3639.431638   \n",
       "  \n",
       "             meandam  \n",
       "  0         0.000000  \n",
       "  1         0.000000  \n",
       "  2      1518.673109  \n",
       "  3      1924.571754  \n",
       "  4      4061.693396  \n",
       "  ..             ...  \n",
       "  265   48732.645166  \n",
       "  266   97059.118391  \n",
       "  267  101965.714461  \n",
       "  268  114473.688804  \n",
       "  269    1941.611239  \n",
       "  \n",
       "  [270 rows x 6 columns],\n",
       "  'rcp8p5':          rp       curve  asset_type      lowerdam       upperdam  \\\n",
       "  0    rp0001       cable       cable      0.000000       0.000000   \n",
       "  1    rp0001        line        line      0.000000       0.000000   \n",
       "  2    rp0001        line        line     12.118317     186.435639   \n",
       "  3    rp0001        line        line    632.928674    9737.364212   \n",
       "  4    rp0001        line        line    634.743656    9765.287014   \n",
       "  ..      ...         ...         ...           ...            ...   \n",
       "  285  rp1000        line        line   9808.890213  150906.003273   \n",
       "  286  rp1000        line        line  17113.558010  263285.507842   \n",
       "  287  rp1000        line        line  17523.795623  269596.855737   \n",
       "  288  rp1000        line        line  18783.096595  288970.716848   \n",
       "  289  rp1000  minor_line  minor_line    239.436292    3639.431638   \n",
       "  \n",
       "             meandam  \n",
       "  0         0.000000  \n",
       "  1         0.000000  \n",
       "  2        81.677453  \n",
       "  3      4265.939261  \n",
       "  4      4278.172241  \n",
       "  ..             ...  \n",
       "  285   66111.920034  \n",
       "  286  115345.380986  \n",
       "  287  118110.382498  \n",
       "  288  126598.071051  \n",
       "  289    1941.611239  \n",
       "  \n",
       "  [290 rows x 6 columns]},\n",
       " {'historical':          rp       curve  asset_type      lowerdam      upperdam       meandam\n",
       "  0    rp0001       plant       plant  0.000000e+00  0.000000e+00  0.000000e+00\n",
       "  1    rp0001       plant       plant  7.989003e+04  3.994502e+05  2.929301e+05\n",
       "  2    rp0001       plant       plant  1.830696e+05  9.153478e+05  6.712550e+05\n",
       "  3    rp0001       plant       plant  2.131661e+05  1.065830e+06  7.816090e+05\n",
       "  4    rp0001       plant       plant  3.276472e+05  1.638236e+06  1.201373e+06\n",
       "  ..      ...         ...         ...           ...           ...           ...\n",
       "  533  rp1000       plant       plant  3.823395e+07  1.911698e+08  1.401912e+08\n",
       "  534  rp1000  substation  substation  5.356216e+04  2.678108e+05  1.428324e+05\n",
       "  535  rp1000  substation  substation  1.325985e+05  6.629925e+05  3.535960e+05\n",
       "  536  rp1000  substation  substation  1.228298e+06  6.141492e+06  3.275462e+06\n",
       "  537  rp1000  substation  substation  1.919974e+06  9.599870e+06  5.119931e+06\n",
       "  \n",
       "  [538 rows x 6 columns],\n",
       "  'rcp8p5':          rp       curve  asset_type      lowerdam      upperdam       meandam\n",
       "  0    rp0001       plant       plant  0.000000e+00  0.000000e+00  0.000000e+00\n",
       "  1    rp0001       plant       plant  7.989003e+04  3.994502e+05  2.929301e+05\n",
       "  2    rp0001       plant       plant  2.161801e+05  1.080901e+06  7.926604e+05\n",
       "  3    rp0001       plant       plant  2.760486e+05  1.380243e+06  1.012178e+06\n",
       "  4    rp0001       plant       plant  8.990564e+05  4.495282e+06  3.296540e+06\n",
       "  ..      ...         ...         ...           ...           ...           ...\n",
       "  564  rp1000       plant       plant  3.839948e+07  1.919974e+08  2.815962e+08\n",
       "  565  rp1000  substation  substation  2.086536e+05  1.043268e+06  5.564096e+05\n",
       "  566  rp1000  substation  substation  2.955446e+05  1.477723e+06  7.881188e+05\n",
       "  567  rp1000  substation  substation  1.239916e+06  6.199579e+06  3.306442e+06\n",
       "  568  rp1000  substation  substation  1.919974e+06  9.599870e+06  5.119931e+06\n",
       "  \n",
       "  [569 rows x 6 columns]},\n",
       " {'historical':          rp        curve   asset_type    lowerdam     upperdam       meandam\n",
       "  0    rp0001   power_pole   power_pole    0.000000     0.000000      0.000000\n",
       "  1    rp0001  power_tower  power_tower    0.000000     0.000000      0.000000\n",
       "  2    rp0001  power_tower  power_tower   25.493582   492.674019    724.668090\n",
       "  3    rp0001  power_tower  power_tower   30.298448   585.530050    516.749323\n",
       "  4    rp0001  power_tower  power_tower   57.394727  1109.176865    326.294893\n",
       "  ..      ...          ...          ...         ...          ...           ...\n",
       "  386  rp1000  power_tower  power_tower  431.838935  8345.466230   2455.048507\n",
       "  387  rp1000  power_tower  power_tower  439.570770  8494.887124   7497.014322\n",
       "  388  rp1000  power_tower  power_tower  449.456156  8685.926306   5110.408411\n",
       "  389  rp1000  power_tower  power_tower  449.764274  8691.880821  20455.647119\n",
       "  390  rp1000  power_tower  power_tower  453.141377  8757.144728  82436.962046\n",
       "  \n",
       "  [391 rows x 6 columns],\n",
       "  'rcp8p5':          rp        curve   asset_type    lowerdam     upperdam        meandam\n",
       "  0    rp0001   power_pole   power_pole    0.000000     0.000000       0.000000\n",
       "  1    rp0001  power_tower  power_tower    0.000000     0.000000       0.000000\n",
       "  2    rp0001  power_tower  power_tower    8.892307   171.847518      50.553676\n",
       "  3    rp0001  power_tower  power_tower   27.591061   533.208685     470.574016\n",
       "  4    rp0001  power_tower  power_tower   29.189265   564.094626     331.887909\n",
       "  ..      ...          ...          ...         ...          ...            ...\n",
       "  430  rp1000  power_tower  power_tower  442.942258  8560.042542    5036.344066\n",
       "  431  rp1000  power_tower  power_tower  449.255573  8682.049955    2554.063870\n",
       "  432  rp1000  power_tower  power_tower  451.926272  8733.662320   12846.235338\n",
       "  433  rp1000  power_tower  power_tower  452.942391  8753.299237    2575.023807\n",
       "  434  rp1000  power_tower  power_tower  453.141377  8757.144728  115926.977877\n",
       "  \n",
       "  [435 rows x 6 columns]})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract nested dict by key\n",
    "osm_damage_infra# [0]['historical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5d5e4b99-fb9d-4e25-a456-757930e52242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(osm_damage_infra[0]['historical']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "457c186a-018f-4a87-b4e0-c0a7e2927aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_analysis_osm(country_code,hazard_type): #\n",
    "    \n",
    "    # extract infrastructure data from OSM\n",
    "    #osm_power_infra = extract_osm_infrastructure(country_code,osm_data_path)  #!!!!!!!!!!!!!!!!!!!!!!!!DELETE NOTES AFTER TEST\n",
    "    \n",
    "    # assess damage to hazard_type\n",
    "    osm_damage_infra = assess_damage_osm(country_code,osm_power_infra,hazard_type)\n",
    "    \n",
    "    if hazard_type=='tc':\n",
    "        climate_models = ['_CMCC-CM2-VHR4'] #'','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM'\n",
    "    elif hazard_type=='fl':\n",
    "        climate_models = ['historical','rcp8p5']\n",
    "        \n",
    "    for i in range(len(osm_damage_infra)):\n",
    "        for climate_model in climate_models:\n",
    "            with pd.ExcelWriter(os.path.join(output_path,'{}_{}_damage_{}'.format(country_code,climate_model,i)+'.xlsx')) as writer:\n",
    "                osm_damage_infra[i][climate_model].to_excel(writer)\n",
    "\n",
    "    return osm_damage_infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b08ddf81-6571-4e42-bbdd-b6b6e948186a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for TWN fl (historical): 100%|█████████████████████████████| 58/58 [00:01<00:00, 32.17it/s]\n",
      "polygon damage calculation for TWN fl (historical): 100%|██████████████████████████████| 60/60 [00:02<00:00, 22.03it/s]\n",
      "point damage calculation for TWN fl (historical): 100%|██████████████████████████████| 325/325 [00:05<00:00, 61.07it/s]\n",
      "polyline damage calculation for TWN fl (rcp8p5): 100%|█████████████████████████████████| 69/69 [00:02<00:00, 32.62it/s]\n",
      "polygon damage calculation for TWN fl (rcp8p5): 100%|██████████████████████████████████| 61/61 [00:02<00:00, 21.44it/s]\n",
      "point damage calculation for TWN fl (rcp8p5): 100%|██████████████████████████████████| 392/392 [00:06<00:00, 59.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 51.8 s\n",
      "Wall time: 51.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "osm_damage_infra = country_analysis_osm('TWN','fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b093416a-4b36-4f15-affe-2b78c4942c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#osm_damage_infra[1]['_CNRM-CM6-1-HR']\n",
    "osm_damage_infra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ba717-0015-4527-bf1a-a9556f87a541",
   "metadata": {},
   "source": [
    "# Government data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef53a27c-f539-43db-9870-1ee933ddf7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load collected power grid data\n",
    "def extract_pg_data(country_code,pg_type):\n",
    "    files = [x for x in os.listdir(pg_data_path)  if country_code in x ]\n",
    "    \n",
    "    if pg_type=='line':\n",
    "        for file in files: \n",
    "            file_path = os.path.join(pg_data_path,'{}_{}.gpkg'.format(country_code,pg_type))\n",
    "\n",
    "            pg_data_country = gpd.read_file(file_path)\n",
    "            pg_data_country = pd.DataFrame(pg_data_country.copy())\n",
    "            #print(pg_data_country.head())\n",
    "            pg_data_country.geometry = pygeos.from_shapely(pg_data_country.geometry)\n",
    "            pg_data_country['geometry'] = reproject(pg_data_country)\n",
    "\n",
    "        pg_data_country = buffer_assets(pg_data_country.loc[pg_data_country.asset.isin(['line'])],buffer_size=100).reset_index(drop=True)\n",
    "\n",
    "    elif pg_type=='point':\n",
    "        for file in files:\n",
    "            file_path = os.path.join(pg_data_path,'{}_{}.gpkg'.format(country_code,pg_type))\n",
    "                \n",
    "            pg_data_country = gpd.read_file(file_path)\n",
    "            pg_data_country = pd.DataFrame(pg_data_country.copy())\n",
    "            #print(pg_data_country.head())\n",
    "            pg_data_country.geometry = pygeos.from_shapely(pg_data_country.geometry)\n",
    "            pg_data_country['geometry'] = reproject(pg_data_country)\n",
    "            #print(pg_data_country)\n",
    "\n",
    "        pg_data_country = buffer_assets(pg_data_country.loc[pg_data_country.asset.isin(['plant_point','substation_point','power_tower','power_pole'])],buffer_size=100).reset_index(drop=True)\n",
    "\n",
    "    return pg_data_country\n",
    "\n",
    "def open_pg_data(country_code):\n",
    "    pg_lines = extract_pg_data(country_code,'line')\n",
    "    pg_points = extract_pg_data(country_code,'point')\n",
    "    #print(pg_points)\n",
    "    return pg_lines,pg_points\n",
    "\n",
    "pg_infra = open_pg_data('LAO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24824f71-092f-4509-97cf-4e292da71126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_damage_pg(country_code,pg_infra,hazard_type):\n",
    "    \n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(os.path.join(vul_curve_path,'infra_vulnerability_data.xlsx'))\n",
    "    #curves['line'] = 1 # remove this when things work!\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    pg_lines,pg_points = pg_infra\n",
    "    #print(type(pg_points))\n",
    "    #print(type(pg_infra))\n",
    "    \n",
    "    pg_lines.head(5)\n",
    "    pg_points.head(5)\n",
    "    \n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = ['','_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM'] # !!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        df_ds = open_storm_data()\n",
    "        \n",
    "        # calculate damaged lines in loop by country_code and climate_model\n",
    "        damaged_lines = {}\n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['1_10{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                              '1_100{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "\n",
    "            overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],\n",
    "                                                               pg_lines).T,columns=['asset','hazard_point'])\n",
    "            collect_line_damages = []\n",
    "            for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                              desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_line_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                           df_ds[climate_model],\n",
    "                                                                                           pg_lines,\n",
    "                                                                                           curves,\n",
    "                                                                                           maxdam,\n",
    "                                                                                           return_period,\n",
    "                                                                                           country_code)])\n",
    "\n",
    "        collect_line_damages = [(line[0],line[1][0],line[1][1]) for line in collect_line_damages]\n",
    "        damaged_lines_country = pg_lines.merge(pd.DataFrame(collect_line_damages,columns=['return_period','index','damage']),\n",
    "                                                  left_index=True,right_on='index')\n",
    "        damaged_lines_country = damaged_lines_country.drop(['buffered'],axis=1)\n",
    "        damaged_lines[climate_model] = damaged_lines_country\n",
    "        \n",
    "        # calculate damaged points in loop by country_code and climate_model\n",
    "        damaged_points = {}\n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['1_10{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                              '1_100{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "\n",
    "            overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],pg_points).T,\n",
    "                                          columns=['asset','hazard_point'])\n",
    "            collect_point_damages = []\n",
    "            for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                              desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_point_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                            df_ds[climate_model],\n",
    "                                                                                            pg_points,\n",
    "                                                                                            curves,\n",
    "                                                                                            maxdam,\n",
    "                                                                                            return_period,\n",
    "                                                                                            country_code)])\n",
    "\n",
    "        collect_point_damages = [(line[0],line[1][0],line[1][1]) for line in collect_point_damages]\n",
    "        damaged_points_country = pg_points.merge(pd.DataFrame(collect_point_damages,columns=['return_period','index','damage']),\n",
    "                                                    left_index=True,right_on='index')\n",
    "        damaged_points_country = damaged_points_country.drop(['buffered'],axis=1)\n",
    "        damaged_points[climate_model] = damaged_points_country\n",
    " \n",
    "    elif hazard_type=='fl':\n",
    "        # read flood data\n",
    "        climate_models = ('historical','rcp8p5')\n",
    "        df_ds = open_flood_data(country_code) #['historical'].head(30) # REMOVE .HEAD(30)\n",
    "        #time_periods = []\n",
    "        \n",
    "        #for time_period in time_periods:\n",
    "        return_periods = ['rp0010','rp0050','rp0100','rp0500','rp1000']\n",
    "        \n",
    "        # calculate damaged lines in loop by country_code and climate_model\n",
    "        damaged_lines = {}\n",
    "        for climate_model in climate_models:\n",
    "            overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],pg_lines).T,columns=['asset','hazard_point'])\n",
    "            collect_line_damages = []\n",
    "            for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                              desc='polyline damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_line_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                           df_ds[climate_model],\n",
    "                                                                                           pg_lines,\n",
    "                                                                                           curves,\n",
    "                                                                                           maxdam,\n",
    "                                                                                           return_period,\n",
    "                                                                                           country_code)])\n",
    "                    \n",
    "        collect_line_damages = [(line[0],line[1][0],line[1][1]) for line in collect_line_damages]\n",
    "        damaged_lines_country = pg_lines.merge(pd.DataFrame(collect_line_damages,columns=['return_period','index','damage']),\n",
    "                                                  left_index=True,right_on='index')\n",
    "        damaged_lines = damaged_lines_country.drop(['buffered'],axis=1)\n",
    "        \n",
    "        # calculate damaged points in loop by country_code and climate_model\n",
    "        damaged_points = {}\n",
    "        for climate_model in climate_models:\n",
    "            overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],pg_points).T,\n",
    "                                          columns=['asset','hazard_point'])\n",
    "            collect_point_damages = []\n",
    "            for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                              desc='point damage calculation for {} {} ({})'.format(country_code,hazard_type,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_point_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                            df_ds[climate_model],\n",
    "                                                                                            pg_points,\n",
    "                                                                                            curves,\n",
    "                                                                                            maxdam,\n",
    "                                                                                            return_period,\n",
    "                                                                                            country_code)])\n",
    "\n",
    "        collect_point_damages = [(line[0],line[1][0],line[1][1]) for line in collect_point_damages]\n",
    "        damaged_points_country = pg_points.merge(pd.DataFrame(collect_point_damages,columns=['return_period','index','damage']),\n",
    "                                                    left_index=True,right_on='index')\n",
    "        damaged_points = damaged_points_country.drop(['buffered'],axis=1)\n",
    "        \n",
    "    return damaged_lines,damaged_points\n",
    "\n",
    "pg_damage_infra = assess_damage_pg('LAO',pg_infra,'tc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24da424b-cbc9-4359-a557-7900720bbef8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pg_damage_infra' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpg_damage_infra\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pg_damage_infra' is not defined"
     ]
    }
   ],
   "source": [
    "pg_damage_infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fac49c0-8408-4d6a-b063-ef6180b6c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'tuple'>\n",
      "Loading historical coastal flood data ...\n",
      "Loading future coastal flood data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for LAO fl (historical):  74%|█████████████████      | 317/427 [3:20:12<1:09:28, 37.89s/it]\n",
      "Exception ignored in: <function ZipFile.__del__ at 0x0000012B1188B040>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mye500\\Miniconda3\\envs\\pgrisk\\lib\\zipfile.py\", line 1816, in __del__\n",
      "    self.close()\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def country_analysis_pg(country_code,hazard_type): #\n",
    "    \n",
    "    # extract infrastructure data from OSM\n",
    "    pg_infra = open_pg_data(country_code)\n",
    "\n",
    "    # assess damage to wind storms\n",
    "    pg_damage_infra = assess_damage_pg(country_code,pg_infra,hazard_type)\n",
    "\n",
    "    return pg_damage_infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae8ede-90e1-4231-b55a-351183a71c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_damage_infra = country_analysis_pg('LAO','fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2db9c5e8-9e66-40ed-9f76-3049cfa21b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'_CMCC-CM2-VHR4':         status  capacity_kV              value   id      source country  \\\n",
       "  0     Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "  1     Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "  2     Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "  3     Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "  4     Existing          230  transmission_line  0.0  World Bank    Laos   \n",
       "  ...        ...          ...                ...  ...         ...     ...   \n",
       "  2130  Existing           22               None  NaN  World Bank    None   \n",
       "  2131  Existing           22               None  NaN  World Bank    None   \n",
       "  2132  Existing           22               None  NaN  World Bank    None   \n",
       "  2133  Existing           22               None  NaN  World Bank    None   \n",
       "  2134  Existing           22               None  NaN  World Bank    None   \n",
       "  \n",
       "       operator undergrnd phases cables  year asset  \\\n",
       "  0        None      None   None   None  None  line   \n",
       "  1        None      None   None   None  None  line   \n",
       "  2        None      None   None   None  None  line   \n",
       "  3        None      None   None   None  None  line   \n",
       "  4        None      None   None   None  None  line   \n",
       "  ...       ...       ...    ...    ...   ...   ...   \n",
       "  2130     None      None   None   None  None  line   \n",
       "  2131     None      None   None   None  None  line   \n",
       "  2132     None      None   None   None  None  line   \n",
       "  2133     None      None   None   None  None  line   \n",
       "  2134     None      None   None   None  None  line   \n",
       "  \n",
       "                                                 geometry         return_period  \\\n",
       "  0     LINESTRING (11642041.532 2064458.971, 11641491...    1_10_CMCC-CM2-VHR4   \n",
       "  1     LINESTRING (11642041.532 2064458.971, 11641491...    1_50_CMCC-CM2-VHR4   \n",
       "  2     LINESTRING (11642041.532 2064458.971, 11641491...   1_100_CMCC-CM2-VHR4   \n",
       "  3     LINESTRING (11642041.532 2064458.971, 11641491...   1_500_CMCC-CM2-VHR4   \n",
       "  4     LINESTRING (11642041.532 2064458.971, 11641491...  1_1000_CMCC-CM2-VHR4   \n",
       "  ...                                                 ...                   ...   \n",
       "  2130  LINESTRING (11369167.465 2255664.932, 11361366...    1_10_CMCC-CM2-VHR4   \n",
       "  2131  LINESTRING (11369167.465 2255664.932, 11361366...    1_50_CMCC-CM2-VHR4   \n",
       "  2132  LINESTRING (11369167.465 2255664.932, 11361366...   1_100_CMCC-CM2-VHR4   \n",
       "  2133  LINESTRING (11369167.465 2255664.932, 11361366...   1_500_CMCC-CM2-VHR4   \n",
       "  2134  LINESTRING (11369167.465 2255664.932, 11361366...  1_1000_CMCC-CM2-VHR4   \n",
       "  \n",
       "        index        damage  \n",
       "  0         0  2.790178e+08  \n",
       "  1         0  2.790178e+08  \n",
       "  2         0  2.790178e+08  \n",
       "  3         0  2.790178e+08  \n",
       "  4         0  2.790178e+08  \n",
       "  ...     ...           ...  \n",
       "  2130    426  2.658654e+07  \n",
       "  2131    426  2.658654e+07  \n",
       "  2132    426  2.658654e+07  \n",
       "  2133    426  2.658654e+07  \n",
       "  2134    426  2.658654e+07  \n",
       "  \n",
       "  [2135 rows x 16 columns]},\n",
       " {'_CMCC-CM2-VHR4':        status      source country   type capacit_MW  involt_kV outvolt_kV  \\\n",
       "  0    Existing  World Bank    Laos  Hydro       None        NaN       None   \n",
       "  1    Existing  World Bank    Laos  Hydro       None        NaN       None   \n",
       "  2    Existing  World Bank    Laos  Hydro       None        NaN       None   \n",
       "  3    Existing  World Bank    Laos  Hydro       None        NaN       None   \n",
       "  4    Existing  World Bank    Laos  Hydro       None        NaN       None   \n",
       "  ..        ...         ...     ...    ...        ...        ...        ...   \n",
       "  180   Planned  World Bank    Laos   None       None       22.0       None   \n",
       "  181   Planned  World Bank    Laos   None       None       22.0       None   \n",
       "  182   Planned  World Bank    Laos   None       None       22.0       None   \n",
       "  183   Planned  World Bank    Laos   None       None       22.0       None   \n",
       "  184   Planned  World Bank    Laos   None       None       22.0       None   \n",
       "  \n",
       "      capaci_kVA units                  layer  \\\n",
       "  0         None  None  lao33762powerstations   \n",
       "  1         None  None  lao33762powerstations   \n",
       "  2         None  None  lao33762powerstations   \n",
       "  3         None  None  lao33762powerstations   \n",
       "  4         None  None  lao33762powerstations   \n",
       "  ..         ...   ...                    ...   \n",
       "  180       None  None    lao33762substations   \n",
       "  181       None  None    lao33762substations   \n",
       "  182       None  None    lao33762substations   \n",
       "  183       None  None    lao33762substations   \n",
       "  184       None  None    lao33762substations   \n",
       "  \n",
       "                                                    path             asset  \\\n",
       "  0    C:/Users/mye500/OneDrive - Vrije Universiteit ...       plant_point   \n",
       "  1    C:/Users/mye500/OneDrive - Vrije Universiteit ...       plant_point   \n",
       "  2    C:/Users/mye500/OneDrive - Vrije Universiteit ...       plant_point   \n",
       "  3    C:/Users/mye500/OneDrive - Vrije Universiteit ...       plant_point   \n",
       "  4    C:/Users/mye500/OneDrive - Vrije Universiteit ...       plant_point   \n",
       "  ..                                                 ...               ...   \n",
       "  180  C:/Users/mye500/OneDrive - Vrije Universiteit ...  substation_point   \n",
       "  181  C:/Users/mye500/OneDrive - Vrije Universiteit ...  substation_point   \n",
       "  182  C:/Users/mye500/OneDrive - Vrije Universiteit ...  substation_point   \n",
       "  183  C:/Users/mye500/OneDrive - Vrije Universiteit ...  substation_point   \n",
       "  184  C:/Users/mye500/OneDrive - Vrije Universiteit ...  substation_point   \n",
       "  \n",
       "                               geometry         return_period  index  \\\n",
       "  0    POINT (11361572.355 2244469.157)    1_10_CMCC-CM2-VHR4      0   \n",
       "  1    POINT (11361572.355 2244469.157)    1_50_CMCC-CM2-VHR4      0   \n",
       "  2    POINT (11361572.355 2244469.157)   1_100_CMCC-CM2-VHR4      0   \n",
       "  3    POINT (11361572.355 2244469.157)   1_500_CMCC-CM2-VHR4      0   \n",
       "  4    POINT (11361572.355 2244469.157)  1_1000_CMCC-CM2-VHR4      0   \n",
       "  ..                                ...                   ...    ...   \n",
       "  180  POINT (11668538.497 1965410.054)    1_10_CMCC-CM2-VHR4     36   \n",
       "  181  POINT (11668538.497 1965410.054)    1_50_CMCC-CM2-VHR4     36   \n",
       "  182  POINT (11668538.497 1965410.054)   1_100_CMCC-CM2-VHR4     36   \n",
       "  183  POINT (11668538.497 1965410.054)   1_500_CMCC-CM2-VHR4     36   \n",
       "  184  POINT (11668538.497 1965410.054)  1_1000_CMCC-CM2-VHR4     36   \n",
       "  \n",
       "             damage  \n",
       "  0    1.723896e+07  \n",
       "  1    1.965907e+07  \n",
       "  2    2.060631e+07  \n",
       "  3    2.362159e+07  \n",
       "  4    2.478939e+07  \n",
       "  ..            ...  \n",
       "  180  9.672118e+05  \n",
       "  181  1.260258e+06  \n",
       "  182  1.351720e+06  \n",
       "  183  1.495723e+06  \n",
       "  184  1.539769e+06  \n",
       "  \n",
       "  [185 rows x 16 columns]})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_damage_infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188bac94-5a72-447a-ae22-42da57a6b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def country_analysis_pg(country_code,hazard_type): #\n",
    "    \n",
    "    # extract infrastructure data from gov data\n",
    "    osm_power_infra = extract_pg_infra(country_code,pg_data_path)\n",
    "    osm_damage_infra = assess_damage_pg(country_code,pg_data_country,hazard_type)\n",
    "    \n",
    "    return osm_damage_infra\n",
    "    \n",
    "    \n",
    "osm_damage_infra = country_analysis_pg('LAO','fl') #,'line','PG'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769479e-4a85-4931-af47-fb1ff09b73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gridfinder(country_code):\n",
    "    base_map_path = os.path.join(data_path,'base_map')\n",
    "\n",
    "    cty_boundary_path = os.path.join(base_map_path,'gadm41_{}.gpkg'.format(country_code))\n",
    "    cty_boundary = gpd.read_file(cty_boundary_path)\n",
    "    #mask = pd.DataFrame(mask.copy())\n",
    "    #mask.geometry = pygeos.from_shapely(mask.geometry)\n",
    "    #mask['geometry'] = reproject(mask)\n",
    "\n",
    "    gridfinder_path = r'C:\\Users\\mye500\\OneDrive - Vrije Universiteit Amsterdam\\01_Research-Projects\\01_risk_assessment\\PG_data\\gridfinder\\grid.gpkg'\n",
    "    gridfinder = gpd.read_file(gridfinder_path)\n",
    "    #gridfinder = pd.DataFrame(gridfinder.copy())\n",
    "    #gridfinder.geometry = pygeos.from_shapely(gridfinder.geometry)\n",
    "    #gridfinder['geometry'] = reproject(gridfinder)\n",
    "\n",
    "    clipped = gpd.clip(gridfinder,cty_boundary)\n",
    "\n",
    "    return clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fde70-513a-4898-bbc2-ac8fa3912bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_gridfinder('TWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d93b7-74b5-4ff6-b812-ee1f3bc78aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
