{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a5263e9-087d-4863-a4e5-839dc33017bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from osgeo import ogr,gdal\n",
    "import os\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pyproj\n",
    "from pygeos import from_wkb,from_wkt\n",
    "import pygeos\n",
    "from tqdm import tqdm\n",
    "from shapely.wkb import loads\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from shapely.geometry import mapping\n",
    "pd.options.mode.chained_assignment = None\n",
    "from rasterio.mask import mask\n",
    "#import rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f11a902-f512-4fd3-b035-af38041ee083",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal.SetConfigOption(\"OSM_CONFIG_FILE\", os.path.join('..',\"osmconf.ini\"))\n",
    "\n",
    "# change paths to make it work on your own machine\n",
    "data_path = os.path.join('C:\\\\','data','pg_risk_analysis')\n",
    "tc_path = os.path.join(data_path,'tc_netcdf')\n",
    "fl_path = os.path.join(data_path,'GLOFRIS')\n",
    "osm_data_path = os.path.join('C:\\\\','data','country_osm')\n",
    "pg_data_path = os.path.join(data_path,'pg_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc83d355-8c98-4ae6-97b1-3203a29a4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_b(geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    This function builds an SQL query from the values passed to the retrieve() function.\n",
    "    Arguments:\n",
    "         *geoType* : Type of geometry (osm layer) to search for.\n",
    "         *keyCol* : A list of keys/columns that should be selected from the layer.\n",
    "         ***valConstraint* : A dictionary of constraints for the values. e.g. WHERE 'value'>20 or 'value'='constraint'\n",
    "    Returns:\n",
    "        *string: : a SQL query string.\n",
    "    \"\"\"\n",
    "    query = \"SELECT \" + \"osm_id\"\n",
    "    for a in keyCol: query+= \",\"+ a  \n",
    "    query += \" FROM \" + geoType + \" WHERE \"\n",
    "    # If there are values in the dictionary, add constraint clauses\n",
    "    if valConstraint: \n",
    "        for a in [*valConstraint]:\n",
    "            # For each value of the key, add the constraint\n",
    "            for b in valConstraint[a]: query += a + b\n",
    "        query+= \" AND \"\n",
    "    # Always ensures the first key/col provided is not Null.\n",
    "    query+= \"\"+str(keyCol[0]) +\" IS NOT NULL\" \n",
    "    return query \n",
    "\n",
    "\n",
    "def retrieve(osm_path,geoType,keyCol,**valConstraint):\n",
    "    \"\"\"\n",
    "    Function to extract specified geometry and keys/values from OpenStreetMap\n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.     \n",
    "        *geoType* : Type of Geometry to retrieve. e.g. lines, multipolygons, etc.\n",
    "        *keyCol* : These keys will be returned as columns in the dataframe.\n",
    "        ***valConstraint: A dictionary specifiying the value constraints.  \n",
    "        A key can have multiple values (as a list) for more than one constraint for key/value.  \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all columns, geometries, and constraints specified.    \n",
    "    \"\"\"\n",
    "    driver=ogr.GetDriverByName('OSM')\n",
    "    data = driver.Open(osm_path)\n",
    "    query = query_b(geoType,keyCol,**valConstraint)\n",
    "    sql_lyr = data.ExecuteSQL(query)\n",
    "    features =[]\n",
    "    # cl = columns \n",
    "    cl = ['osm_id'] \n",
    "    for a in keyCol: cl.append(a)\n",
    "    if data is not None:\n",
    "        print('query is finished, lets start the loop')\n",
    "        for feature in tqdm(sql_lyr,desc='extract'):\n",
    "            #try:\n",
    "            if feature.GetField(keyCol[0]) is not None:\n",
    "                geom1 = (feature.geometry().ExportToWkt())\n",
    "                #print(geom1)\n",
    "                geom = from_wkt(feature.geometry().ExportToWkt()) \n",
    "                if geom is None:\n",
    "                    continue\n",
    "                # field will become a row in the dataframe.\n",
    "                field = []\n",
    "                for i in cl: field.append(feature.GetField(i))\n",
    "                field.append(geom)   \n",
    "                features.append(field)\n",
    "            #except:\n",
    "            #    print(\"WARNING: skipped OSM feature\")   \n",
    "    else:\n",
    "        print(\"ERROR: Nonetype error when requesting SQL. Check required.\")    \n",
    "    cl.append('geometry')                   \n",
    "    if len(features) > 0:\n",
    "        return pd.DataFrame(features,columns=cl)\n",
    "    else:\n",
    "        print(\"WARNING: No features or No Memory. returning empty GeoDataFrame\") \n",
    "        return pd.DataFrame(columns=['osm_id','geometry'])\n",
    "\n",
    "def power_polyline(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract all energy linestrings from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'lines',['power','voltage'])\n",
    "    \n",
    "    df = df.reset_index(drop=True).rename(columns={'power': 'asset'})\n",
    "    \n",
    "    #print(df) #check infra keys\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def power_polygon(osm_path): # check with joel, something was wrong here with extracting substations\n",
    "    \"\"\"\n",
    "    Function to extract energy polygons from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['other_tags']) \n",
    "    \n",
    "    df = df.loc[(df.other_tags.str.contains('power'))]   #keep rows containing power data         \n",
    "    df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})     \n",
    "    \n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"substation\"', case=False)]  = 'substation' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"plant\"', case=False)] = 'plant' #specify row\n",
    "    \n",
    "    df = df.loc[(df.asset == 'substation') | (df.asset == 'plant')]\n",
    "            \n",
    "    return df.reset_index(drop=True) \n",
    "\n",
    "def electricity(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract building polygons from OpenStreetMap    \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with all unique building polygons.    \n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['power'])\n",
    "    \n",
    "    df = df.reset_index(drop=True).rename(columns={'power': 'asset'})\n",
    "    \n",
    "    #df = df[df.asset!='generator']\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"substation\"', case=False)]  = 'substation' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"plant\"', case=False)] = 'plant' #specify row\n",
    "    \n",
    "    #print(df)  #check infra keys\n",
    "    \n",
    "    df = df.loc[(df.asset == 'substation') | (df.asset == 'plant')]\n",
    "    \n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def retrieve_poly_subs(osm_path, w_list, b_list):\n",
    "    \"\"\"\n",
    "    Function to extract electricity substation polygons from OpenStreetMap\n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region\n",
    "        for which we want to do the analysis.\n",
    "        *w_list* :  white list of keywords to search in the other_tags columns\n",
    "        *b_list* :  black list of keywords of rows that should not be selected\n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique substation.\n",
    "    \"\"\"\n",
    "    df = retrieve(osm_path,'multipolygons',['other_tags'])\n",
    "    df = df[df.other_tags.str.contains('substation', case=False, na=False)]\n",
    "    #df = df.loc[(df.other_tags.str.contains('substation'))]\n",
    "    df = df[~df.other_tags.str.contains('|'.join(b_list))]\n",
    "    #df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})\n",
    "    df['asset']  = 'substation' #specify row\n",
    "    #df = df.loc[(df.asset == 'substation')] #specify row\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def power_point(osm_path):\n",
    "    \"\"\"\n",
    "    Function to extract energy points from OpenStreetMap  \n",
    "    Arguments:\n",
    "        *osm_path* : file path to the .osm.pbf file of the region \n",
    "        for which we want to do the analysis.        \n",
    "    Returns:\n",
    "        *GeoDataFrame* : a geopandas GeoDataFrame with specified unique energy linestrings.\n",
    "    \"\"\"   \n",
    "    df = retrieve(osm_path,'points',['other_tags']) \n",
    "    df = df.loc[(df.other_tags.str.contains('power'))]  #keep rows containing power data       \n",
    "    df = df.reset_index(drop=True).rename(columns={'other_tags': 'asset'})     \n",
    "    \n",
    "    #print(df)\n",
    "    \n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"tower\"', case=False)]  = 'power_tower' #specify row\n",
    "    df['asset'].loc[df['asset'].str.contains('\"power\"=>\"pole\"', case=False)] = 'power_pole' #specify row\n",
    "    #df['asset'].loc[df['asset'].str.contains('\"utility\"=>\"power\"', case=False)] = 'power_tower' #specify row\n",
    "    \n",
    "    df = df.loc[(df.asset == 'power_tower') | (df.asset == 'power_pole')]\n",
    "            \n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36fe9f2e-0be0-47fd-83ca-67f3a272279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject(df_ds,current_crs=\"epsg:4326\",approximate_crs = \"epsg:3857\"):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        df_ds ([type]): [description]\n",
    "        current_crs (str, optional): [description]. Defaults to \"epsg:3857\".\n",
    "        approximate_crs (str, optional): [description]. Defaults to \"epsg:4326\".\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"    \n",
    "\n",
    "    geometries = df_ds['geometry']\n",
    "    coords = pygeos.get_coordinates(geometries)\n",
    "    transformer=pyproj.Transformer.from_crs(current_crs, approximate_crs,always_xy=True)\n",
    "    new_coords = transformer.transform(coords[:, 0], coords[:, 1])\n",
    "    \n",
    "    return pygeos.set_coordinates(geometries.copy(), np.array(new_coords).T) \n",
    "\n",
    "def load_curves_maxdam(data_path,hazard='wind'): \n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        data_path ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    \n",
    "    if hazard == 'wind':\n",
    "        sheet_name = 'flooding_curves'\n",
    "    elif hazard == 'flood':\n",
    "        sheet_name = 'flooding_curves'\n",
    "    \n",
    "    # load curves and maximum damages as separate inputs\n",
    "    curves = pd.read_excel(data_path,sheet_name=sheet_name,skiprows=8,index_col=[0])\n",
    "    maxdam=pd.read_excel(data_path,sheet_name=sheet_name,index_col=[0]).iloc[:5]\n",
    "    \n",
    "    curves.columns = maxdam.columns\n",
    "\n",
    "    #transpose maxdam so its easier work with the dataframe\n",
    "    maxdam = maxdam.T\n",
    "\n",
    "    #interpolate the curves to fill missing values\n",
    "    curves = curves.interpolate()\n",
    "   \n",
    "    return curves,maxdam\n",
    "\n",
    "def buffer_assets(assets,buffer_size=100):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        assets ([type]): [description]\n",
    "        buffer_size (int, optional): [description]. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"    \n",
    "    assets['buffered'] = pygeos.buffer(assets.geometry.values,buffer_size)\n",
    "    return assets\n",
    "\n",
    "def overlay_hazard_assets(df_ds,assets):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        df_ds ([type]): [description]\n",
    "        assets ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"\n",
    "    #overlay \n",
    "    hazard_tree = pygeos.STRtree(df_ds.geometry.values)\n",
    "    if (pygeos.get_type_id(assets.iloc[0].geometry) == 3) | (pygeos.get_type_id(assets.iloc[0].geometry) == 6):\n",
    "        return  hazard_tree.query_bulk(assets.geometry,predicate='intersects')    \n",
    "    else:\n",
    "        return  hazard_tree.query_bulk(assets.buffered,predicate='intersects')\n",
    "    \n",
    "def get_damage_per_asset_per_rp(asset,df_ds,assets,curves,maxdam,return_period,country):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        asset ([type]): [description]\n",
    "        df_ds ([type]): [description]\n",
    "        assets ([type]): [description]\n",
    "        grid_size (int, optional): [description]. Defaults to 90.\n",
    "\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"    \n",
    "\n",
    "    # find the exact hazard overlays:\n",
    "    get_hazard_points = df_ds.iloc[asset[1]['hazard_point'].values].reset_index()\n",
    "    get_hazard_points = get_hazard_points.loc[pygeos.intersects(get_hazard_points.geometry.values,assets.iloc[asset[0]].geometry)]\n",
    "\n",
    "    asset_type = assets.iloc[asset[0]].asset\n",
    "    asset_geom = assets.iloc[asset[0]].geometry\n",
    "\n",
    "    if asset_type in ['plant','substation','generator']:\n",
    "        maxdam_asset = maxdam.loc[asset_type].MaxDam/pygeos.area(asset_geom)\n",
    "    else:\n",
    "        maxdam_asset = maxdam.loc[asset_type].MaxDam\n",
    "\n",
    "\n",
    "    hazard_intensity = curves[asset_type].index.values\n",
    "    fragility_values = curves[asset_type].values\n",
    "    \n",
    "    if len(get_hazard_points) == 0:\n",
    "        return asset[0],0\n",
    "    else:\n",
    "        \n",
    "        if pygeos.get_type_id(asset_geom) == 1:\n",
    "            get_hazard_points['overlay_meters'] = pygeos.length(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            return asset[0],np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,fragility_values))*get_hazard_points.overlay_meters*maxdam_asset)\n",
    "        \n",
    "        elif  pygeos.get_type_id(asset_geom) == 3:\n",
    "            get_hazard_points['overlay_m2'] = pygeos.area(pygeos.intersection(get_hazard_points.geometry.values,asset_geom))\n",
    "            return asset[0],get_hazard_points.apply(lambda x: np.interp(x[return_period], hazard_intensity, fragility_values)*maxdam_asset*x.overlay_m2,axis=1).sum()     \n",
    "        \n",
    "        else:\n",
    "            return asset[0],np.sum((np.interp(get_hazard_points[return_period].values,hazard_intensity,fragility_values))*maxdam_asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0988af3-3666-4ae7-a052-c0c0a6ef85e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_storm_data(climate_model):\n",
    "    \n",
    "    with xr.open_dataset(os.path.join(tc_path,'STORM_FIXED_RETURN_PERIODS{}_WP.nc'.format(climate_model))) as ds:\n",
    "        \"\"\"\n",
    "        TC climate model:\n",
    "            CMCC-CM2-VHR4\n",
    "            CNRM-CM6-1-HR\n",
    "            EC-Earth3P-HR\n",
    "            HadGEM3-GC31-HM\n",
    "        \"\"\"\n",
    "        \n",
    "        # get the mean values\n",
    "        df_ds = ds['mean'].to_dataframe().unstack(level=2).reset_index()\n",
    "\n",
    "        # create geometry values and drop lat lon columns\n",
    "        df_ds['geometry'] = [pygeos.points(x) for x in list(zip(df_ds['lon'],df_ds['lat']))]\n",
    "        df_ds = df_ds.drop(['lat','lon'],axis=1,level=0)\n",
    "        #print(df_ds)\n",
    "        \n",
    "        #rename columns to return periods\n",
    "        return_periods = ['1_{}{}'.format(int(x),climate_model) for x in ds['rp']]\n",
    "        df_ds.columns = ['1_{}{}'.format(int(x),climate_model) for x in list(df_ds.columns.get_level_values(1))[:-1]]+['geometry']     \n",
    "        df_ds['geometry'] = pygeos.buffer(df_ds.geometry,radius=0.1/2,cap_style='square').values\n",
    "        df_ds['geometry'] = reproject(df_ds)\n",
    "            \n",
    "        # drop all non values to reduce size\n",
    "        #if climate_model == '':\n",
    "        #    df_ds = df_ds.loc[~df_ds['1_10000'].isna()].reset_index(drop=True)\n",
    "        \n",
    "        df_ds = df_ds.loc[~df_ds['1_10000{}'.format(climate_model)].isna()].reset_index(drop=True)\n",
    "        df_ds = df_ds.fillna(0)\n",
    "        df_ds = df_ds[['1_{}{}'.format(int(x),climate_model) for x in [10,50,100,500,1000]]+['geometry']]\n",
    "        #print(df_ds)\n",
    "\n",
    "    return df_ds\n",
    "\n",
    "# load hazard data \n",
    "def extract_wind_data():\n",
    "    climate_models = ['_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "    df_ds = {}\n",
    "    for climate_model in climate_models:\n",
    "        df_ds_cl = open_storm_data(climate_model)\n",
    "        df_ds[climate_model] = df_ds_cl\n",
    "    \n",
    "    return df_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e201351c-2a6f-453e-94da-57c68ed804b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_10_CMCC-CM2-VHR4</th>\n",
       "      <th>1_50_CMCC-CM2-VHR4</th>\n",
       "      <th>1_100_CMCC-CM2-VHR4</th>\n",
       "      <th>1_500_CMCC-CM2-VHR4</th>\n",
       "      <th>1_1000_CMCC-CM2-VHR4</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.212739</td>\n",
       "      <td>19.212739</td>\n",
       "      <td>19.212739</td>\n",
       "      <td>19.212739</td>\n",
       "      <td>19.212739</td>\n",
       "      <td>POLYGON ((11143081.028 568480.588, 11143081.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.759801</td>\n",
       "      <td>19.759801</td>\n",
       "      <td>19.759801</td>\n",
       "      <td>19.759801</td>\n",
       "      <td>19.759801</td>\n",
       "      <td>POLYGON ((11154212.977 568480.588, 11154212.97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.745395</td>\n",
       "      <td>19.745395</td>\n",
       "      <td>19.745395</td>\n",
       "      <td>19.745395</td>\n",
       "      <td>19.745395</td>\n",
       "      <td>POLYGON ((11165344.927 568480.588, 11165344.92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.615344</td>\n",
       "      <td>18.615344</td>\n",
       "      <td>18.615344</td>\n",
       "      <td>18.615344</td>\n",
       "      <td>18.615344</td>\n",
       "      <td>POLYGON ((11176476.876 568480.588, 11176476.87...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.845578</td>\n",
       "      <td>19.845578</td>\n",
       "      <td>19.845578</td>\n",
       "      <td>19.845578</td>\n",
       "      <td>19.845578</td>\n",
       "      <td>POLYGON ((11187608.825 568480.588, 11187608.82...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384730</th>\n",
       "      <td>18.237884</td>\n",
       "      <td>18.237884</td>\n",
       "      <td>18.237884</td>\n",
       "      <td>19.609745</td>\n",
       "      <td>23.423505</td>\n",
       "      <td>POLYGON ((20004112.496 8399737.89, 20004112.49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384731</th>\n",
       "      <td>18.080329</td>\n",
       "      <td>18.080329</td>\n",
       "      <td>18.080329</td>\n",
       "      <td>19.692856</td>\n",
       "      <td>23.656502</td>\n",
       "      <td>POLYGON ((20015244.445 8399737.89, 20015244.44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384732</th>\n",
       "      <td>18.070724</td>\n",
       "      <td>18.070724</td>\n",
       "      <td>18.070724</td>\n",
       "      <td>19.649922</td>\n",
       "      <td>23.449598</td>\n",
       "      <td>POLYGON ((20026376.394 8399737.89, 20026376.39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384733</th>\n",
       "      <td>18.192747</td>\n",
       "      <td>18.192747</td>\n",
       "      <td>18.192747</td>\n",
       "      <td>19.393939</td>\n",
       "      <td>23.184443</td>\n",
       "      <td>POLYGON ((20037508.343 8399737.89, 20037508.34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384734</th>\n",
       "      <td>18.122295</td>\n",
       "      <td>18.122295</td>\n",
       "      <td>18.122295</td>\n",
       "      <td>19.304801</td>\n",
       "      <td>23.242072</td>\n",
       "      <td>POLYGON ((-20026376.394 8399737.89, -20026376....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384735 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1_10_CMCC-CM2-VHR4  1_50_CMCC-CM2-VHR4  1_100_CMCC-CM2-VHR4  \\\n",
       "0                19.212739           19.212739            19.212739   \n",
       "1                19.759801           19.759801            19.759801   \n",
       "2                19.745395           19.745395            19.745395   \n",
       "3                18.615344           18.615344            18.615344   \n",
       "4                19.845578           19.845578            19.845578   \n",
       "...                    ...                 ...                  ...   \n",
       "384730           18.237884           18.237884            18.237884   \n",
       "384731           18.080329           18.080329            18.080329   \n",
       "384732           18.070724           18.070724            18.070724   \n",
       "384733           18.192747           18.192747            18.192747   \n",
       "384734           18.122295           18.122295            18.122295   \n",
       "\n",
       "        1_500_CMCC-CM2-VHR4  1_1000_CMCC-CM2-VHR4  \\\n",
       "0                 19.212739             19.212739   \n",
       "1                 19.759801             19.759801   \n",
       "2                 19.745395             19.745395   \n",
       "3                 18.615344             18.615344   \n",
       "4                 19.845578             19.845578   \n",
       "...                     ...                   ...   \n",
       "384730            19.609745             23.423505   \n",
       "384731            19.692856             23.656502   \n",
       "384732            19.649922             23.449598   \n",
       "384733            19.393939             23.184443   \n",
       "384734            19.304801             23.242072   \n",
       "\n",
       "                                                 geometry  \n",
       "0       POLYGON ((11143081.028 568480.588, 11143081.02...  \n",
       "1       POLYGON ((11154212.977 568480.588, 11154212.97...  \n",
       "2       POLYGON ((11165344.927 568480.588, 11165344.92...  \n",
       "3       POLYGON ((11176476.876 568480.588, 11176476.87...  \n",
       "4       POLYGON ((11187608.825 568480.588, 11187608.82...  \n",
       "...                                                   ...  \n",
       "384730  POLYGON ((20004112.496 8399737.89, 20004112.49...  \n",
       "384731  POLYGON ((20015244.445 8399737.89, 20015244.44...  \n",
       "384732  POLYGON ((20026376.394 8399737.89, 20026376.39...  \n",
       "384733  POLYGON ((20037508.343 8399737.89, 20037508.34...  \n",
       "384734  POLYGON ((-20026376.394 8399737.89, -20026376....  \n",
       "\n",
       "[384735 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_storm_data('_CMCC-CM2-VHR4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c7ff6dd-a3f2-4e2a-becd-e5cffa38edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_flood_data(country_code,time_period='HIST'):\n",
    "     \n",
    "    # load country geometry file and create geometry to clip\n",
    "    ne_countries = gpd.read_file('C:\\\\Data\\\\natural_earth\\\\ne_10m_admin_0_countries.shp') \n",
    "    geometry = ne_countries.loc[ne_countries['ISO_A3']==country_code].geometry.values[0]\n",
    "    geoms = [mapping(geometry)]\n",
    "    \n",
    "    rps = ['0010','0050','0100','0500','1000']\n",
    "    for rp in rps: \n",
    "        input_file = os.path.join(fl_path,time_period,'global',\n",
    "                                  'inuncoast_historical_nosub_hist_rp{}_0.tif'.format(rp))\n",
    "\n",
    "        # load raster file and save clipped version\n",
    "        with rasterio.open(input_file) as src:\n",
    "            out_image, out_transform = mask(src, geoms, crop=True) #rasterio.mask.mask(src, geoms, crop=True)\n",
    "            out_meta = src.meta\n",
    "\n",
    "            out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": out_image.shape[1],\n",
    "                     \"width\": out_image.shape[2],\n",
    "                     \"transform\": out_transform})\n",
    "\n",
    "            file_path = os.path.join(fl_path,time_period,'country',\n",
    "                                            '_'.join([country_code]+input_file.split('_')[3:]))\n",
    "            \n",
    "            with rasterio.open(file_path, \"w\", **out_meta) as dest:\n",
    "                dest.write(out_image) \n",
    "\n",
    "def open_flood_data(country_code,time_period='HIST'):\n",
    "    \"\"\"\n",
    "    # THIS STILL NEEDS TO BE TESTED WITH GLOFRIS DATA\n",
    "    with xr.open_dataset(os.path.join(fl_path)) as ds: #, engine=\"rasterio\"  | ,'HIST/inuncoast_historical_nosub_hist_rp0500_0.nc'\n",
    "        df_ds = ds.to_dataframe().reset_index()\n",
    "        df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "        df_ds = df_ds.rename(columns={'band_data': 'hazard_intensity'})\n",
    "        df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "        df_ds = df_ds.dropna()\n",
    "        df_ds = df_ds.reset_index(drop=True)\n",
    "        df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=20/2,cap_style='square').values\n",
    "        df_ds['geometry'] = reproject(df_ds)\n",
    "    \"\"\"    \n",
    "        \n",
    "    files = [x for x in os.listdir(os.path.join(fl_path,time_period,'country'))  if country_code in x ]\n",
    "\n",
    "    collect_df_ds = [] \n",
    "    for file in files: \n",
    "\n",
    "        file_path = os.path.join(fl_path,time_period,'country',file)\n",
    "\n",
    "        with xr.open_dataset(file_path) as ds: #, engine=\"rasterio\"\n",
    "            df_ds = ds.to_dataframe().reset_index()\n",
    "            df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "            df_ds = df_ds.rename(columns={'band_data': file.split('_')[4]}) #rename to return period\n",
    "            df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "            df_ds = df_ds.dropna()\n",
    "            df_ds = df_ds.reset_index(drop=True)\n",
    "            df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=20/2,cap_style='square').values\n",
    "            df_ds['geometry'] = reproject(df_ds)\n",
    "            collect_df_ds.append(df_ds)\n",
    "\n",
    "    df_all = collect_df_ds[0].merge(collect_df_ds[1]).merge(collect_df_ds[2]).merge(collect_df_ds[3]).merge(collect_df_ds[4])\n",
    "    \n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "026be916-0307-424e-b44f-e92ea59bbe8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rp0010</th>\n",
       "      <th>geometry</th>\n",
       "      <th>rp0050</th>\n",
       "      <th>rp0100</th>\n",
       "      <th>rp0500</th>\n",
       "      <th>rp1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((12256739.768 3550231.461, 12256739.7...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((12256739.768 3549156.386, 12256739.7...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((12256739.768 3548081.403, 12256739.7...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((12256739.768 3547006.51, 12256739.76...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((12256739.768 3545931.71, 12256739.76...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280983</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((13097201.923 2900842.81, 13097201.92...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((13098129.585 2909047.237, 13098129.5...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280985</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((13098129.585 2908021.438, 13098129.5...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((13098129.585 2906995.709, 13098129.5...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280987</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((13098129.585 2905970.05, 13098129.58...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280988 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rp0010                                           geometry  rp0050  \\\n",
       "0          0.0  POLYGON ((12256739.768 3550231.461, 12256739.7...     0.0   \n",
       "1          0.0  POLYGON ((12256739.768 3549156.386, 12256739.7...     0.0   \n",
       "2          0.0  POLYGON ((12256739.768 3548081.403, 12256739.7...     0.0   \n",
       "3          0.0  POLYGON ((12256739.768 3547006.51, 12256739.76...     0.0   \n",
       "4          0.0  POLYGON ((12256739.768 3545931.71, 12256739.76...     0.0   \n",
       "...        ...                                                ...     ...   \n",
       "280983     0.0  POLYGON ((13097201.923 2900842.81, 13097201.92...     0.0   \n",
       "280984     0.0  POLYGON ((13098129.585 2909047.237, 13098129.5...     0.0   \n",
       "280985     0.0  POLYGON ((13098129.585 2908021.438, 13098129.5...     0.0   \n",
       "280986     0.0  POLYGON ((13098129.585 2906995.709, 13098129.5...     0.0   \n",
       "280987     0.0  POLYGON ((13098129.585 2905970.05, 13098129.58...     0.0   \n",
       "\n",
       "        rp0100  rp0500  rp1000  \n",
       "0          0.0     0.0     0.0  \n",
       "1          0.0     0.0     0.0  \n",
       "2          0.0     0.0     0.0  \n",
       "3          0.0     0.0     0.0  \n",
       "4          0.0     0.0     0.0  \n",
       "...        ...     ...     ...  \n",
       "280983     0.0     0.0     0.0  \n",
       "280984     0.0     0.0     0.0  \n",
       "280985     0.0     0.0     0.0  \n",
       "280986     0.0     0.0     0.0  \n",
       "280987     0.0     0.0     0.0  \n",
       "\n",
       "[280988 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_flood_data('LAO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dab73528-7a6d-4f68-8723-874b972d8169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 37.3 s\n",
      "Wall time: 37.4 s\n"
     ]
    }
   ],
   "source": [
    "# can be deleted\n",
    "%%time\n",
    "fl_path = 'C:\\Data\\pg_risk_analysis\\GLOFRIS'\n",
    "time_period = 'HIST'\n",
    "country_code = 'LAO'\n",
    "\n",
    "files = [x for x in os.listdir(os.path.join(fl_path,time_period,'country'))  if country_code in x ]\n",
    "\n",
    "collect_df_ds = [] \n",
    "for file in files: \n",
    "\n",
    "    file_path = os.path.join(fl_path,time_period,'country',file)\n",
    "\n",
    "    with xr.open_dataset(file_path) as ds: #, engine=\"rasterio\"\n",
    "        df_ds = ds.to_dataframe().reset_index()\n",
    "        df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "        df_ds = df_ds.rename(columns={'band_data': file.split('_')[4]}) #rename to return period\n",
    "        df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "        df_ds = df_ds.dropna()\n",
    "        df_ds = df_ds.reset_index(drop=True)\n",
    "        df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=20/2,cap_style='square').values\n",
    "        df_ds['geometry'] = reproject(df_ds)\n",
    "        collect_df_ds.append(df_ds)\n",
    "        \n",
    "df_all = collect_df_ds[0].merge(collect_df_ds[1]).merge(collect_df_ds[2]).merge(collect_df_ds[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "749ee196-e3a1-427b-9592-d44d5e2a6ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rp0010</th>\n",
       "      <th>geometry</th>\n",
       "      <th>rp0050</th>\n",
       "      <th>rp0100</th>\n",
       "      <th>rp0500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((12256739.768 3550231.461, 12256739.7...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((12256739.768 3549156.386, 12256739.7...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((12256739.768 3548081.403, 12256739.7...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((12256739.768 3547006.51, 12256739.76...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((12256739.768 3545931.71, 12256739.76...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280983</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((13097201.923 2900842.81, 13097201.92...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((13098129.585 2909047.237, 13098129.5...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280985</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((13098129.585 2908021.438, 13098129.5...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((13098129.585 2906995.709, 13098129.5...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280987</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((13098129.585 2905970.05, 13098129.58...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280988 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rp0010                                           geometry  rp0050  \\\n",
       "0          0.0  POLYGON ((12256739.768 3550231.461, 12256739.7...     0.0   \n",
       "1          0.0  POLYGON ((12256739.768 3549156.386, 12256739.7...     0.0   \n",
       "2          0.0  POLYGON ((12256739.768 3548081.403, 12256739.7...     0.0   \n",
       "3          0.0  POLYGON ((12256739.768 3547006.51, 12256739.76...     0.0   \n",
       "4          0.0  POLYGON ((12256739.768 3545931.71, 12256739.76...     0.0   \n",
       "...        ...                                                ...     ...   \n",
       "280983     0.0  POLYGON ((13097201.923 2900842.81, 13097201.92...     0.0   \n",
       "280984     0.0  POLYGON ((13098129.585 2909047.237, 13098129.5...     0.0   \n",
       "280985     0.0  POLYGON ((13098129.585 2908021.438, 13098129.5...     0.0   \n",
       "280986     0.0  POLYGON ((13098129.585 2906995.709, 13098129.5...     0.0   \n",
       "280987     0.0  POLYGON ((13098129.585 2905970.05, 13098129.58...     0.0   \n",
       "\n",
       "        rp0100  rp0500  \n",
       "0          0.0     0.0  \n",
       "1          0.0     0.0  \n",
       "2          0.0     0.0  \n",
       "3          0.0     0.0  \n",
       "4          0.0     0.0  \n",
       "...        ...     ...  \n",
       "280983     0.0     0.0  \n",
       "280984     0.0     0.0  \n",
       "280985     0.0     0.0  \n",
       "280986     0.0     0.0  \n",
       "280987     0.0     0.0  \n",
       "\n",
       "[280988 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad63938b-fd93-45ab-9515-bd7ed46edc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be deleted\n",
    "with xr.open_dataset(file_path) as ds: #, engine=\"rasterio\"\n",
    "    df_ds = ds.to_dataframe().reset_index()\n",
    "    df_ds['geometry'] = pygeos.points(df_ds.x,y=df_ds.y)\n",
    "    df_ds = df_ds.rename(columns={'band_data': 'hazard_intensity'})\n",
    "    df_ds = df_ds.drop(['band','x', 'y','spatial_ref'], axis=1)\n",
    "    df_ds = df_ds.dropna()\n",
    "    df_ds = df_ds.reset_index(drop=True)\n",
    "    df_ds.geometry= pygeos.buffer(df_ds.geometry,radius=20/2,cap_style='square').values\n",
    "    df_ds['geometry'] = reproject(df_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "020a06c6-b91d-4f1a-a4a7-58df28aff382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hazard_intensity</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((12256739.768 3550231.461, 12256739.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((12256739.768 3549156.386, 12256739.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((12256739.768 3548081.403, 12256739.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((12256739.768 3547006.51, 12256739.76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((12256739.768 3545931.71, 12256739.76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280983</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((13097201.923 2900842.81, 13097201.92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((13098129.585 2909047.237, 13098129.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280985</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((13098129.585 2908021.438, 13098129.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((13098129.585 2906995.709, 13098129.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280987</th>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((13098129.585 2905970.05, 13098129.58...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280988 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hazard_intensity                                           geometry\n",
       "0                    0.0  POLYGON ((12256739.768 3550231.461, 12256739.7...\n",
       "1                    0.0  POLYGON ((12256739.768 3549156.386, 12256739.7...\n",
       "2                    0.0  POLYGON ((12256739.768 3548081.403, 12256739.7...\n",
       "3                    0.0  POLYGON ((12256739.768 3547006.51, 12256739.76...\n",
       "4                    0.0  POLYGON ((12256739.768 3545931.71, 12256739.76...\n",
       "...                  ...                                                ...\n",
       "280983               0.0  POLYGON ((13097201.923 2900842.81, 13097201.92...\n",
       "280984               0.0  POLYGON ((13098129.585 2909047.237, 13098129.5...\n",
       "280985               0.0  POLYGON ((13098129.585 2908021.438, 13098129.5...\n",
       "280986               0.0  POLYGON ((13098129.585 2906995.709, 13098129.5...\n",
       "280987               0.0  POLYGON ((13098129.585 2905970.05, 13098129.58...\n",
       "\n",
       "[280988 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3de688-606c-4dd2-abe3-f37015c7442e",
   "metadata": {},
   "source": [
    "# OSM data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "934161b6-5f01-4315-87b3-9e4a7bd70876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|██████████████████████████████████████████████████████████████████████| 447/447 [00:02<00:00, 159.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|█████████████████████████████████████████████████████████████████████████| 25/25 [00:08<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query is finished, lets start the loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|█████████████████████████████████████████████████████████████████| 45489/45489 [00:04<00:00, 9699.07it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_osm_infrastructure(country_code,osm_data_path):\n",
    "\n",
    "    # lines\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    power_lines_country = power_polyline(osm_path)\n",
    "    power_lines_country['geometry'] = reproject(power_lines_country)\n",
    "    power_lines_country = buffer_assets(power_lines_country.loc[power_lines_country.asset.isin(\n",
    "        ['cable','minor_cable','line','minor_line'])],buffer_size=100).reset_index(drop=True)\n",
    "    \n",
    "    # polygons\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    power_poly_country = electricity(osm_path)\n",
    "    power_poly_country['geometry'] = reproject(power_poly_country)\n",
    "    \n",
    "    # points\n",
    "    osm_path = os.path.join(osm_data_path,'{}.osm.pbf'.format(country_code))\n",
    "    power_points_country = power_point(osm_path)\n",
    "    power_points_country['geometry'] = reproject(power_points_country)\n",
    "    power_points_country = buffer_assets(power_points_country.loc[power_points_country.asset.isin(\n",
    "        ['power_tower','power_pole'])],buffer_size=100).reset_index(drop=True)\n",
    "\n",
    "    return power_lines_country,power_poly_country,power_points_country\n",
    "\n",
    "\n",
    "ctry_power_infra = extract_osm_infrastructure('LAO',osm_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc58d66c-58a8-421c-b264-6e74c0b53b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ctry_power_infra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "abb7a943-1950-445c-8328-f6db95b7f163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "polyline damage calculation for LAO: 100%|███████████████████████████████████████████| 345/345 [00:06<00:00, 51.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rp0010', (0, 1201767797.788254)]\n"
     ]
    }
   ],
   "source": [
    "def assess_damage_osm(country_code,ctry_power_infra,hazard_type='tc'):\n",
    "    \n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(data_path=os.path.join('..','data','infra_vulnerability_data.xlsx'))\n",
    "    curves['line'] = 1 # remove this when things work!\n",
    "    \n",
    "    # read infrastructure data:\n",
    "    power_lines,power_poly,power_points = ctry_power_infra\n",
    "    \n",
    "    if hazard_type=='tc':\n",
    "        # read wind data\n",
    "        climate_models = ['_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "        df_ds = extract_wind_data()\n",
    "        \"\"\"    \n",
    "        # calculate damaged lines in loop by country_code and climate_model\n",
    "        damaged_lines = {}\n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['1_10{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                              '1_100{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "\n",
    "            overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],\n",
    "                                                               power_lines).T,columns=['asset','hazard_point'])\n",
    "            collect_line_damages = []\n",
    "            for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                              desc='polyline damage calculation for {} {}'.format(country_code,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_line_damages.append([return_period,get_damage_per_asset_per_rp(asset,df_ds[climate_model],\n",
    "                                                                                           power_lines,\n",
    "                                                                                           curves,\n",
    "                                                                                           maxdam,\n",
    "                                                                                           return_period,\n",
    "                                                                                           country_code)])\n",
    "\n",
    "        collect_line_damages = [(line[0],line[1][0],line[1][1]) for line in collect_line_damages]\n",
    "        damaged_lines_country = power_lines.merge(pd.DataFrame(collect_line_damages,\n",
    "                                                                                 columns=['return_period','index','damage']),\n",
    "                                                                    left_index=True,right_on='index')\n",
    "        damaged_lines_country = damaged_lines_country.drop(['buffered'],axis=1)\n",
    "        damaged_lines[climate_model] = damaged_lines_country\n",
    "        \"\"\"\n",
    "        # calculate damaged polygons in loop by country_code and climate_model\n",
    "        damaged_poly = {}\n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['1_10{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                              '1_100{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "\n",
    "            overlay_poly = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],power_poly).T,\n",
    "                                                              columns=['asset','hazard_point'])\n",
    "            collect_poly_damages = []\n",
    "            for asset in tqdm(overlay_poly.groupby('asset'),total=len(overlay_poly.asset.unique()),desc='polygon damage calculation for {} {}'.format(country_code,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_poly_damages.append([return_period,get_damage_per_asset_per_rp(asset,df_ds[climate_model],\n",
    "                                                                                           power_poly,\n",
    "                                                                                           curves,maxdam,\n",
    "                                                                                           return_period,\n",
    "                                                                                           country_code)])\n",
    "\n",
    "            collect_poly_damages = [(line[0],line[1][0],line[1][1]) for line in collect_poly_damages]\n",
    "            print(collect_poly_damages[0])\n",
    "            damaged_poly_country = power_poly.merge(pd.DataFrame(collect_poly_damages,columns=['return_period','index','damage']),left_index=True,right_on='index')\n",
    "            damaged_poly[climate_model] = damaged_poly_country\n",
    "        \"\"\"\n",
    "        # calculate damaged points in loop by country_code and climate_model\n",
    "        damaged_points = {}\n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['1_10{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                              '1_100{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "\n",
    "            overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],power_points).T,\n",
    "                                          columns=['asset','hazard_point'])\n",
    "            collect_point_damages = []\n",
    "            for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),desc='point damage calculation for {} {}'.format(country_code,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_point_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                            df_ds[climate_model],\n",
    "                                                                                            power_points,\n",
    "                                                                                            curves,\n",
    "                                                                                            maxdam,\n",
    "                                                                                            return_period,\n",
    "                                                                                            country_code)])\n",
    "\n",
    "            collect_point_damages = [(line[0],line[1][0],line[1][1]) for line in collect_point_damages]\n",
    "            damaged_points_country = power_points.merge(pd.DataFrame(collect_point_damages,columns=['return_period','index','damage']),left_index=True,right_on='index')\n",
    "            damaged_points_country = damaged_points_country.drop(['buffered'],axis=1)\n",
    "            damaged_points[climate_model] = damaged_points_country\n",
    "            \"\"\"\n",
    "        \n",
    "    elif hazard_type=='fl':\n",
    "        # read flood data\n",
    "        df_ds = open_flood_data(country_code).head(50) # REMOVE .HEAD()\n",
    "        #time_periods = []\n",
    "        \n",
    "        #for time_period in time_periods:\n",
    "        return_periods = ['rp0010','rp0050','rp0100','rp0500','rp1000']\n",
    "        \n",
    "        # calculate damaged lines in loop by country_code and climate_model\n",
    "        damaged_lines = {}\n",
    "        overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds,power_lines).T,columns=['asset','hazard_point'])\n",
    "        collect_line_damages = []\n",
    "        for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                          desc='polyline damage calculation for {}'.format(country_code)):\n",
    "            for return_period in return_periods:\n",
    "                collect_line_damages.append([return_period,get_damage_per_asset_per_rp(asset,df_ds,\n",
    "                                                                                       power_lines,\n",
    "                                                                                       curves,\n",
    "                                                                                       maxdam,\n",
    "                                                                                       return_period,\n",
    "                                                                                       country_code)])\n",
    "\n",
    "        print(collect_line_damages[0])\n",
    "        collect_line_damages = [(line[0],line[1][0],line[1][1]) for line in collect_line_damages]\n",
    "        damaged_lines = power_lines.merge(pd.DataFrame(collect_line_damages,\n",
    "                                                                                 columns=['return_period','index','damage']),\n",
    "                                                                    left_index=True,right_on='index')\n",
    "        damaged_lines = damaged_lines_country.drop(['buffered'],axis=1)\n",
    "        \"\"\"\n",
    "        # calculate damaged polygons in loop by country_code and climate_model\n",
    "        damaged_poly = {}\n",
    "        overlay_poly = pd.DataFrame(overlay_hazard_assets(df_ds,power_poly).T,\n",
    "                                                          columns=['asset','hazard_point'])\n",
    "        collect_poly_damages = []\n",
    "        for asset in tqdm(overlay_poly.groupby('asset'),total=len(overlay_poly.asset.unique()),desc='polygon damage calculation for {}'.format(country_code)):\n",
    "            for return_period in return_periods:\n",
    "                collect_poly_damages.append([return_period,get_damage_per_asset_per_rp(asset,df_ds,\n",
    "                                                                                       power_poly,\n",
    "                                                                                       curves,maxdam,\n",
    "                                                                                       return_period,\n",
    "                                                                                       country_code)])\n",
    "\n",
    "            collect_poly_damages = [(line[0],line[1][0],line[1][1]) for line in collect_poly_damages]\n",
    "            print(collect_poly_damages[0])\n",
    "            damaged_poly = power_poly.merge(pd.DataFrame(collect_poly_damages,columns=['return_period','index','damage']),left_index=True,right_on='index')\n",
    "        \n",
    "        # calculate damaged points in loop by country_code and climate_model\n",
    "        damaged_points = {}\n",
    "        overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds,power_points).T,\n",
    "                                      columns=['asset','hazard_point'])\n",
    "        collect_point_damages = []\n",
    "        for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),desc='point damage calculation for {}'.format(country_code)):\n",
    "            for return_period in return_periods:\n",
    "                collect_point_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                        df_ds,\n",
    "                                                                                        power_points,\n",
    "                                                                                        curves,\n",
    "                                                                                        maxdam,\n",
    "                                                                                        return_period,\n",
    "                                                                                        country_code)])\n",
    "\n",
    "            print(collect_point_damages[1][1])\n",
    "            collect_point_damages = [(line[0],line[1][0],line[1][1]) for line in collect_point_damages]\n",
    "            damaged_points = power_points.merge(pd.DataFrame(collect_point_damages,columns=['return_period','index','damage']),left_index=True,right_on='index')\n",
    "            damaged_points = damaged_points_country.drop(['buffered'],axis=1)\n",
    "            \"\"\"\n",
    "\n",
    "    #return damaged_lines,damaged_poly,damaged_points\n",
    "    return damaged_lines\n",
    "\n",
    "ctry_damage_infra = assess_damage_osm('LAO',ctry_power_infra,'fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c5f06-2b02-486a-afe9-9cb9807d5819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_analysis_osm(country_code,exposure_data='OSM',hazard_type='tc'): #\n",
    "    \n",
    "    if exposure_data == 'OSM':\n",
    "        # extract infrastructure data from OSM\n",
    "        ctry_power_infra = extract_osm_infrastructure(country_code,osm_data_path)\n",
    "\n",
    "        # extract wind data\n",
    "        # df_ds = extract_wind_data()\n",
    "    \n",
    "        # assess damage to wind storms\n",
    "        #climate_models = ['_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "        ctry_damage_infra = assess_damage_osm(country_code,ctry_power_infra,hazard_type)\n",
    "    \n",
    "        return ctry_damage_infra\n",
    "    \"\"\"\n",
    "    elif exposure_data == 'PG':\n",
    "        # extract power grid data\n",
    "        ctry_power_infra = extract_pg_data(country_code,pg_type)\n",
    "\n",
    "        # extract wind data\n",
    "        df_ds = extract_wind_data()\n",
    "    \n",
    "        # assess damage to wind storms\n",
    "        climate_models = ['_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "        ctry_damage_infra = assess_damage_infrastructure(country_code,ctry_power_infra,climate_models)\n",
    "    \n",
    "        return ctry_damage_infra\n",
    "        \"\"\"\n",
    "\n",
    "ctry_damage_infra = country_analysis_osm('LAO') #,'line','PG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b093416a-4b36-4f15-affe-2b78c4942c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osm_id</th>\n",
       "      <th>asset</th>\n",
       "      <th>geometry</th>\n",
       "      <th>return_period</th>\n",
       "      <th>index</th>\n",
       "      <th>damage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>plant</td>\n",
       "      <td>MULTIPOLYGON (((11440952.95 2125594.573, 11440...</td>\n",
       "      <td>1_10_CNRM-CM6-1-HR</td>\n",
       "      <td>0</td>\n",
       "      <td>2989.453138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>plant</td>\n",
       "      <td>MULTIPOLYGON (((11440952.95 2125594.573, 11440...</td>\n",
       "      <td>1_50_CNRM-CM6-1-HR</td>\n",
       "      <td>0</td>\n",
       "      <td>3593.237462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>plant</td>\n",
       "      <td>MULTIPOLYGON (((11440952.95 2125594.573, 11440...</td>\n",
       "      <td>1_100_CNRM-CM6-1-HR</td>\n",
       "      <td>0</td>\n",
       "      <td>3867.059570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>plant</td>\n",
       "      <td>MULTIPOLYGON (((11440952.95 2125594.573, 11440...</td>\n",
       "      <td>1_500_CNRM-CM6-1-HR</td>\n",
       "      <td>0</td>\n",
       "      <td>4374.063048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>plant</td>\n",
       "      <td>MULTIPOLYGON (((11440952.95 2125594.573, 11440...</td>\n",
       "      <td>1_1000_CNRM-CM6-1-HR</td>\n",
       "      <td>0</td>\n",
       "      <td>4639.178446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>None</td>\n",
       "      <td>plant</td>\n",
       "      <td>MULTIPOLYGON (((11832832.657 1731959.498, 1183...</td>\n",
       "      <td>1_10_CNRM-CM6-1-HR</td>\n",
       "      <td>21</td>\n",
       "      <td>1931.199196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>None</td>\n",
       "      <td>plant</td>\n",
       "      <td>MULTIPOLYGON (((11832832.657 1731959.498, 1183...</td>\n",
       "      <td>1_50_CNRM-CM6-1-HR</td>\n",
       "      <td>21</td>\n",
       "      <td>2670.295005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>None</td>\n",
       "      <td>plant</td>\n",
       "      <td>MULTIPOLYGON (((11832832.657 1731959.498, 1183...</td>\n",
       "      <td>1_100_CNRM-CM6-1-HR</td>\n",
       "      <td>21</td>\n",
       "      <td>2890.193758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>None</td>\n",
       "      <td>plant</td>\n",
       "      <td>MULTIPOLYGON (((11832832.657 1731959.498, 1183...</td>\n",
       "      <td>1_500_CNRM-CM6-1-HR</td>\n",
       "      <td>21</td>\n",
       "      <td>3190.366191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>None</td>\n",
       "      <td>plant</td>\n",
       "      <td>MULTIPOLYGON (((11832832.657 1731959.498, 1183...</td>\n",
       "      <td>1_1000_CNRM-CM6-1-HR</td>\n",
       "      <td>21</td>\n",
       "      <td>3309.699509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    osm_id  asset                                           geometry  \\\n",
       "0     None  plant  MULTIPOLYGON (((11440952.95 2125594.573, 11440...   \n",
       "1     None  plant  MULTIPOLYGON (((11440952.95 2125594.573, 11440...   \n",
       "2     None  plant  MULTIPOLYGON (((11440952.95 2125594.573, 11440...   \n",
       "3     None  plant  MULTIPOLYGON (((11440952.95 2125594.573, 11440...   \n",
       "4     None  plant  MULTIPOLYGON (((11440952.95 2125594.573, 11440...   \n",
       "..     ...    ...                                                ...   \n",
       "105   None  plant  MULTIPOLYGON (((11832832.657 1731959.498, 1183...   \n",
       "106   None  plant  MULTIPOLYGON (((11832832.657 1731959.498, 1183...   \n",
       "107   None  plant  MULTIPOLYGON (((11832832.657 1731959.498, 1183...   \n",
       "108   None  plant  MULTIPOLYGON (((11832832.657 1731959.498, 1183...   \n",
       "109   None  plant  MULTIPOLYGON (((11832832.657 1731959.498, 1183...   \n",
       "\n",
       "            return_period  index       damage  \n",
       "0      1_10_CNRM-CM6-1-HR      0  2989.453138  \n",
       "1      1_50_CNRM-CM6-1-HR      0  3593.237462  \n",
       "2     1_100_CNRM-CM6-1-HR      0  3867.059570  \n",
       "3     1_500_CNRM-CM6-1-HR      0  4374.063048  \n",
       "4    1_1000_CNRM-CM6-1-HR      0  4639.178446  \n",
       "..                    ...    ...          ...  \n",
       "105    1_10_CNRM-CM6-1-HR     21  1931.199196  \n",
       "106    1_50_CNRM-CM6-1-HR     21  2670.295005  \n",
       "107   1_100_CNRM-CM6-1-HR     21  2890.193758  \n",
       "108   1_500_CNRM-CM6-1-HR     21  3190.366191  \n",
       "109  1_1000_CNRM-CM6-1-HR     21  3309.699509  \n",
       "\n",
       "[110 rows x 6 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctry_damage_infra[1]['_CNRM-CM6-1-HR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ba717-0015-4527-bf1a-a9556f87a541",
   "metadata": {},
   "source": [
    "# Government data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "902f54e2-624d-4113-863b-f633bf096f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load collected power grid data\n",
    "def extract_pg_data(country_code,pg_type):\n",
    "\n",
    "    pg_path = os.path.join(pg_data_path,'{}_{}.gpkg'.format(country_code,pg_type)) #e.g.,LAO_line\n",
    "    pg_data_country = gpd.read_file(os.path.join(pg_path))\n",
    "    \n",
    "    pg_data_country = pd.DataFrame(pg_data_country.copy())\n",
    "    #print(pg_data_country.head())\n",
    "    pg_data_country.geometry = pygeos.from_shapely(pg_data_country.geometry)\n",
    "    pg_data_country['geometry'] = reproject(pg_data_country)\n",
    "    \n",
    "    if pg_type == 'line':\n",
    "        pg_data_country = buffer_assets(pg_data_country.loc[pg_data_country.asset.isin(['line'])],buffer_size=100).reset_index(drop=True)\n",
    "        return pg_data_country\n",
    "    \n",
    "    elif pg_type == 'point':\n",
    "        pg_data_country = buffer_assets(pg_data_country.loc[pg_data_country.asset.isin(['point'])],buffer_size=100).reset_index(drop=True)\n",
    "        return pg_data_country\n",
    "    \n",
    "    return pg_data_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9faf42e9-9f3a-471f-9cb3-c2987c4d8a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_damage_pg(country_code,pg_data_country,pg_type='line'):\n",
    "    \n",
    "    # load curves and maxdam\n",
    "    curves,maxdam = load_curves_maxdam(data_path=os.path.join('..','data','infra_vulnerability_data.xlsx'))\n",
    "    curves['line'] = 1 # remove this when things work!\n",
    "    \n",
    "    # read wind data\n",
    "    climate_models = ['_CMCC-CM2-VHR4','_CNRM-CM6-1-HR','_EC-Earth3P-HR','_HadGEM3-GC31-HM']\n",
    "    df_ds = extract_wind_data()\n",
    "\n",
    "    if pg_type=='line':        \n",
    "        # calculate damaged lines in loop by country_code and climate_model\n",
    "        damaged_lines = {}\n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['1_10{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                              '1_100{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "\n",
    "            overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],pg_data_country).T,\n",
    "                                         columns=['asset','hazard_point'])\n",
    "            collect_line_damages = []\n",
    "            for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),\n",
    "                              desc='polyline damage calculation for {} {}'.format(country_code,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_line_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                           df_ds[climate_model],\n",
    "                                                                                           pg_data_country,\n",
    "                                                                                           curves,\n",
    "                                                                                           maxdam,\n",
    "                                                                                           return_period,\n",
    "                                                                                           country_code)])\n",
    "\n",
    "            collect_line_damages = [(line[0],line[1][0],line[1][1]) for line in collect_line_damages]\n",
    "            damaged_lines_country = pg_data_country.merge(pd.DataFrame(collect_line_damages,columns=['return_period','index','damage']),\n",
    "                                                          left_index=True,right_on='index')\n",
    "            damaged_lines_country = damaged_lines_country.drop(['buffered'],axis=1)\n",
    "            damaged_lines[climate_model] = damaged_lines_country\n",
    "            \n",
    "    elif pg_type=='point':\n",
    "        # calculate damaged points in loop by country_code and climate_model\n",
    "        damaged_points = {}\n",
    "        for climate_model in climate_models:\n",
    "            return_periods = ['1_10{}'.format(climate_model),'1_50{}'.format(climate_model),\n",
    "                              '1_100{}'.format(climate_model),'1_500{}'.format(climate_model),'1_1000{}'.format(climate_model)]\n",
    "\n",
    "            overlay_points = pd.DataFrame(overlay_hazard_assets(df_ds[climate_model],pg_data_country).T,\n",
    "                                          columns=['asset','hazard_point'])\n",
    "            collect_point_damages = []\n",
    "            for asset in tqdm(overlay_points.groupby('asset'),total=len(overlay_points.asset.unique()),\n",
    "                              desc='point damage calculation for {} {}'.format(country_code,climate_model)):\n",
    "                for return_period in return_periods:\n",
    "                    collect_point_damages.append([return_period,get_damage_per_asset_per_rp(asset,\n",
    "                                                                                            df_ds[climate_model],\n",
    "                                                                                            pg_data_country,\n",
    "                                                                                            curves,\n",
    "                                                                                            maxdam,\n",
    "                                                                                            return_period,\n",
    "                                                                                            country_code)])\n",
    "\n",
    "            collect_point_damages = [(line[0],line[1][0],line[1][1]) for line in collect_point_damages]\n",
    "            damaged_points_country = pg_data_country.merge(pd.DataFrame(collect_point_damages,columns=['return_period','index','damage']),\n",
    "                                                        left_index=True,right_on='index')\n",
    "            damaged_points_country = damaged_points_country.drop(['buffered'],axis=1)\n",
    "            damaged_points[climate_model] = damaged_points_country\n",
    "   \n",
    "    return damaged_lines,damaged_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "64587507-ee0b-406a-a246-6bccede568dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "      <th>source</th>\n",
       "      <th>country</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>capacit_MW</th>\n",
       "      <th>operator</th>\n",
       "      <th>year</th>\n",
       "      <th>asset</th>\n",
       "      <th>value</th>\n",
       "      <th>involt_kV</th>\n",
       "      <th>outvolt_kV</th>\n",
       "      <th>capaci_kVA</th>\n",
       "      <th>units</th>\n",
       "      <th>layer</th>\n",
       "      <th>path</th>\n",
       "      <th>geometry</th>\n",
       "      <th>buffered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Existing</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>Laos</td>\n",
       "      <td>None</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>point</td>\n",
       "      <td>plant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>lao33762powerstations</td>\n",
       "      <td>C:/Users/mye500/OneDrive - Vrije Universiteit ...</td>\n",
       "      <td>POINT (11361572.355 2244469.157)</td>\n",
       "      <td>POLYGON ((11361672.355 2244469.157, 11361670.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Existing</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>Laos</td>\n",
       "      <td>None</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>point</td>\n",
       "      <td>plant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>lao33762powerstations</td>\n",
       "      <td>C:/Users/mye500/OneDrive - Vrije Universiteit ...</td>\n",
       "      <td>POINT (11419824.439 2099840.655)</td>\n",
       "      <td>POLYGON ((11419924.439 2099840.655, 11419922.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Existing</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>Laos</td>\n",
       "      <td>None</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>point</td>\n",
       "      <td>plant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>lao33762powerstations</td>\n",
       "      <td>C:/Users/mye500/OneDrive - Vrije Universiteit ...</td>\n",
       "      <td>POINT (11453022.972 2103393.117)</td>\n",
       "      <td>POLYGON ((11453122.972 2103393.117, 11453121.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Existing</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>Laos</td>\n",
       "      <td>None</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>point</td>\n",
       "      <td>plant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>lao33762powerstations</td>\n",
       "      <td>C:/Users/mye500/OneDrive - Vrije Universiteit ...</td>\n",
       "      <td>POINT (11637642.554 2064169.509)</td>\n",
       "      <td>POLYGON ((11637742.554 2064169.509, 11637740.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Existing</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>Laos</td>\n",
       "      <td>None</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>point</td>\n",
       "      <td>plant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>lao33762powerstations</td>\n",
       "      <td>C:/Users/mye500/OneDrive - Vrije Universiteit ...</td>\n",
       "      <td>POINT (11699554.725 2082341.258)</td>\n",
       "      <td>POLYGON ((11699654.725 2082341.258, 11699652.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    status      source country  name   type capacit_MW operator  year  \\\n",
       "0   0  Existing  World Bank    Laos  None  Hydro       None     None  None   \n",
       "1   1  Existing  World Bank    Laos  None  Hydro       None     None  None   \n",
       "2   2  Existing  World Bank    Laos  None  Hydro       None     None  None   \n",
       "3   3  Existing  World Bank    Laos  None  Hydro       None     None  None   \n",
       "4   4  Existing  World Bank    Laos  None  Hydro       None     None  None   \n",
       "\n",
       "   asset  value  involt_kV outvolt_kV capaci_kVA units                  layer  \\\n",
       "0  point  plant        NaN       None       None  None  lao33762powerstations   \n",
       "1  point  plant        NaN       None       None  None  lao33762powerstations   \n",
       "2  point  plant        NaN       None       None  None  lao33762powerstations   \n",
       "3  point  plant        NaN       None       None  None  lao33762powerstations   \n",
       "4  point  plant        NaN       None       None  None  lao33762powerstations   \n",
       "\n",
       "                                                path  \\\n",
       "0  C:/Users/mye500/OneDrive - Vrije Universiteit ...   \n",
       "1  C:/Users/mye500/OneDrive - Vrije Universiteit ...   \n",
       "2  C:/Users/mye500/OneDrive - Vrije Universiteit ...   \n",
       "3  C:/Users/mye500/OneDrive - Vrije Universiteit ...   \n",
       "4  C:/Users/mye500/OneDrive - Vrije Universiteit ...   \n",
       "\n",
       "                           geometry  \\\n",
       "0  POINT (11361572.355 2244469.157)   \n",
       "1  POINT (11419824.439 2099840.655)   \n",
       "2  POINT (11453022.972 2103393.117)   \n",
       "3  POINT (11637642.554 2064169.509)   \n",
       "4  POINT (11699554.725 2082341.258)   \n",
       "\n",
       "                                            buffered  \n",
       "0  POLYGON ((11361672.355 2244469.157, 11361670.4...  \n",
       "1  POLYGON ((11419924.439 2099840.655, 11419922.5...  \n",
       "2  POLYGON ((11453122.972 2103393.117, 11453121.0...  \n",
       "3  POLYGON ((11637742.554 2064169.509, 11637740.6...  \n",
       "4  POLYGON ((11699654.725 2082341.258, 11699652.8...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_data_country = extract_pg_data('LAO','point')\n",
    "pg_data_country.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fbe97d11-3136-40fc-8e19-7a295ce62ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "point damage calculation for LAO _CMCC-CM2-VHR4:   0%|                                          | 0/37 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'point'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pgrisk\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pgrisk\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pgrisk\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'point'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [129], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m assess_damage_infra \u001b[38;5;241m=\u001b[39m \u001b[43massess_damage_pg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLAO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpg_data_country\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpoint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m assess_damage_infra\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn [125], line 51\u001b[0m, in \u001b[0;36massess_damage_pg\u001b[1;34m(country_code, pg_data_country, pg_type)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m asset \u001b[38;5;129;01min\u001b[39;00m tqdm(overlay_points\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masset\u001b[39m\u001b[38;5;124m'\u001b[39m),total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(overlay_points\u001b[38;5;241m.\u001b[39masset\u001b[38;5;241m.\u001b[39munique()),\n\u001b[0;32m     49\u001b[0m                   desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoint damage calculation for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(country_code,climate_model)):\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m return_period \u001b[38;5;129;01min\u001b[39;00m return_periods:\n\u001b[1;32m---> 51\u001b[0m         collect_point_damages\u001b[38;5;241m.\u001b[39mappend([return_period,\u001b[43mget_damage_per_asset_per_rp\u001b[49m\u001b[43m(\u001b[49m\u001b[43masset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mdf_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclimate_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mpg_data_country\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mcurves\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mmaxdam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mreturn_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43mcountry_code\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[0;32m     59\u001b[0m collect_point_damages \u001b[38;5;241m=\u001b[39m [(line[\u001b[38;5;241m0\u001b[39m],line[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m],line[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m collect_point_damages]\n\u001b[0;32m     60\u001b[0m damaged_points_country \u001b[38;5;241m=\u001b[39m pg_data_country\u001b[38;5;241m.\u001b[39mmerge(pd\u001b[38;5;241m.\u001b[39mDataFrame(collect_point_damages,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_period\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdamage\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     61\u001b[0m                                             left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [4], line 102\u001b[0m, in \u001b[0;36mget_damage_per_asset_per_rp\u001b[1;34m(asset, df_ds, assets, curves, maxdam, return_period, country)\u001b[0m\n\u001b[0;32m    100\u001b[0m     maxdam_asset \u001b[38;5;241m=\u001b[39m maxdam\u001b[38;5;241m.\u001b[39mloc[asset_type]\u001b[38;5;241m.\u001b[39mMaxDam\u001b[38;5;241m/\u001b[39mpygeos\u001b[38;5;241m.\u001b[39marea(asset_geom)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 102\u001b[0m     maxdam_asset \u001b[38;5;241m=\u001b[39m \u001b[43mmaxdam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43masset_type\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mMaxDam\n\u001b[0;32m    105\u001b[0m hazard_intensity \u001b[38;5;241m=\u001b[39m curves[asset_type]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m    106\u001b[0m fragility_values \u001b[38;5;241m=\u001b[39m curves[asset_type]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pgrisk\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1070\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1072\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pgrisk\\lib\\site-packages\\pandas\\core\\indexing.py:1312\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pgrisk\\lib\\site-packages\\pandas\\core\\indexing.py:1260\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pgrisk\\lib\\site-packages\\pandas\\core\\generic.py:4056\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4054\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[0;32m   4055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4056\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4058\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   4059\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\pgrisk\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'point'"
     ]
    }
   ],
   "source": [
    "assess_damage_infra = assess_damage_pg('LAO',pg_data_country,'point')\n",
    "assess_damage_infra.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cafa914c-b259-4701-9dde-8408c2be02d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHN', 'IDN', 'JPN', 'KHM', 'KOR', 'LAO', 'LUX', 'MMR', 'MNG', 'PHL', 'PRK', 'THA', 'TWN', 'VNM']\n"
     ]
    }
   ],
   "source": [
    "osm_data_path = os.path.join('C:\\\\','data','country_osm')\n",
    "filelist = []\n",
    "country_codes = []\n",
    "for i in os.listdir(osm_data_path):\n",
    "    osm_path = os.path.join(osm_data_path,i)\n",
    "    if os.path.isfile(osm_path):\n",
    "        filelist.append(i)\n",
    "        country_codes.append(os.path.splitext(os.path.splitext(i)[0])[0])\n",
    "        osm_path = os.path.join(osm_data_path,i)\n",
    "        #print(osm_path)\n",
    "print(country_codes)\n",
    "country_codes = tuple(country_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0baa84d-4bab-4ffb-b139-0f3bafd7d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines\n",
    "overlay_lines = pd.DataFrame(overlay_hazard_assets(df_ds,pg_data).T,columns=['asset','hazard_point'])\n",
    "#print(overlay_lines.asset.unique())\n",
    "\n",
    "collect_line_damages = []\n",
    "for asset in tqdm(overlay_lines.groupby('asset'),total=len(overlay_lines.asset.unique()),desc='polyline damage calculation for {}'.format(country_code)):\n",
    "    for return_period in return_periods:\n",
    "        collect_line_damages.append([return_period,get_damage_per_asset_per_rp(asset,df_ds,pg_data,curves,maxdam,return_period,country_code)])\n",
    "\n",
    "collect_line_damages = [(line[0],line[1][0],line[1][1]) for line in collect_line_damages]\n",
    "damaged_lines = pg_data.merge(pd.DataFrame(collect_line_damages,columns=['return_period','index','damage']),left_index=True,right_on='index')\n",
    "damaged_lines = damaged_lines.drop(['buffered'],axis=1)\n",
    "damaged_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769479e-4a85-4931-af47-fb1ff09b73d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
